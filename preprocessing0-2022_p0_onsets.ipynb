{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936897e1-0e30-4bc7-a43a-32b8e1870b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:37:41.318338Z",
     "start_time": "2023-12-03T23:37:39.324512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import python packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import importlib\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5828b-fe13-4187-b261-8daacd5bb6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_list = ['KUMC', 'UTSW', 'MCW', 'UofU', 'UIOWA', 'UMHC', 'UPITT', 'UTHSCSA', 'UNMC']\n",
    "ext_list = ['csv','dsv', 'dsv', 'csv', 'csv', 'csv', 'csv', 'csv', 'csv']\n",
    "sep_list = [',','|', '|', '|', ',', ',', ',', ',', '|']\n",
    "encoding_list = ['utf-8','utf-8','utf-8','utf-8','utf-8','utf-8', 'windows-1252','utf-8', 'utf-16'] \n",
    "ct = 0\n",
    "\n",
    "site = site_list[ct]\n",
    "ext = ext_list[ct]\n",
    "sep = sep_list[ct]\n",
    "encoding = encoding_list[ct]\n",
    "path = []\n",
    "\n",
    "if site != 'KUMC':\n",
    "    rawpath = '/blue/yonghui.wu/hoyinchan/Data/data2022raw/' + site + '/raw/'\n",
    "else: \n",
    "    rawpath = '/blue/yonghui.wu/hoyinchan/Data/data2022raw/' + site + '_ORCALE/raw/'\n",
    "path.append(rawpath)\n",
    "path.append('/blue/yonghui.wu/hoyinchan/Data/data2022/' + site + '/')\n",
    "pdata = '/blue/yonghui.wu/hoyinchan/Data/data2022/'+ site \n",
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec29da-bc09-4488-8daf-5c46f7efaf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redo_onset(site, pdata):\n",
    "\n",
    "\n",
    "    onsets = pd.read_pickle(pdata+'/onset00.pkl')\n",
    "    admit  = try_load_csv('onsets', site, ext, sep, path, admit=None, datecol='ADMIT_DATE')\n",
    "\n",
    "    # Format datetime\n",
    "    admit['ADMIT_DATE'] = pd.to_datetime(pd.to_datetime(admit['ADMIT_DATE']).dt.date)\n",
    "    admit['DISCHARGE_DATE'] = pd.to_datetime(pd.to_datetime(admit['DISCHARGE_DATE']).dt.date)\n",
    "\n",
    "    # Get back non-aki\n",
    "    onsets_new = admit[['PATID', 'ENCOUNTERID', 'ADMIT_DATE', 'DISCHARGE_DATE']].merge(onsets , on = ['PATID', 'ENCOUNTERID', 'ADMIT_DATE'] , how='outer')\n",
    "\n",
    "    # fill stage\n",
    "    onsets_new['AKI_STAGE'] = onsets_new['AKI_STAGE'].fillna(0).astype(int)\n",
    "\n",
    "    # use discharge date as since_admit for aki0\n",
    "    onsets_new['DISCHARGE_SINCE_ADMIT'] = (onsets_new['DISCHARGE_DATE']-onsets_new['ADMIT_DATE']).dt.days\n",
    "    onsets_new['SINCE_ADMIT'] = np.where(onsets_new['ONSET_SINCE_ADMIT'].notna(), onsets_new['ONSET_SINCE_ADMIT'], onsets_new['DISCHARGE_SINCE_ADMIT'])\n",
    "\n",
    "    onsets_new.to_parquet(pdata+'/p0_onset_'+site+'.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da47e0-812b-4502-9ec8-da1323a0ae05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ct in range(len(site_list)):\n",
    "    site_list = ['KUMC', 'UTSW', 'MCW', 'UofU', 'UIOWA', 'UMHC', 'UPITT', 'UTHSCSA', 'UNMC']\n",
    "    ext_list = ['csv','dsv', 'dsv', 'csv', 'csv', 'csv', 'csv', 'csv', 'csv']\n",
    "    sep_list = [',','|', '|', '|', ',', ',', ',', ',', '|']\n",
    "    encoding_list = ['utf-8','utf-8','utf-8','utf-8','utf-8','utf-8', 'windows-1252','utf-8', 'utf-16'] \n",
    "\n",
    "    site = site_list[ct]\n",
    "    ext = ext_list[ct]\n",
    "    sep = sep_list[ct]\n",
    "    encoding = encoding_list[ct]\n",
    "    path = []\n",
    "\n",
    "    if site != 'KUMC':\n",
    "        rawpath = '/blue/yonghui.wu/hoyinchan/Data/data2022raw/' + site + '/raw/'\n",
    "    else: \n",
    "        rawpath = '/blue/yonghui.wu/hoyinchan/Data/data2022raw/' + site + '_ORCALE/raw/'\n",
    "    path.append(rawpath)\n",
    "    path.append('/blue/yonghui.wu/hoyinchan/Data/data2022/' + site + '/')\n",
    "    pdata = '/blue/yonghui.wu/hoyinchan/Data/data2022/'+ site \n",
    "    print(site)\n",
    "    \n",
    "    redo_onset(site, pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3f591-4f08-483b-9c5f-bfc49ee5b265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def try_load_csv(dataname, site, ext, sep, path, admit, datecol=None):\n",
    "    \n",
    "    datadtypes =  {\"PATID\": 'object', \"ENCOUNTERID\": 'object', \"ONSETS_ENCOUNTERID\": 'object', '\\ufeff\"ONSETS_ENCOUNTERID\"': 'object', #General\n",
    "               \"RESULT_NUM\":\"Float64\",  \"LAB_LOINC\": 'object', \"LAB_PX_TYPE\": 'object', \"RESULT_UNIT\": 'object', #lab\n",
    "               \"RESULT_QUAL\": 'object', \"RESULT_NUM\":\"Float64\", \"SPECIMEN_SOURCE\": 'object', #lab\n",
    "               \"SEX\": 'Int64', \"SEX\": 'category', \"RACE\": 'category', \"HISPANIC\": 'category', #demo, demodeath\n",
    "               \"DX\": 'object', \"DX_TYPE\": 'object', #DX\n",
    "               \"PX\": 'object', \"PX_TYPE\": 'object', #PX\n",
    "               \"MEDADMIN_TYPE\": \"object\", \"MEDADMIN_CODE\": 'object', #AMED\n",
    "               \"RXNORM_CUI\": \"object\",\n",
    "               \"SYSTOLIC\": 'Float64', \"DIASTOLIC\": 'Float64', \"ORIGINAL_BMI\": 'Float64', \"WT\": 'Float64', #VITAL_OLD\n",
    "               \"OBSCLIN_TYPE\": \"object\", \"OBSCLIN_CODE\": \"object\"} #VITAL      \n",
    "    \n",
    "    print(f\"processing : {dataname}\")\n",
    "    filename = 'AKI_'+dataname.upper()\n",
    "    outfilename = f\"/p0_{dataname}_{site}.pkl\"    \n",
    "    \n",
    "    # Site Specific filenames\n",
    "    if 'UMHC' in path[0]:\n",
    "        filename = 'DEID_'+filename    \n",
    "    if 'UofU' in path[0]:\n",
    "        if dataname == 'vital':\n",
    "            filename = 'DEID_AKI_VITAL_OLD'\n",
    "        if  dataname == 'dx_current':\n",
    "            filename = 'DEID_AKI_DX_CURRENT_ADMIT_DATE'                \n",
    "    \n",
    "    try:\n",
    "        # Try to load the file from the first path\n",
    "        df = pd.read_csv( path[0] +  filename + '.' + ext, engine=\"pyarrow\", sep=sep, encoding=encoding, dtype='object')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load from {path[0]}: {e}. Loading converted csv...\")\n",
    "        try:\n",
    "            # If the first attempt fails, try to load the file from the second path\n",
    "            #df = pd.read_csv( path[0] +  filename + '.' + ext, engine=\"pyarrow\", sep=sep)\n",
    "            df = pd.read_csv(path[1] +  filename + '.csv', engine=\"pyarrow\", sep=',', encoding=encoding, dtype='object')\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                # If the first attempt fails, try to load the file from the second path\n",
    "                df = pd.read_csv(path[1] +  filename + '.csv', sep=',', on_bad_lines = 'skip', encoding=encoding, dtype='object')\n",
    "            except Exception as e:\n",
    "                # If the second attempt also fails, handle or re-raise the exception\n",
    "                print(f\"Failed to load from {path[1]} as well: {e}\")\n",
    "                raise Exception(f\"Could not load the file from either path.\")\n",
    "        \n",
    "    try:\n",
    "        # handle UofU column shifted\n",
    "        if 'UofU' in path[0] and dataname=='dx':\n",
    "            df = df.reset_index()\n",
    "            df = df.drop('RAW_DX_POA',axis=1)\n",
    "            df.columns = ['ONSETS_ENCOUNTERID', 'DIAGNOSISID', 'PATID', 'ENCOUNTERID',\n",
    "                   'ENC_TYPE', 'ADMIT_DATE', 'DX_DATE', 'PROVIDERID', 'DX', 'DX_TYPE',\n",
    "                   'DX_SOURCE', 'DX_ORIGIN', 'PDX', 'DX_POA', 'RAW_DX', 'RAW_DX_TYPE',\n",
    "                   'RAW_DX_SOURCE', 'RAW_PDX', 'RAW_DX_POA', 'DAYS_SINCE_ADMIT']\n",
    "            df['DX_DATE'] = df['ADMIT_DATE'] \n",
    "        \n",
    "    \n",
    "        if 'UofU' in path[0] and dataname=='demo':\n",
    "            df = df.reset_index()\n",
    "            df = df.drop(['RAW_HISPANIC', 'RAW_RACE', 'BIOBANK_FLAG'],axis=1)\n",
    "            df.columns = ['ONSETS_ENCOUNTERID', 'AGE', 'PATID',\n",
    "                   'BIRTH_DATE', 'BIRTH_TIME', 'SEX', 'SEXUAL_ORIENTATION',\n",
    "                   'GENDER_IDENTITY', 'HISPANIC', 'BIOBANK_FLAG', 'RACE',\n",
    "                   'PAT_PREF_LANGUAGE_SPOKEN', 'RAW_SEX', 'RAW_SEXUAL_ORIENTATION',\n",
    "                   'RAW_GENDER_IDENTITY', 'RAW_HISPANIC', 'RAW_RACE',\n",
    "                   'RAW_PAT_PREF_LANGUAGE_SPOKEN', 'DEATH_DATE', 'DDAYS_SINCE_ENC',\n",
    "                   'DEATH_DATE_IMPUTE', 'DEATH_SOURCE']   \n",
    "        \n",
    "        # Some site use admit date as dx date\n",
    "        if 'DX_DATE' in df.columns and df['DX_DATE'].isna():\n",
    "            df['DX_DATE'] = df['ADMIT_DATE']\n",
    "                \n",
    "        df.rename(columns = {'\\ufeff\"ONSETS_ENCOUNTERID\"': 'ONSETS_ENCOUNTERID'}, inplace = True) # to handle the BOM character in UTHSCSA\n",
    "        df.columns = df.columns.str.upper()\n",
    "        df.columns = df.columns.str.replace('\"+PD.DATE_SHIFT\"','').str.replace('AKI.','') # To handle the starnge date name in KUMC\n",
    "        \n",
    "        # if not onset\n",
    "        if admit is not None:\n",
    "            df[\"ENCOUNTERID\"] = df[\"ONSETS_ENCOUNTERID\"]   \n",
    "            df = df.drop('ADMIT_DATE', axis=1, errors='ignore')\n",
    "            df = admit[[\"PATID\",\"ENCOUNTERID\", 'ADMIT_DATE']].merge(df, on = [\"PATID\",\"ENCOUNTERID\"], how = \"inner\")\n",
    "\n",
    "            # recalculate DAYS_SINCE_ADMIT using day as unit\n",
    "            if datecol is not None:\n",
    "                df[datecol] = pd.to_datetime(pd.to_datetime(df[datecol]).dt.date)\n",
    "                df['DAYS_SINCE_ADMIT'] = (df[datecol]-df['ADMIT_DATE']).dt.days\n",
    "                df = df.drop('ADMIT_DATE',axis=1)\n",
    "        \n",
    "        # Convert dataype\n",
    "        filtered_datadtypes = {key: datadtypes[key] for key in datadtypes if key in df.columns}\n",
    "        df = df.astype(filtered_datadtypes)            \n",
    "            \n",
    "        \n",
    "        if dataname == 'onsets':\n",
    "            return df\n",
    "        else:\n",
    "            df.to_pickle(pdata+outfilename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print (f\"{dataname} failed at postprocessing\")\n",
    "        raise Exception(f\"Could not load the file from either path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db429ad6-ac2e-4aa7-a177-1f7514628e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_PM_TEMPORAL_MOEA",
   "language": "python",
   "name": "aki_pm_temporal_moea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
