{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7cb206-e76d-4e6c-b257-2a580705c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c3439-c6da-416a-b230-1a8a3189eef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing Criterias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee2b86-035d-4e2f-92bd-608482aa43cb",
   "metadata": {},
   "source": [
    "1. age between 18 and 90 ☑️  \n",
    "2. hospitalized for at least 2 days ☑️  \n",
    "3. (abandoned)at least 2 SCr records between Admit date and AKI onset date, and also at least 2 SCr records within 30 days before the current Admit\n",
    "date, thus, one patient should at least have 5 records, 2 from history, 2 between admit and onset and 1 from the AKI onset day. ☑️  \n",
    "4. Exclude:  \n",
    "    (1)Non-AKI patients, Patients directly starting with AKI stage 2 or 3 ☑️  \n",
    "    (2)eGFR <15 mL/min/1.73 m^2 (calculated) ☑️    \n",
    "    (3)has undergone any dialysis procedure or renal transplantation (RRT) prior to the visit (find it in PX) ☑️  \n",
    "    (4)required RRT within 48h of their admission SCr measurement record ☑️    \n",
    "    (5)has pre-existing end stage renal disease ☑️      \n",
    "    (6)Burn patients ☑️     \n",
    "    (7)initial SCr measurement of > 3.5 mg/dL ☑️    \n",
    "    \n",
    "General Idea: Use AKI_ONSET to filter out NON-AKI patients, and hospitalized for less than 2 days, initial SCr measurement of > 3.5 mg/dL, then use it as query, to screen AKI_DEMO(for age), AKI_PX(for dialysis and RRT), AKI_DX(for end stage renal disease, burn patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d168a-c5f3-4e89-8599-9c066136fe75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tunable parameters'\n",
    "time_interval_before_ONSET = 7\n",
    "min_hospital_time = 3\n",
    "missing_percent_allowed = 0.2\n",
    "%store time_interval_before_ONSET\n",
    "n_rec_after_admit = 3\n",
    "max_SCR = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9144b9-4fc8-4552-9c19-55893e72ea3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define raw path\n",
    "raw_path = '/blue/yonghui.wu/hoyinchan/Data/data2022raw/'\n",
    "%store raw_path\n",
    "#pandas can show all the columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "#all avaiable clinical center names\n",
    "ct_names = ['UPITT', 'UTHSCSA', 'UIOWA', 'UTSW', 'MCW', 'UMHC', 'UofU', 'KUMC_ORCALE', 'UNMC']\n",
    "%store ct_names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a4857-e4c6-4003-b56c-657e279d5c96",
   "metadata": {},
   "source": [
    "# Modification (Oct 6, 2023)\n",
    "1. extract scr records 3 days prior to discharge and get the mean, then we can calculate % of patients went below to baseline\n",
    "2. persistent AKI definition: AKI onset lasts for more than 48h from its onset, get the % of persistent AKI in each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a595c398-786e-483f-872b-3471c389e30b",
   "metadata": {},
   "source": [
    "# What Data Should Be Collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1408f5df-5313-4bc8-afa1-a8c145d168ef",
   "metadata": {},
   "source": [
    "According to Ho Yin's paper, we need to collect AKI stages, Age, Gender, Race, BMI, ALT, AST, AMMONIA, CALCIUM, CK, CK_MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2d222-f676-4c91-9a69-bd3b5c65fc09",
   "metadata": {},
   "source": [
    "# Create a df that records the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e1620-0515-4d4e-ba45-4fd14367295f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "records_num_df = pd.DataFrame(0, index = ['Total number of encounters', 'Patients experiencing AKI onset during hospitalization',\n",
    "                                         'Patients whose first onset AKI stage was stage 1', 'Hospitalization > 2 days', \n",
    "                                         'SCr baseline less than 3.5', 'Patients with eGFR < 15 excluded', 'Burned patients excluded', \n",
    "                                         'Patients with pre-existing end stage renal disease excluded', \n",
    "                                          'Patients with dialysis or renal transplantation excluded',\n",
    "                                         'Patient not satisfying SCr trajectory requirements excluded'], columns = ct_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d4dd7-476b-41df-909e-7b51ef9cb65f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocess ONSETS Data and Screen AKI Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d7351-6d70-420b-a001-527c53064c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#need to uppercase all the column names of MCW\n",
    "def Upper_Case_Columns(df):\n",
    "    df.columns = [col.upper() for col in df.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ef396-5ce0-425b-9b8c-1f509eca80e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_AKI_ONSETS(ct_names, raw_path, fill_in_rec_num_df = False):\n",
    "    \n",
    "    AKI_ONSETS_dfs = dict()\n",
    "    \n",
    "    for ct in ct_names:\n",
    "        print('\\n' + ct + ':')\n",
    "        data_path = raw_path + ct + '/raw/'\n",
    "        if (ct == 'UPITT') or (ct == 'UTHSCSA') or (ct == 'UIOWA') or (ct == 'UNMC'):\n",
    "            AKI_onset = pd.read_csv(data_path + \"AKI_ONSETS.csv\", delimiter = ',')\n",
    "        elif (ct == 'UTSW'):\n",
    "            AKI_onset = pd.read_csv(data_path + \"AKI_ONSETS.dsv\", delimiter = '|')\n",
    "        elif (ct == 'MCW'):\n",
    "            AKI_onset = pd.read_csv(data_path + \"AKI_ONSETS.dsv\", delimiter = '|')\n",
    "            Upper_Case_Columns(AKI_onset)\n",
    "        elif (ct == 'UMHC'):\n",
    "            AKI_onset = pd.read_csv(data_path + \"DEID_AKI_ONSETS.csv\", delimiter = ',')\n",
    "        elif (ct == 'UofU'):\n",
    "            AKI_onset = pd.read_csv(data_path + \"AKI_ONSETS.csv\", delimiter = '|')\n",
    "        elif (ct == 'KUMC'):\n",
    "            AKI_onset = pd.read_csv(data_path + \"AKI_ONSETS.csv\", delimiter = ',')\n",
    "            AKI_onset_cols = AKI_onset.columns.tolist()\n",
    "            # AKI_onset_cols = [s[:-len('\"+PD.DATE_SHIFT\"')] \\\n",
    "            #                   if s.endswith('\"+PD.DATE_SHIFT\"') else s for s in AKI_onset_cols]\n",
    "            AKI_onset.columns = AKI_onset_cols\n",
    "        \n",
    "        AKI_onset.rename(columns={'ENCOUNTERID': 'ONSETS_ENCOUNTERID'}, inplace = True) \n",
    "        \n",
    "        AKI_ONSETS_dfs[ct] = AKI_onset\n",
    "        print('Initially, there are %d encounters in total!' %(len(AKI_ONSETS_dfs[ct].ONSETS_ENCOUNTERID.unique())))\n",
    "        \n",
    "        if fill_in_rec_num_df:\n",
    "            records_num_df.loc['Total number of encounters', ct] = len(AKI_ONSETS_dfs[ct].ONSETS_ENCOUNTERID.unique())\n",
    "            \n",
    "    return AKI_ONSETS_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114b401-e3e4-4fb5-8497-958aa42a0eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_AKI_ONSETS_v2(ct_names, fill_in_rec_num_df = False):\n",
    "    new_onsets = pd.read_csv('/blue/yonghui.wu/lideyi/AKI_subphenotyping_project_v3/NEW_ONSETS/NEW_ONSETS.csv')\n",
    "    AKI_ONSETS_dfs = dict()\n",
    "    for ct in ct_names:\n",
    "        print('\\n' + ct + ':')\n",
    "        if ct == 'KUMC_ORCALE':\n",
    "            this_center = new_onsets[new_onsets.CENTER_NAME == 'KUMC'].copy()\n",
    "        else:\n",
    "            this_center = new_onsets[new_onsets.CENTER_NAME == ct].copy()\n",
    "        \n",
    "        AKI_ONSETS_dfs[ct] = this_center\n",
    "        print('Initially, there are %d encounters in total!' %(len(AKI_ONSETS_dfs[ct].ONSETS_ENCOUNTERID.unique())))\n",
    "        if fill_in_rec_num_df:\n",
    "            records_num_df.loc['Total number of encounters', ct] = len(AKI_ONSETS_dfs[ct].ONSETS_ENCOUNTERID.unique())\n",
    "    return AKI_ONSETS_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a63c70-667d-4fc7-891b-9c7c8541b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_from_ONSETS(AKI_ONSETS_dfs):\n",
    "    \n",
    "    AKI_query_dfs = dict()\n",
    "    \n",
    "    for ct, AKI_onset in AKI_ONSETS_dfs.items():\n",
    "        print('\\n' + ct + ':')\n",
    "        #Criteria 4 exclude (1) screen Non-AKI patients\n",
    "        AKI_onset = AKI_onset[AKI_onset.NONAKI_SINCE_ADMIT == False]\n",
    "        print('After Criteria 4 Exclude (1) screen Non-AKI patients, there are %d qualified encounters left!' \n",
    "              %(len(AKI_onset.ONSETS_ENCOUNTERID.unique())))\n",
    "        records_num_df.loc['Patients experiencing AKI onset during hospitalization', ct] = \\\n",
    "        len(AKI_onset.ONSETS_ENCOUNTERID.unique())\n",
    "        \n",
    "        #only extract useful columns\n",
    "        AKI_onset = AKI_onset[['PATID','ONSETS_ENCOUNTERID','ADMIT_DATE', 'DISCHARGE_DATE', \n",
    "                               'SERUM_CREAT_BASE', 'AKI1_ONSET', 'AKI2_ONSET', 'AKI3_ONSET']]\n",
    "        \n",
    "        # Converting string data type into datetime object\n",
    "        time_cols = ['ADMIT_DATE', 'DISCHARGE_DATE', 'AKI1_ONSET', 'AKI2_ONSET', 'AKI3_ONSET']\n",
    "        for col in time_cols:\n",
    "            AKI_onset[col] = pd.to_datetime(AKI_onset[col], format='mixed')\n",
    "\n",
    "        #filter patients not start with AKI stage 1\n",
    "        AKI_onset = AKI_onset[AKI_onset.apply(filter_patients_start_stage_1, axis=1)]\n",
    "        print('After Criteria 4 Exclude (1.1) screen Non-AKI Stage 1 patients, there are %d qualified encounters left!' \n",
    "              %(len(AKI_onset.ONSETS_ENCOUNTERID.unique())))\n",
    "        records_num_df.loc['Patients whose first onset AKI stage was stage 1', ct] = \\\n",
    "        len(AKI_onset.ONSETS_ENCOUNTERID.unique())\n",
    "        \n",
    "        #find highest stage    \n",
    "        AKI_onset['HIGHEST_STAGE'] = AKI_onset.apply(find_highest_stage, axis = 1)\n",
    "        AKI_onset['HIGHEST_STAGE_ONSET'] = AKI_onset.apply(find_highest_stage_onset_date, axis = 1)\n",
    "        AKI_onset['PROGRESSION_TIME'] = AKI_onset.apply(progression_time, axis = 1)\n",
    "\n",
    "        #Criteria 2: hospitalized for at least 3 days\n",
    "        AKI_onset = AKI_onset[(AKI_onset.DISCHARGE_DATE - AKI_onset.ADMIT_DATE).dt.days >= min_hospital_time]\n",
    "        print('After Criteria 2: hospitalized for at least %s days, there are %d qualified encounters left!' \n",
    "              %(min_hospital_time, len(AKI_onset.ONSETS_ENCOUNTERID.unique())))\n",
    "        records_num_df.loc['Hospitalization > 2 days', ct] = \\\n",
    "        len(AKI_onset.ONSETS_ENCOUNTERID.unique())\n",
    "\n",
    "        #Criteria 4 Exclude (7): initial SCr measurement of > 3.5 mg/dL\n",
    "        AKI_onset = AKI_onset[AKI_onset.SERUM_CREAT_BASE <= 3.5]\n",
    "        print('After Criteria 4 Exclude (7): initial SCr measurement of > 3.5 mg/dL, there are %d qualified encounters left!' \n",
    "              %(len(AKI_onset.ONSETS_ENCOUNTERID.unique())))\n",
    "        records_num_df.loc['SCr baseline less than 3.5', ct] = \\\n",
    "        len(AKI_onset.ONSETS_ENCOUNTERID.unique())\n",
    "\n",
    "        #drop any possible duplicates\n",
    "        AKI_onset.drop_duplicates(inplace = True)\n",
    "\n",
    "        #make a deep copy for further preprocessing with other dataframes\n",
    "        AKI_query = AKI_onset.copy(deep=True)\n",
    "        AKI_query.rename(columns={'AKI1_ONSET': 'EARLIEST_ONSET'}, inplace=True)\n",
    "        AKI_query.drop(['AKI2_ONSET', 'AKI3_ONSET'], axis = 1, inplace = True)\n",
    "        \n",
    "        \n",
    "        AKI_query_dfs[ct] = AKI_query\n",
    "        \n",
    "    return AKI_query_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ed2fd-d86e-4703-a2b8-770a14012e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def progression_time(row):\n",
    "    return (row['HIGHEST_STAGE_ONSET'] - row['AKI1_ONSET']).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c894be-d6fc-4fbf-baa8-39cc31d11d79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_highest_stage_onset_date(row):\n",
    "    if row['HIGHEST_STAGE'] == 'AKI Stage 3':\n",
    "        return row['AKI3_ONSET']\n",
    "    elif row['HIGHEST_STAGE'] == 'AKI Stage 2':\n",
    "        return row['AKI2_ONSET']\n",
    "    else:\n",
    "        return row['AKI1_ONSET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0a677-dbd6-4ef6-9f0c-ba24054e1291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some patients have both 2 stages or 3 stages, find the highest one\n",
    "def find_highest_stage(row):\n",
    "    if pd.notna(row['AKI3_ONSET']):\n",
    "        return 'AKI Stage 3'\n",
    "    elif pd.notna(row['AKI2_ONSET']):\n",
    "        return 'AKI Stage 2'\n",
    "    else:\n",
    "        return 'AKI Stage 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f40a846-6ef2-4ae3-bf86-5717156c1b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_patients_start_stage_1(row):\n",
    "    if pd.notna(row['AKI1_ONSET']):\n",
    "        #patients only developed stage 1\n",
    "        if (pd.isna(row['AKI2_ONSET'])) and (pd.isna(row['AKI3_ONSET'])):\n",
    "            return True\n",
    "        #patients developed stage 1 at first\n",
    "        elif row['AKI1_ONSET'] < min(row[['AKI2_ONSET', 'AKI3_ONSET']]):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7edda-07b6-4208-89d7-015def39de1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read onset datasets, which indicates which patient experienced AKI during hosipitalization\n",
    "AKI_ONSETS_dfs = read_AKI_ONSETS_v2(ct_names, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9402967-eba4-4076-863b-0d397e1b0445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AKI_query_dfs = generate_query_from_ONSETS(AKI_ONSETS_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51f99f-5d78-472b-a3d5-d274252a4035",
   "metadata": {},
   "source": [
    "# Preprocess Demographic Data and Join with Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a0387-fda3-4c84-acea-2880fa23533a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read patients' demographical data\n",
    "def read_AKI_DEMO(ct_names, raw_path):\n",
    "    AKI_DEMO_dfs = dict()\n",
    "    use_cols = ['ONSETS_ENCOUNTERID', 'AGE', 'PATID', 'SEX', 'RACE']\n",
    "\n",
    "    for ct in ct_names:\n",
    "        data_path = raw_path + ct + '/raw/'\n",
    "        if (ct == 'UPITT') or (ct == 'UTHSCSA') or (ct == 'UIOWA') or (ct == 'KUMC_ORCALE'):\n",
    "             AKI_DEMO = pd.read_csv(data_path + \"AKI_DEMO.csv\", delimiter = ',', usecols = use_cols)\n",
    "        elif (ct == 'UTSW'):\n",
    "            AKI_DEMO = pd.read_csv(data_path + \"AKI_DEMO.dsv\", delimiter = '|', usecols = use_cols)\n",
    "        elif (ct == 'MCW'):\n",
    "            AKI_DEMO = pd.read_csv(data_path + \"AKI_DEMO.dsv\", delimiter = '|', usecols = list(map(str.lower, use_cols)))\n",
    "            Upper_Case_Columns(AKI_DEMO)\n",
    "        elif (ct == 'UMHC'):\n",
    "            AKI_DEMO = pd.read_csv(data_path + \"DEID_AKI_DEMO.csv\", delimiter = ',', usecols = use_cols)\n",
    "        elif (ct == 'UofU'):\n",
    "            AKI_DEMO = pd.read_csv(data_path + \"AKI_DEMO.csv\", delimiter = '|', \n",
    "                                           header=None, skiprows = 1, usecols=[0, 1, 2, 5, 17])\n",
    "            AKI_DEMO.columns = use_cols\n",
    "    \n",
    "        AKI_DEMO_dfs[ct] = AKI_DEMO\n",
    "        \n",
    "    return AKI_DEMO_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6cc4f-64d1-4ad3-a9e8-e1c3d2e617e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate eGFR\n",
    "def calculate_ckd_epi(row, SCr_col_name):\n",
    "    \n",
    "    age = row['AGE']\n",
    "    gender = row['SEX']\n",
    "    race = row['RACE']\n",
    "    SCr = row[SCr_col_name]\n",
    "    \n",
    "    # Constants for the CKD-EPI formula\n",
    "    k = 0.7 if gender == 'F' else 0.9\n",
    "    alpha = -0.329 if gender == 'F' else -0.411\n",
    "    \n",
    "    # Calculate the eGFR\n",
    "    min_term = min(SCr / k, 1) ** alpha\n",
    "    max_term = max(SCr / k, 1) ** -1.209\n",
    "    age_term = 0.993 ** age\n",
    "    # Gender and ethnicity adjustments\n",
    "    gender_term = 1.018 if gender == 'F' else 1\n",
    "    african_american_term = 1.159 if race == \"RACE:black\" else 1\n",
    "    \n",
    "    eGFR = 141 * min_term * max_term * age_term * gender_term * african_american_term\n",
    "    \n",
    "    return eGFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf6e4e-29ef-429e-90a2-4aafc627898f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_query_by_AKI_DEMO(AKI_DEMO_dfs, AKI_query_dfs):\n",
    "    \n",
    "    for ct, AKI_DEMO in AKI_DEMO_dfs.items():\n",
    "        print('\\n' + ct + ':')\n",
    "        AKI_DEMO = AKI_query_dfs[ct].merge(AKI_DEMO, how = 'left', on = ['PATID', 'ONSETS_ENCOUNTERID'])\n",
    "        \n",
    "        #Criteria 1: age between 18 and 90\n",
    "        AKI_DEMO = AKI_DEMO[(AKI_DEMO.AGE >= 18) & (AKI_DEMO.AGE <= 90)]\n",
    "        AKI_query_dfs[ct] = AKI_query_dfs[ct][AKI_query_dfs[ct].PATID.isin(AKI_DEMO.PATID)]\n",
    "        print('After Criteria 1: age between 18 and 90, there are %d qualified patients left!' \n",
    "              %(len(AKI_query_dfs[ct].ONSETS_ENCOUNTERID.unique())))\n",
    "        \n",
    "        #Criteria 4 Exclude (2): eGFR <15 mL/min/1.73 m^2 \n",
    "        AKI_DEMO['GFR'] = AKI_DEMO.apply(calculate_ckd_epi, args = ('SERUM_CREAT_BASE',), axis = 1)\n",
    "        AKI_DEMO = AKI_DEMO[AKI_DEMO.GFR >= 15]\n",
    "\n",
    "        #update query by filtering out AKI patients that is not with the age range\n",
    "        AKI_query_dfs[ct] = AKI_query_dfs[ct][AKI_query_dfs[ct].PATID.isin(AKI_DEMO.PATID)]\n",
    "        print('After Criteria 1: Exclude(2) GFR < 15, there are %d qualified patients left!' \n",
    "              %(len(AKI_query_dfs[ct].ONSETS_ENCOUNTERID.unique())))\n",
    "        records_num_df.loc['Patients with eGFR < 15 excluded', ct] = \\\n",
    "        len(AKI_query_dfs[ct].ONSETS_ENCOUNTERID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5fe308-4907-4e2a-a075-6b24da39b6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AKI_DEMO_dfs = read_AKI_DEMO(ct_names, raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c0523-d558-41ba-bbfa-eb5d034978e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_query_by_AKI_DEMO(AKI_DEMO_dfs, AKI_query_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69e397-d3d5-4df7-a034-8f3d47f58608",
   "metadata": {},
   "source": [
    "# Preprocess Diagnosis Data and Join with Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8648eac-2cc1-41f5-b461-02553a02a8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read patients' diagnosis data\n",
    "#cneters do not have a DX_DATE: UTHSCSA, UTSW, UofU\n",
    "def read_AKI_DX(ct_names, raw_path):\n",
    "    AKI_DX_dfs = dict()\n",
    "    use_cols = ['PATID', 'DX_DATE', 'DX', 'DX_TYPE', 'DAYS_SINCE_ADMIT']\n",
    "    ct_missing_DX_DATE = ['UTHSCSA', 'UTSW', 'UofU']\n",
    "    \n",
    "    for ct in ct_names:\n",
    "        data_path = raw_path + ct + '/raw/'\n",
    "        if (ct == 'UPITT') or (ct == 'UTHSCSA') or (ct == 'UIOWA'):\n",
    "            AKI_DX = pd.read_csv(data_path + \"AKI_DX.csv\", delimiter = ',', usecols=use_cols)\n",
    "            #adjust the col order of UIOWA\n",
    "            if ct == 'UIOWA':\n",
    "                AKI_DX = AKI_DX[use_cols]\n",
    "        elif (ct == 'UTSW'):\n",
    "            AKI_DX = pd.read_csv(data_path + \"AKI_DX.dsv\", delimiter = '|', usecols=use_cols)\n",
    "        elif (ct == 'MCW'):\n",
    "            AKI_DX = pd.read_csv(data_path + \"AKI_DX.dsv\", delimiter = '|', usecols=list(map(str.lower, use_cols)))\n",
    "            Upper_Case_Columns(AKI_DX)\n",
    "        elif (ct == 'UMHC'):\n",
    "            AKI_DX = pd.read_csv(data_path + \"DEID_AKI_DX.csv\", delimiter = ',', usecols=use_cols)\n",
    "        elif (ct == 'UofU'):\n",
    "            AKI_DX = pd.read_csv(data_path + \"AKI_DX.csv\", delimiter = '|', header=None, \n",
    "                                           skiprows = 1, usecols=[2, 6, 8, 9, 20])\n",
    "            AKI_DX.columns = use_cols\n",
    "        elif (ct == 'KUMC_ORCALE'):\n",
    "            AKI_DX = pd.read_csv(data_path + \"AKI_DX.csv\", delimiter = ',', \n",
    "                                 usecols=['PATID', 'DX_DATE\"+PD.DATE_SHIFT\"', 'DX', \n",
    "                                          'DX_TYPE', 'DAYS_SINCE_ADMIT'])\n",
    "            AKI_DX.columns = use_cols\n",
    "        \n",
    "        if ct not in ct_missing_DX_DATE:\n",
    "            AKI_DX['DX_DATE'] = pd.to_datetime(AKI_DX['DX_DATE'], format = 'mixed')\n",
    "            AKI_DX['DX_DATE'] = AKI_DX['DX_DATE'].dt.strftime('%Y-%m-%d')\n",
    "            AKI_DX['DX_DATE'] = pd.to_datetime(AKI_DX['DX_DATE'], format = 'mixed')\n",
    "            \n",
    "        AKI_DX_dfs[ct] = AKI_DX\n",
    "        \n",
    "    return AKI_DX_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98726165-41cb-425e-8209-de1402a78fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_query_by_AKI_DX(AKI_DX_dfs, AKI_query_dfs):\n",
    "    ct_missing_DX_DATE = ['UTHSCSA', 'UTSW', 'UofU']\n",
    "    \n",
    "    for ct, AKI_DX in AKI_DX_dfs.items():\n",
    "        print('\\n' + ct + ':')\n",
    "        \n",
    "        #filter DX that is before the target hospitalization\n",
    "        AKI_DX_to_filter = \\\n",
    "        AKI_query_dfs[ct][['PATID', 'ADMIT_DATE']].merge(AKI_DX, on = \"PATID\", how = \"left\")\n",
    "        AKI_DX_to_filter.dropna(subset=['DX'], inplace = True)\n",
    "        \n",
    "        if ct in ct_missing_DX_DATE:\n",
    "            AKI_DX_to_filter.loc[:, 'DX_DATE'] = \\\n",
    "            AKI_DX_to_filter.loc[:, 'ADMIT_DATE'] + \\\n",
    "            pd.to_timedelta(AKI_DX_to_filter.loc[:, 'DAYS_SINCE_ADMIT'], unit='D')\n",
    "        \n",
    "        AKI_DX_filtered = AKI_DX_to_filter[AKI_DX_to_filter.DX_DATE <= AKI_DX_to_filter.ADMIT_DATE]\n",
    "        \n",
    "        # Convert the mixed column to numeric, coercing errors to NaN\n",
    "        AKI_DX['numeric_DX'] = pd.to_numeric(AKI_DX['DX'], errors='coerce')\n",
    "\n",
    "        #Criteria 4 Exclude (6): Burn patients, Burns' ICD-9 codes are 940-949\n",
    "        AKI_BURN = AKI_DX[(AKI_DX['numeric_DX'] >= 940) & (AKI_DX['numeric_DX'] <= 949) & (AKI_DX['DX_TYPE'] == 9)]\n",
    "        #update query by filtering out patients with burns \n",
    "        AKI_query_dfs[ct] = AKI_query_dfs[ct][~AKI_query_dfs[ct].PATID.isin(AKI_BURN.PATID)]\n",
    "        print('After Criteria 4 Exclude (6): burned patients, there are %s qualified patients left!' \n",
    "              %(len(AKI_query_dfs[ct].ONSETS_ENCOUNTERID.unique())))\n",
    "        records_num_df.loc['Burned patients excluded', ct] = \\\n",
    "        len(AKI_query_dfs[ct].ONSETS_ENCOUNTERID.unique())\n",
    "\n",
    "        #Criteria 4 Exclude (5): has pre-existing end stage renal disease, ICD-9 403, 404, 585\n",
    "        ICD10_end_stage_renal = ['I12.0', 'I13.1', 'I13.2', 'N18.6', 'Z49.3']\n",
    "        AKI_END_RENAL = AKI_DX[((((AKI_DX['numeric_DX'] >= 403) & (AKI_DX['numeric_DX'] < 405)) | \n",
    "                                 ((AKI_DX['numeric_DX'] >= 585) & (AKI_DX['numeric_DX'] < 586))) & (AKI_DX['DX_TYPE'] == 9)) | \n",
    "                               ((AKI_DX.DX.isin(ICD10_end_stage_renal)) & (AKI_DX['DX_TYPE'] == 10))]\n",
    "        \n",
    "        #Criteria 4 Exclude (3): has undergone any dialysis procedure or renal transplantation (RRT) prior to the visit\n",
    "        DIA_RRT_DX_ICD10_DX = ['T86.10', 'T86.11', 'T86.12']\n",
    "        AKI_DIA_RRT_DX = AKI_DX[(AKI_DX.DX.isin(DIA_RRT_DX_ICD10_DX)) & (AKI_DX.DX_TYPE == 10)]\n",
    "        \n",
    "        # Drop the auxiliary column \n",
    "        AKI_DX.drop('numeric_DX', axis=1, inplace=True)\n",
    "\n",
    "        #update query by filtering out patients with end stage renal disease \n",
    "        AKI_query_dfs[ct] = AKI_query_dfs[ct][~AKI_query_dfs[ct].PATID.isin(AKI_END_RENAL.PATID)]\n",
    "        AKI_query_dfs[ct] = AKI_query_dfs[ct][~AKI_query_dfs[ct].PATID.isin(AKI_DIA_RRT_DX.PATID)]\n",
    "        print('After Criteria 4 Exclude (5): has pre-existing end stage renal disease, there are %s qualified patients left!' \n",
    "              %(len(AKI_query_dfs[ct].ONSETS_ENCOUNTERID.unique())))\n",
    "        records_num_df.loc['Patients with pre-existing end stage renal disease excluded', ct] = \\\n",
    "        len(AKI_query_dfs[ct].ONSETS_ENCOUNTERID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8f6a8-a78f-4095-9316-638563dd34ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AKI_DX_dfs = read_AKI_DX(ct_names, raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26455788-a72d-4115-b675-4099564d2003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_query_by_AKI_DX(AKI_DX_dfs, AKI_query_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49408e98-6575-46d4-946e-a539f7b09d05",
   "metadata": {},
   "source": [
    "# Preprocess Procedure Data and Join with Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989743b4-3101-404f-b83b-931905293538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read patients' Procedure data\n",
    "def read_AKI_PX(ct_names, raw_path):\n",
    "    AKI_PX_dfs = dict()\n",
    "    use_cols = ['PATID', 'PX', 'PX_TYPE']\n",
    "\n",
    "    for ct in ct_names:\n",
    "        data_path = raw_path + ct + '/raw/'\n",
    "        if (ct == 'UPITT') or (ct == 'UTHSCSA') or (ct == 'UIOWA') or (ct == 'KUMC_ORCALE'):\n",
    "            AKI_PX = pd.read_csv(data_path + \"AKI_PX.csv\", delimiter = ',', usecols = use_cols)\n",
    "        elif (ct == 'UTSW'):\n",
    "            AKI_PX = pd.read_csv(data_path + \"AKI_PX.dsv\", delimiter = '|', usecols = use_cols)\n",
    "        elif (ct == 'MCW'):\n",
    "            AKI_PX = pd.read_csv(data_path + \"AKI_PX.dsv\", delimiter = '|', usecols = list(map(str.lower, use_cols)))\n",
    "            Upper_Case_Columns(AKI_PX)\n",
    "        elif (ct == 'UMHC'):\n",
    "            AKI_PX = pd.read_csv(data_path + \"DEID_AKI_PX.csv\", delimiter = ',', usecols = use_cols)\n",
    "        elif (ct == 'UofU'):\n",
    "            AKI_PX = pd.read_csv(data_path + \"AKI_PX.csv\", delimiter = '|', usecols = use_cols)\n",
    "    \n",
    "        AKI_PX_dfs[ct] = AKI_PX\n",
    "        \n",
    "    return AKI_PX_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c373a6f-d33e-4479-91bd-f8ea5e963952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_query_by_AKI_PX(AKI_PX_dfs, AKI_query_dfs):\n",
    "    #Criteria 4 Exclude (3): has undergone any dialysis procedure or renal transplantation (RRT) prior to the visit \n",
    "    ICD10_DIA_RRT = ['5A1D00Z','5A1D60Z','5A1D70Z','5A1D80Z',\n",
    "                     '5A1D90Z', '0TY00Z0','0TY00Z1',\n",
    "                     '0TY00Z2','0TY10Z0','0TY10Z1',\n",
    "                     '0TY10Z2', '0TB00ZZ','0TB10ZZ','0TT00ZZ',\n",
    "                     '0TT10ZZ','0TT20ZZ']\n",
    "    ICD9_DIA_RRT = ['39.93','39.95','54.98', '55.51',\n",
    "                    '55.52','55.53','55.54','55.61','55.69']\n",
    "    CPT_DIA_RRT = ['00868', '01990', '50300', '50320', \n",
    "                   '50323', '50325', '50327', '50328', \n",
    "                   '50329', '50340', '50360',\n",
    "                    '50365', '50370', '50380', \n",
    "                   '90935', '90937']\n",
    "    \n",
    "    for ct, AKI_PX in AKI_PX_dfs.items():\n",
    "        print('\\n' + ct + ':')\n",
    "        AKI_DIA_RRT = AKI_PX[((AKI_PX.PX.isin(ICD10_DIA_RRT)) & (AKI_PX.PX_TYPE == '10')) | \n",
    "                     ((AKI_PX.PX.isin(ICD9_DIA_RRT)) & (AKI_PX.PX_TYPE == '09')) |\n",
    "                     ((AKI_PX.PX.isin(CPT_DIA_RRT)) & (AKI_PX.PX_TYPE == 'CH'))]\n",
    "        AKI_query_dfs[ct] = AKI_query_dfs[ct][~AKI_query_dfs[ct].PATID.isin(AKI_DIA_RRT.PATID)]\n",
    "\n",
    "        print('After Criteria 4 Exclude (3): has undergone any dialysis procedure or renal transplantation (RRT) prior to the visit, there are %d qualified patients left!' \n",
    "              %(len(AKI_query_dfs[ct].ONSETS_ENCOUNTERID.unique())))\n",
    "        records_num_df.loc['Patients with dialysis or renal transplantation excluded', ct] = \\\n",
    "        len(AKI_query_dfs[ct].ONSETS_ENCOUNTERID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df2852-d425-4e9e-910f-8b12526cbd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AKI_PX_dfs = read_AKI_PX(ct_names, raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03bc89-bd11-4ee2-8551-5c7294229349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_query_by_AKI_PX(AKI_PX_dfs, AKI_query_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449b88a-de4c-4404-8ab4-36e716fc1159",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocess SCr Data and Merge with Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994fee4e-83e9-4ad0-8123-f86e9a9ffc8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read Scr records, here we kept the historical records(DAYS_SINCE_ADMIT < 0)\n",
    "def read_AKI_LAB_SCR(ct_names, raw_path):\n",
    "    SCR_dfs = dict()\n",
    "    use_cols = ['ONSETS_ENCOUNTERID','PATID','ENCOUNTERID','SPECIMEN_DATE','RESULT_NUM', 'DAYS_SINCE_ADMIT']\n",
    "\n",
    "    for ct in ct_names:\n",
    "        data_path = raw_path + ct + '/raw/'\n",
    "        if (ct == 'UPITT') or (ct == 'UTHSCSA') or (ct == 'UIOWA'):\n",
    "            SCR_df = pd.read_csv(data_path + \"AKI_LAB_SCR.csv\", delimiter = ',', usecols=use_cols)\n",
    "        elif (ct == 'UTSW'):\n",
    "            SCR_df = pd.read_csv(data_path + \"AKI_LAB_SCR.dsv\", delimiter = '|', usecols=use_cols)\n",
    "        elif (ct == 'MCW'):\n",
    "            SCR_df = pd.read_csv(data_path + \"AKI_LAB_SCR.dsv\", delimiter = '|', usecols=list(map(str.lower, use_cols)))\n",
    "            Upper_Case_Columns(SCR_df)\n",
    "        elif (ct == 'UMHC'):\n",
    "            SCR_df = pd.read_csv(data_path + \"DEID_AKI_LAB_SCR.csv\", delimiter = ',', usecols=use_cols)\n",
    "        elif (ct == 'UofU'):\n",
    "            SCR_df = pd.read_csv(data_path + \"AKI_LAB_SCR.csv\", delimiter = '|', usecols=use_cols)\n",
    "        elif (ct == 'KUMC_ORCALE'):\n",
    "            use_cols = ['ONSETS_ENCOUNTERID','PATID','ENCOUNTERID',\n",
    "                        'SPECIMEN_DATE\"+PD.DATE_SHIFT\"','RESULT_NUM', 'DAYS_SINCE_ADMIT']\n",
    "            SCR_df = pd.read_csv(data_path + \"AKI_LAB_SCR.csv\", delimiter = ',', usecols=use_cols)\n",
    "            SCR_df.columns = ['ONSETS_ENCOUNTERID','PATID','ENCOUNTERID', 'SPECIMEN_DATE','RESULT_NUM', \n",
    "                              'DAYS_SINCE_ADMIT']\n",
    "\n",
    "        SCR_dfs[ct] = SCR_df\n",
    "        \n",
    "    return SCR_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc15327-be75-4acc-b185-3c7093e1d466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_groups(group):\n",
    "    return group['RESULT_NUM'].max() <= max_SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34624ef8-7b16-48bc-9aff-890a3ed2c485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_SCR_query_and_process(SCR_dfs, AKI_query_dfs, mode = 'BEFORE_ONSET'):\n",
    "    AKI_SCR_dfs = dict()\n",
    "    \n",
    "    for ct, Scr in SCR_dfs.items():\n",
    "        print('\\n' + ct + ':')\n",
    "        #filter out Non-AKI patients\n",
    "        AKI_Scr = AKI_query_dfs[ct].merge(Scr, how = 'inner', on = ['PATID', 'ONSETS_ENCOUNTERID'])\n",
    "        \n",
    "        # Converting string data type into datetime object\n",
    "        AKI_Scr['SPECIMEN_DATE'] = pd.to_datetime(AKI_Scr['SPECIMEN_DATE'], format='mixed')\n",
    "        # Extract just the date part(Only needed by UMHC data)\n",
    "        if ct == 'UMHC':\n",
    "            AKI_Scr['SPECIMEN_DATE'] = AKI_Scr['SPECIMEN_DATE'].dt.date\n",
    "            AKI_Scr['SPECIMEN_DATE'] = pd.to_datetime(AKI_Scr['SPECIMEN_DATE'])\n",
    "            \n",
    "        #some DAYS_SINCE_ADMIT need to be corrected\n",
    "        AKI_Scr['DAYS_SINCE_ADMIT'] = (AKI_Scr['SPECIMEN_DATE'] - AKI_Scr['ADMIT_DATE']).dt.days\n",
    "        \n",
    "        #sort the df by ONSETS_ENCOUNTERID\n",
    "        #Tip: 'ONSETS_ENCOUNTERID'represents the ID for current hospitalization， 'ENCOUNTERID' is bound to the test day，can be in the past，\n",
    "        #if it happend in the past, then DAYS_SINCE_ADMIT is negative, means that it happended before the date of admit date represented by\n",
    "        #'ONSETS_ENCOUNTERID', if it happens now, then 'ENCOUNTERID' should be same as 'ONSETS_ENCOUNTERID'.\n",
    "        #Here, ADMIT_DATE, DISCHARGE_DATE, AKI123_ONSET, EARLIEST_ONSET is tied to ONSETS_ENCOUNTERID, representing current hospitalization,\n",
    "        #while, SPECIMEN_DATE is tied to ENCOUNTERID, and DAYS_SINCE_ADMIT is relative to ONSETS_ENCOUNTERID/ADMIT_DATE\n",
    "        AKI_Scr = AKI_Scr.sort_values(by=['ONSETS_ENCOUNTERID', 'SPECIMEN_DATE'])\n",
    "\n",
    "        #Multiple measurements of SCr one the same day are averaged\n",
    "        AKI_Scr['RESULT_NUM'] = AKI_Scr.groupby(['PATID', 'SPECIMEN_DATE'])['RESULT_NUM'].transform(np.mean)\n",
    "        AKI_Scr.drop_duplicates(subset=['PATID', 'SPECIMEN_DATE'], inplace=True)\n",
    "\n",
    "        print('After Averaging records on the same day, there are %s qualified records left!' %len(AKI_Scr.ONSETS_ENCOUNTERID.unique()))\n",
    "        \n",
    "        \n",
    "        AKI_Scr.drop_duplicates(subset=['PATID', 'SPECIMEN_DATE'], inplace=True)\n",
    "        \n",
    "        #((at least n SCr records)---|Admit|---(at least n' SCr records)---|AKI Onset|---(no requirement)---|Discharge|)\n",
    "        #Criteria 3: at least n SCr records between Admit date and AKI onset date, \n",
    "        #and also at least n' SCr history records within 30 days before the ONSET day,\n",
    "        #total time series interval is 30 days before the onset day\n",
    "        AKI_Scr['DAYS_BEFORE_ONSET'] = (AKI_Scr['SPECIMEN_DATE'] - AKI_Scr['EARLIEST_ONSET']).dt.days\n",
    "        \n",
    "        if mode == 'BEFORE_ONSET':\n",
    "            #drop records after onset day(we should include onset dat itself), or historical records not within 7 day time interval\n",
    "            AKI_Scr = AKI_Scr[(AKI_Scr.DAYS_BEFORE_ONSET <= 0) & (AKI_Scr.DAYS_BEFORE_ONSET > -time_interval_before_ONSET)]\n",
    "\n",
    "            #sub-requirement 2: admit-onset period # of record should be at least 'n_rec_after_admit'\n",
    "            scr_before_onset = AKI_Scr[(AKI_Scr.DAYS_BEFORE_ONSET < 0) & ((AKI_Scr.DAYS_SINCE_ADMIT >=0))].groupby('ONSETS_ENCOUNTERID').count()\n",
    "            encounters_to_keep2 = scr_before_onset[scr_before_onset.SPECIMEN_DATE >= n_rec_after_admit].index\n",
    "            AKI_Scr = AKI_Scr[AKI_Scr.ONSETS_ENCOUNTERID.isin(encounters_to_keep2)]\n",
    "\n",
    "            print('After Criteria 3 sub-req 2: admit-onset period # of record should be at least %s, there are %s qualified records left!' \n",
    "                  %(n_rec_after_admit, len(AKI_Scr.ONSETS_ENCOUNTERID.unique())))\n",
    "\n",
    "            #sub-requirement 3: at least 1 record on the AKI onset day\n",
    "            scr_on_onset = AKI_Scr[AKI_Scr.DAYS_BEFORE_ONSET == 0].groupby('ONSETS_ENCOUNTERID').count()\n",
    "            encounters_to_keep3 = scr_on_onset[scr_on_onset.SPECIMEN_DATE >= 1].index\n",
    "            AKI_Scr = AKI_Scr[AKI_Scr.ONSETS_ENCOUNTERID.isin(encounters_to_keep3)]\n",
    "\n",
    "            print('After Criteria 3 sub-req 3: at least 1 record on the AKI onset day, there are %s qualified records left!' \n",
    "                  %len(AKI_Scr.ONSETS_ENCOUNTERID.unique()))\n",
    "\n",
    "            #sub-requirement 4: total record count should not below the criteria\n",
    "            scr_rec_total = AKI_Scr.groupby('ONSETS_ENCOUNTERID').count()\n",
    "            n_records_req = int((1 - missing_percent_allowed) * time_interval_before_ONSET)\n",
    "            encounters_to_keep4 = scr_rec_total[scr_rec_total.SPECIMEN_DATE >= n_records_req].index\n",
    "            AKI_Scr = AKI_Scr[AKI_Scr.ONSETS_ENCOUNTERID.isin(encounters_to_keep4)]\n",
    "            print('After Criteria 3 sub-req 4: total record count should not below the criteria - %s, there are %s qualified records left!' \n",
    "                  %(n_records_req, len(AKI_Scr.ONSETS_ENCOUNTERID.unique())))\n",
    "            \n",
    "            #sub-requirement 5: max SCr should not excceed a certain number\n",
    "            AKI_Scr = AKI_Scr.groupby('ONSETS_ENCOUNTERID').filter(filter_groups)\n",
    "            print('After Criteria 3 sub-req 5: should not exceed max SCr, there are %s qualified records left!' \n",
    "                  %len(AKI_Scr.ONSETS_ENCOUNTERID.unique()))\n",
    "            records_num_df.loc['Patient not satisfying SCr trajectory requirements excluded', ct] = \\\n",
    "            len(AKI_Scr.ONSETS_ENCOUNTERID.unique())\n",
    "        \n",
    "        elif mode == 'AFTER_ONSET':\n",
    "            #here we only require time after onset but not limit window because we also want to analyse time window prior to discharge\n",
    "            AKI_Scr = AKI_Scr[AKI_Scr.DAYS_BEFORE_ONSET > 0]\n",
    "        elif mode == 'BEFORE_ADMIT':\n",
    "            #here we apply time window since we will only plot trajectory\n",
    "            AKI_Scr = AKI_Scr[(AKI_Scr.SPECIMEN_DATE < AKI_Scr.ADMIT_DATE) & \\\n",
    "                              (AKI_Scr.SPECIMEN_DATE >= AKI_Scr.ADMIT_DATE - pd.Timedelta(days=7))]\n",
    "        \n",
    "        AKI_SCR_dfs[ct] = AKI_Scr\n",
    "    \n",
    "    return AKI_SCR_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9cfdf-5708-44c5-ac55-74bbf473ce36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_dfs = read_AKI_LAB_SCR(ct_names, raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f27aad-aa5a-43c7-a360-4001ffdd4427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AKI_SCR_dfs_before_onset = merge_SCR_query_and_process(SCR_dfs, AKI_query_dfs, mode = 'BEFORE_ONSET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec69c33-6e03-41be-9e85-01f3e4687473",
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_SCR_dfs_after_onset = merge_SCR_query_and_process(SCR_dfs, AKI_query_dfs, mode = 'AFTER_ONSET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f5bce2-e699-4f6b-b1ab-d0a2efb6f620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AKI_SCR_dfs_before_admit = merge_SCR_query_and_process(SCR_dfs, AKI_query_dfs, mode = 'BEFORE_ADMIT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737520ee-c9d3-4400-9c6c-6effb339405d",
   "metadata": {},
   "source": [
    "# Merge All Data and Output to Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd358c70-6725-4206-b96c-64cc9688dff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to hold the concatenated result\n",
    "concat_SCR_df_before_onset = pd.DataFrame()\n",
    "\n",
    "# Loop through the dict of dataframes and concatenate\n",
    "for ct, AKI_Scr_before_onset in AKI_SCR_dfs_before_onset.items():\n",
    "    #previously there was no center name col, here we add it\n",
    "    if ct == 'KUMC_ORCALE':\n",
    "        AKI_Scr_before_onset['CENTER_NAME'] = 'KUMC'\n",
    "    else:\n",
    "        AKI_Scr_before_onset['CENTER_NAME'] = ct\n",
    "    concat_SCR_df_before_onset = pd.concat([concat_SCR_df_before_onset, \n",
    "                                            AKI_Scr_before_onset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d5f2a-a939-4e23-8d29-c01fea827ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_SCR_df_before_onset['ONSETS_ENCOUNTERID'] = concat_SCR_df_before_onset['ONSETS_ENCOUNTERID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b8418-ce1b-4b52-8240-ff6571efbc55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#here we drop these records becasue they are the only 2 patients that have the same onset_encounterID\n",
    "#And it will bring error in the following pipelines\n",
    "concat_SCR_df_before_onset['unique_col2_count'] = concat_SCR_df_before_onset.groupby('ONSETS_ENCOUNTERID')['CENTER_NAME'].transform('nunique')\n",
    "dup_result = concat_SCR_df_before_onset[concat_SCR_df_before_onset['unique_col2_count'] > 1]\n",
    "dup_result = list(dup_result.ONSETS_ENCOUNTERID.unique())\n",
    "concat_SCR_df_before_onset = \\\n",
    "concat_SCR_df_before_onset[~concat_SCR_df_before_onset.ONSETS_ENCOUNTERID.isin(dup_result)]\n",
    "concat_SCR_df_before_onset.drop('unique_col2_count', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090a1b7-3c72-4e9d-b10a-ca7add80ee1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dup_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446338d2-9379-401b-bd3b-a2825494aa57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(concat_SCR_df_before_onset.ONSETS_ENCOUNTERID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905ccb5-b4e1-4a95-a556-f439afa46e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ct_name in ct_names:\n",
    "    if ct_name == 'KUMC_ORCALE':\n",
    "        ct_name = 'KUMC'\n",
    "    unique_encounter_n = len(concat_SCR_df_before_onset[concat_SCR_df_before_onset.CENTER_NAME == ct_name].ONSETS_ENCOUNTERID.unique())\n",
    "    print(ct_name, unique_encounter_n)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b213f39-7f6a-4d39-9967-a25b41ac5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to hold the concatenated result\n",
    "concat_SCR_df_after_onset = pd.DataFrame()\n",
    "\n",
    "# Loop through the dict of dataframes and concatenate\n",
    "for ct, AKI_Scr_after_onset in AKI_SCR_dfs_after_onset.items():\n",
    "    #previously there was no center name col, here we add it\n",
    "    if ct == 'KUMC_ORCALE':\n",
    "        AKI_Scr_after_onset['CENTER_NAME'] = 'KUMC'\n",
    "    else:\n",
    "        AKI_Scr_after_onset['CENTER_NAME'] = ct\n",
    "    concat_SCR_df_after_onset = pd.concat([concat_SCR_df_after_onset, \n",
    "                                           AKI_Scr_after_onset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc5e05-c63e-47aa-ab28-8e2c13de6e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_SCR_df_after_onset['ONSETS_ENCOUNTERID'] = concat_SCR_df_after_onset['ONSETS_ENCOUNTERID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc03c8d-053b-4c65-a564-0d15f0334b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#here we filter out records that is not in before onset collection\n",
    "concat_SCR_df_after_onset_filtered = \\\n",
    "concat_SCR_df_after_onset[concat_SCR_df_after_onset.ONSETS_ENCOUNTERID.isin(concat_SCR_df_before_onset.ONSETS_ENCOUNTERID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856f35a-897e-4ffe-9547-92234000ffa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(concat_SCR_df_after_onset_filtered.ONSETS_ENCOUNTERID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2a186-5562-4b35-8d1c-5d928fc79cff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to hold the concatenated result\n",
    "concat_SCR_df_before_admit = pd.DataFrame()\n",
    "\n",
    "# Loop through the dict of dataframes and concatenate\n",
    "for ct, AKI_Scr_before_admit in AKI_SCR_dfs_before_admit.items():\n",
    "    #previously there was no center name col, here we add it\n",
    "    if ct == 'KUMC_ORCALE':\n",
    "        AKI_Scr_before_admit['CENTER_NAME'] = 'KUMC'\n",
    "    else:\n",
    "        AKI_Scr_before_admit['CENTER_NAME'] = ct\n",
    "    concat_SCR_df_before_admit = pd.concat([concat_SCR_df_before_admit, \n",
    "                                           AKI_Scr_before_admit], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc657cf8-e0f2-499e-a391-3fe62fa476aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_SCR_df_before_admit['ONSETS_ENCOUNTERID'] = concat_SCR_df_before_admit['ONSETS_ENCOUNTERID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e952fb-33ca-4f93-9b79-7c6a3efe9b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#here we filter out records that is not in before onset collection\n",
    "concat_SCR_df_before_admit_filtered = \\\n",
    "concat_SCR_df_before_admit[concat_SCR_df_before_admit.ONSETS_ENCOUNTERID.isin(concat_SCR_df_before_onset.ONSETS_ENCOUNTERID)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed8bf1b-f524-4f81-ac72-9d7e3a3ef611",
   "metadata": {},
   "source": [
    "# Save DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da474cd-fd88-47af-a290-675959d7a967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_SCR_df_before_onset.to_csv('/blue/yonghui.wu/lideyi/AKI_subphenotyping_project_v3/full_data/concat_SCR_data_before_onset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2074d5-734b-45f0-b816-4d4997a8f5a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_SCR_df_after_onset_filtered.to_csv('/blue/yonghui.wu/lideyi/AKI_subphenotyping_project_v3/full_data/concat_SCR_data_after_onset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603069f2-a9d7-4aba-8fd6-b5083382fcea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_SCR_df_before_admit_filtered.to_csv('/blue/yonghui.wu/lideyi/AKI_subphenotyping_project_v3/full_data/concat_SCR_data_before_admit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41140cea-8c65-4c3f-9092-89e7a9a8ee50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "records_num_df['Total'] = records_num_df.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61cecbd-ebf4-4a65-a5a9-5230cb56b763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_percentage(col):\n",
    "    total = col.iloc[0]  # first row (cluster total) is the total count\n",
    "    return col.map(lambda entry: f\"{entry}({(entry / total) * 100:.2f}%)\" if total != 0 else \"0(0.00%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee696eb-ba0b-4f9b-881e-2fea13744cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "records_num_df_penct = records_num_df.apply(add_percentage, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc085ea-d468-4cfd-9b80-2073260cf456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "records_num_df_penct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85090c4c-7532-41a7-bd6a-6cb2d5605fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "records_num_df_penct.to_csv('./Tables/Patient_Screening.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_CDM_PY",
   "language": "python",
   "name": "aki_cdm_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
