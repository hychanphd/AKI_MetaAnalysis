{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe554efa-da3a-4c6f-b113-7b79b3df2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This module create test train split or cross validation set for different columns filtering and oversampling strategy \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d10c5-b3e5-4789-a20e-fd777c7de2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.interpolate import BSpline, make_interp_spline, interp1d\n",
    "#import rpy2.robjects as robjects\n",
    "#ÃŸfrom rpy2.robjects.packages import importr\n",
    "import csv\n",
    "from dfply import *\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import logging\n",
    "import utils_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe42d5-93cd-4acb-a647-4c982ebb3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    site ='MCRI'\n",
    "    year=2013\n",
    "    datafolder = datafolder\n",
    "    home_directory = \"/home/hoyinchan/code/AKI_CDM_PY/\"\n",
    "    pred_end = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731b3ce-3bd9-4e59-9bf3-be71d3f5df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_smote(site, datafolder, stg='stg01', suffix='', returnflag=False, random_state=0):\n",
    "# site = 'MCRI'\n",
    "# stg='stg01'\n",
    "# suffix=''\n",
    "# returnflag=False\n",
    "# random_state=None\n",
    "    year=3000\n",
    "\n",
    "    print('Running pre_smote on site '+site+\":\"+str(year)+':'+stg, flush = True)\n",
    "    data = pd.read_pickle(datafolder+site+'/bt3pos'+suffix+'_'+site+'_'+stg+'_'+str(year)+'.pkl')\n",
    "\n",
    "    label = data['FLAG'] \n",
    "    data = data[data.columns[data.columns!='FLAG']]\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(data, label, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    if returnflag:\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    X_train.to_pickle(datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_nofs_raw'+suffix+'.pkl')\n",
    "    X_test.to_pickle( datafolder+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_nofs_raw'+suffix+'.pkl')    \n",
    "    y_train.to_pickle(datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_nofs_raw'+suffix+'.pkl')\n",
    "    y_test.to_pickle( datafolder+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_nofs_raw'+suffix+'.pkl')\n",
    "    \n",
    "    print('Finished pre_smote on site '+site+\":\"+str(year)+':'+stg, flush = True)    \n",
    "\n",
    "#    CKD Depreciated\n",
    "#    X_train_ckdg  = X_train[['EGFR','CKD_group']]\n",
    "#    X_train = X_train.drop(['EGFR','CKD_group'],axis=1)\n",
    "\n",
    "#    X_test_ckdg = X_test[['EGFR','CKD_group']]\n",
    "#    X_test = X_test.drop(['EGFR','CKD_group'],axis=1)    \n",
    "#    X_train_ckdg.to_pickle(datafolder+site+'/X_train_ckdg_'+site+'_'+str(year)+'_'+stg+'_nofs_raw'+suffix+'.pkl')\n",
    "#    X_test_ckdg.to_pickle( datafolder+site+'/X_test_ckdg_' +site+'_'+str(year)+'_'+stg+'_nofs_raw'+suffix+'.pkl')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383e8f9-91f9-465e-a7b0-71c606623bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smote(site, year, stg):    \n",
    "    print('Running smote on site '+site+\":\"+str(year)+':'+stg, flush = True)\n",
    "    \n",
    "    X_train = pd.read_pickle(datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+'_nofs_raw.pkl')\n",
    "    y_train = pd.read_pickle(datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+'_nofs_raw.pkl')\n",
    "    \n",
    "    # impute continuous value for SMOTE\n",
    "    imp_num = sklearn.impute.SimpleImputer()\n",
    "    imp_num.fit(X_train.select_dtypes(['Int64', 'Float64']))\n",
    "    X_train_imp = X_train.reset_index().combine_first(pd.DataFrame(imp_num.transform(X_train.select_dtypes(['int64', 'float64'])), columns=X_train.select_dtypes(['int64', 'float64']).columns)).drop('index',axis=1)\n",
    "    #cat_fea = [X_train_imp.columns.get_loc(c) for c in list(X_train_imp.select_dtypes('bool').columns)]\n",
    "\n",
    "    # SMOTE\n",
    "    sm = SMOTENC(categorical_features=X_train_imp.dtypes == 'bool', k_neighbors=5, n_jobs=23)\n",
    "    X_res, y_res = sm.fit_resample(X_train_imp, y_train)\n",
    "    \n",
    "    #Save tables\n",
    "    X_res.to_pickle(datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_nofs_sm.pkl')\n",
    "    y_res.to_pickle(datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_nofs_sm.pkl')\n",
    "\n",
    "    #Just copy\n",
    "    X_test = pd.read_pickle(datafolder+site+'/X_test_'+site+'_'+str(year)+'_'+stg+'_nofs_raw.pkl')\n",
    "    y_test = pd.read_pickle(datafolder+site+'/y_test_'+site+'_'+str(year)+'_'+stg+'_nofs_raw.pkl')\n",
    "    X_test.to_pickle(       datafolder+site+'/X_test_'+site+'_'+str(year)+'_'+stg+'_nofs_sm.pkl')\n",
    "    y_test.to_pickle(       datafolder+site+'/y_test_'+site+'_'+str(year)+'_'+stg+'_nofs_sm.pkl')\n",
    "    \n",
    "    print('Finished smote on site '+site+\":\"+str(year)+':'+stg, flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e7613-68fe-4595-8de8-1a4d15ea3256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def copy_minor(site, year, stg):\n",
    "    \n",
    "    print('Running copy_minor on site '+site+\":\"+str(year)+':'+stg, flush = True)\n",
    "    X_train = pd.read_pickle(datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_nofs_raw.pkl')\n",
    "    y_train = pd.read_pickle(datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_nofs_raw.pkl')   \n",
    "    \n",
    "    bt_data = X_train\n",
    "    bt_data.insert(0,'FLAG',y_train)\n",
    "    \n",
    "    countsflag = bt_data['FLAG'].value_counts()\n",
    "    ratio = math.floor(countsflag[0]/countsflag[1])\n",
    "    data1 = bt_data[bt_data['FLAG']==1]\n",
    "    data1 = pd.concat([data1]*ratio, axis=0, ignore_index=True)   \n",
    "    bt_data = pd.concat([data1, bt_data[bt_data['FLAG']==0]], axis=0, ignore_index=True)\n",
    "    countsflag2 = bt_data['FLAG'].value_counts()\n",
    "    ratio2 = countsflag2[0] - countsflag2[1]\n",
    "    data2 = bt_data[bt_data['FLAG']==1].sample(n=ratio2)\n",
    "    bt_data = pd.concat([data2, bt_data], axis=0, ignore_index=True)        \n",
    "\n",
    "    y_cp = bt_data['FLAG']\n",
    "    X_cp = bt_data[bt_data.columns[bt_data.columns!='FLAG']]\n",
    "\n",
    "    X_cp.to_pickle(datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_nofs_cp.pkl')\n",
    "    y_cp.to_pickle(datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_nofs_cp.pkl')\n",
    "\n",
    "    #Just copy\n",
    "    X_test = pd.read_pickle(datafolder+site+'/X_test_'+site+'_'+str(year)+'_'+stg+'_nofs_raw.pkl')\n",
    "    y_test = pd.read_pickle(datafolder+site+'/y_test_'+site+'_'+str(year)+'_'+stg+'_nofs_raw.pkl')\n",
    "    X_test.to_pickle(       datafolder+site+'/X_test_'+site+'_'+str(year)+'_'+stg+'_nofs_cp.pkl')\n",
    "    y_test.to_pickle(       datafolder+site+'/y_test_'+site+'_'+str(year)+'_'+stg+'_nofs_cp.pkl')    \n",
    "    \n",
    "    print('Finished copy_minor on site '+site+\":\"+str(year)+':'+stg, flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f0bd8-fce8-4e64-8be7-6ec8cceddc3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rm_scr_bun(X_train):\n",
    "    rm_key = ['2160-0','38483-4','14682-9','21232-4','35203-9','44784-7','59826-8',\n",
    "                  '16188-5','16189-3','59826-8','35591-7','50380-5','50381-3','35592-5',\n",
    "                  '44784-7','11041-1','51620-3','72271-0','11042-9','51619-5','35203-9','14682-9',\n",
    "                  '12966-8','12965-0','6299-2','59570-2','12964-3','49071-4','72270-2',\n",
    "                  '11065-0','3094-0','35234-4','14937-7',\n",
    "                  '48642-3','48643-1',\n",
    "                  '3097-3','44734-2']        \n",
    "    rm_col = [x for x in X_train.columns if 'LAB' in x and x.split(':')[2].split('(')[0] in rm_key]\n",
    "    return X_train.drop(rm_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cba465-20df-4a38-9c85-f78fc1369680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rm_lab(X_train):\n",
    "    rm_col = [x for x in X_train.columns if 'LAB' in x]\n",
    "    return X_train.drop(rm_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894fd72c-4d5b-4ed2-a000-8ab9745c7930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def only_med(X_train):\n",
    "    rm_col = [x for x in X_train.columns if 'MED' not in x]\n",
    "    return X_train.drop(rm_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de10d18-280b-423b-bf48-7602030bfe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def all_only_med(site, year, stg, oversample='raw', suffix=''):\n",
    "    print('Running cp_only_med on site '+site+\":\"+str(year)+':'+stg, flush = True)        \n",
    "    \n",
    "    X_train = pd.read_pickle( datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    X_train = only_med(X_train)\n",
    "    X_train.to_pickle(        datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_onlymed_'+oversample+suffix+'.pkl')\n",
    "\n",
    "    X_test = pd.read_pickle(  datafolder+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    X_test = only_med(X_test)\n",
    "    X_test.to_pickle(         datafolder+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_onlymed_'+oversample+suffix+'.pkl')\n",
    "        \n",
    "    #Just copy\n",
    "    y_train = pd.read_pickle( datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    y_train.to_pickle(        datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_onlymed_'+oversample+suffix+'.pkl')    \n",
    "    y_test = pd.read_pickle(  datafolder+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    y_test.to_pickle(         datafolder+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_onlymed_'+oversample+suffix+'.pkl')    \n",
    "    \n",
    "    print('Finished cp_rm_scr_bun on site '+site+\":\"+str(year)+':'+stg, flush = True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f0b0bf-246b-4049-b61d-48e4446d7fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def all_rm_lab(site, year, stg, oversample='raw', suffix=''):\n",
    "    print('Running cp_rm_lab on site '+site+\":\"+str(year)+':'+stg, flush = True)        \n",
    "    \n",
    "    X_train = pd.read_pickle( datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    X_train = rm_lab(X_train)\n",
    "    X_train.to_pickle(        datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_rmlab_'+oversample+suffix+'.pkl')\n",
    "\n",
    "    X_test = pd.read_pickle(  datafolder+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    X_test = rm_lab(X_test)\n",
    "    X_test.to_pickle(         datafolder+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_rmlab_'+oversample+suffix+'.pkl')\n",
    "        \n",
    "    #Just copy\n",
    "    y_train = pd.read_pickle( datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    y_train.to_pickle(        datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_rmlab_'+oversample+suffix+'.pkl')    \n",
    "    y_test = pd.read_pickle(  datafolder+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    y_test.to_pickle(         datafolder+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_rmlab_'+oversample+suffix+'.pkl')    \n",
    "    \n",
    "    print('Finished cp_rm_scr_bun on site '+site+\":\"+str(year)+':'+stg, flush = True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda9e40-cbbd-40a2-800d-4577c9aff733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_rm_scr_bun(site, year, stg, oversample, suffix=''):\n",
    "    print('Running cp_rm_scr_bun on site '+site+\":\"+str(year)+':'+stg, flush = True)        \n",
    "    \n",
    "    X_train = pd.read_pickle( datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    X_train = rm_scr_bun(X_train)\n",
    "    X_train.to_pickle(        datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_rmscrbun_'+oversample+suffix+'.pkl')\n",
    "\n",
    "    X_test = pd.read_pickle(  datafolder+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    X_test = rm_scr_bun(X_test)\n",
    "    X_test.to_pickle(         datafolder+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_rmscrbun_'+oversample+suffix+'.pkl')\n",
    "        \n",
    "    #Just copy\n",
    "    y_train = pd.read_pickle( datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    y_train.to_pickle(        datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_rmscrbun_'+oversample+suffix+'.pkl')    \n",
    "    y_test = pd.read_pickle(  datafolder+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_nofs_'    +oversample+suffix+'.pkl')\n",
    "    y_test.to_pickle(         datafolder+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_rmscrbun_'+oversample+suffix+'.pkl')    \n",
    "    \n",
    "    print('Finished cp_rm_scr_bun on site '+site+\":\"+str(year)+':'+stg, flush = True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182593fe-f1b1-4cde-9560-cb4ed13292e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_all_pre_catboost(configs_variables):\n",
    "    '''\n",
    "    This module create test train split for different columns filtering and oversampling strategy \n",
    "    '''\n",
    "\n",
    "    year = 3000\n",
    "#    configs_variables = utils_function.read_config(site)\n",
    "    site, datafolder, home_directory = utils_function.get_commons(configs_variables)\n",
    "    fs = configs_variables['fs']\n",
    "    stg = configs_variables['stg']\n",
    "    oversample = configs_variables['oversample']\n",
    "    drop_correlation_catboost = configs_variables['drop_correlation_catboost']\n",
    "    random_state = int(configs_variables['random_state'])\n",
    "    \n",
    "    #save raw data\n",
    "    try:\n",
    "        if drop_correlation_catboost:\n",
    "            pre_smote(site, datafolder, stg, 'nc', random_state=random_state)\n",
    "        else:\n",
    "            pre_smote(site, datafolder, stg, '', random_state=random_state)            \n",
    "    except Exception as e:\n",
    "        logging.basicConfig(filename='preboost.log', filemode='a')    \n",
    "        print('pre_smote ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n', flush = True)\n",
    "        logging.error('pre_smote ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n')\n",
    "        logging.shutdown()       \n",
    "\n",
    "\n",
    "    #generate copy data\n",
    "    # if oversample == 'cp':\n",
    "        # try:\n",
    "        #     copy_minor(site, year, stg)\n",
    "        # except Exception as e:\n",
    "        #     logging.basicConfig(filename='preboost.log', filemode='a')    \n",
    "        #     print('copy_minor ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n', flush = True)\n",
    "        #     logging.error('copy_minor ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n')\n",
    "        #     logging.shutdown()       \n",
    "\n",
    "\n",
    "    #generate smote\n",
    "    # if oversample == 'sm':    \n",
    "        # try:\n",
    "        # #smote(site, year, stg)    \n",
    "        # except Exception as e:\n",
    "        #     logging.basicConfig(filename='preboost.log', filemode='a')    \n",
    "        #     print('smote ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n', flush = True)\n",
    "        #     logging.error('smote ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n')\n",
    "        #     logging.shutdown()           \n",
    "\n",
    "    #generate rm_scr_bun version\n",
    "    if fs == 'rmscrbun':\n",
    "        try:\n",
    "            all_rm_scr_bun(site, year, stg, 'raw', suffix)\n",
    "            #smote_rm_scr_bun(site, year)\n",
    "        except Exception as e:\n",
    "            logging.basicConfig(filename='preboost.log', filemode='a')    \n",
    "            print('raw_rm_scr_bun ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n', flush = True)\n",
    "            logging.error('raw_rm_scr_bun ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n')\n",
    "            logging.shutdown()       \n",
    "\n",
    "    #generate rm_lab version\n",
    "    if fs == 'rmlab':    \n",
    "        try:\n",
    "            all_rm_lab(site, year, stg, 'raw', suffix)\n",
    "            #smote_rm_scr_bun(site, year)\n",
    "        except Exception as e:\n",
    "            logging.basicConfig(filename='preboost.log', filemode='a')    \n",
    "            print('all_rm_lab ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n', flush = True)\n",
    "            logging.error('all_rm_lab ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n')\n",
    "            logging.shutdown()       \n",
    "\n",
    "    #generate only_med version\n",
    "    if fs == 'onlymed':     \n",
    "        try:\n",
    "            all_only_med(site, year, stg, 'raw', suffix)\n",
    "            #smote_rm_scr_bun(site, year)\n",
    "        except Exception as e:\n",
    "            logging.basicConfig(filename='preboost.log', filemode='a')    \n",
    "            print('all_only_med ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n', flush = True)\n",
    "            logging.error('all_only_med ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n')\n",
    "            logging.shutdown()       \n",
    "        \n",
    "        \n",
    "    # try:\n",
    "    #     all_rm_scr_bun(site, year, stg, 'cp')\n",
    "    #     #smote_rm_scr_bun(site, year)\n",
    "    # except Exception as e:\n",
    "    #     logging.basicConfig(filename='preboost.log', filemode='a')    \n",
    "    #     print('cp_rm_scr_bun ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n', flush = True)\n",
    "    #     logging.error('raw_rm_scr_bun ERROR!!!!! '+site+\":\"+str(year)+'\\n+++++++++++++++++\\n'+str(e)+'\\n-------------------\\n')\n",
    "    #     logging.shutdown()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd641a-c833-4974-87c4-9f1f2f9f5833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_crossvalidate(configs_variables):\n",
    "    '''\n",
    "    This module create cross validation dataset\n",
    "    '''\n",
    "    year = 3000\n",
    "#    configs_variables = utils_function.read_config(site)\n",
    "    site, datafolder, home_directory = utils_function.get_commons(configs_variables)\n",
    "    fs = configs_variables['fs']\n",
    "    stg = configs_variables['stg']\n",
    "    oversample = configs_variables['oversample']\n",
    "    drop_correlation_catboost = configs_variables['drop_correlation_catboost']    \n",
    "    n_splits = int(configs_variables['n_splits'])\n",
    "    random_state = int(configs_variables['random_state'])\n",
    "    \n",
    "    if drop_correlation_catboost:\n",
    "        suffix = 'nc'\n",
    "    else:\n",
    "        suffix = ''   \n",
    "    \n",
    "    X_train = pd.read_pickle(datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+'.pkl')\n",
    "    X_test =  pd.read_pickle(datafolder+site+ '/X_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+'.pkl')\n",
    "    y_train = pd.read_pickle(datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+'.pkl')\n",
    "    y_test =  pd.read_pickle(datafolder+site+ '/y_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+'.pkl')           \n",
    "\n",
    "    X = pd.concat([X_train, X_test])\n",
    "    y = pd.concat([y_train, y_test])\n",
    "\n",
    "    skf = sklearn.model_selection.StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "    skf.get_n_splits(X, y)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        X_train_fold = X.iloc[train_index,:]\n",
    "        X_test_fold = X.iloc[test_index,:]\n",
    "        y_train_fold = y.iloc[train_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        pd.to_pickle(X_train_fold, datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+str(i)+'.pkl')\n",
    "        pd.to_pickle(X_test_fold, datafolder+site+'/X_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+str(i)+'.pkl')\n",
    "        pd.to_pickle(y_train_fold, datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+str(i)+'.pkl')\n",
    "        pd.to_pickle(y_test_fold, datafolder+site+'/y_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbb31c-c59f-4aec-bf5b-bdc3708c6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boosttrap(configs_variables, numberbt):\n",
    "    '''\n",
    "    This module read and return cross validation dataset\n",
    "    '''\n",
    "    year = 3000\n",
    "    site, datafolder, home_directory = utils_function.get_commons(configs_variables)\n",
    "    fs = configs_variables['fs']\n",
    "    stg = configs_variables['stg']\n",
    "    oversample = configs_variables['oversample']\n",
    "    drop_correlation_catboost = configs_variables['drop_correlation_catboost']    \n",
    "    if drop_correlation_catboost:\n",
    "        suffix = 'nc'\n",
    "    else:\n",
    "        suffix = '' \n",
    "\n",
    "    X_train = pd.read_pickle(datafolder+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+str(numberbt)+'.pkl')\n",
    "    X_test =  pd.read_pickle(datafolder+site+ '/X_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+str(numberbt)+'.pkl')\n",
    "    y_train = pd.read_pickle(datafolder+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+str(numberbt)+'.pkl')\n",
    "    y_test =  pd.read_pickle(datafolder+site+ '/y_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+str(numberbt)+'.pkl')           \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_CDM_PY",
   "language": "python",
   "name": "aki_cdm_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
