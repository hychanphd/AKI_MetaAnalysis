{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c1fe3-d350-41c0-b552-89ff3b6e9b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.interpolate import BSpline, make_interp_spline, interp1d\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import csv\n",
    "from dfply import *\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os.path import exists\n",
    "import logging\n",
    "import time\n",
    "from numpy import nan\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost\n",
    "from catboost import Pool, cv\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25dfb1-94e4-4992-a4fb-6407c4fa1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['MCRI', 'IUR', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'KUMC']\n",
    "tablename = ['onset', 'px', 'dx', 'lab', 'amed', 'vital', 'demo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c084d5-89b5-4444-bc4c-612839acc2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check existence of p0 Table\n",
    "parasites = [(site, table) for site in sites for table in tablename]\n",
    "def if_p0_table_exists(site, table):\n",
    "    if exists('data/'+site+'/p0_'+table+'_'+site+'.pkl'):\n",
    "        if pd.read_pickle('data/'+site+'/p0_'+table+'_'+site+'.pkl').empty:\n",
    "            print('p0 '+site+' '+table+' is empty')\n",
    "    else:\n",
    "        print('p0 '+site+' '+table+' is missing')\n",
    "        \n",
    "for site, table in parasites:\n",
    "    if_p0_table_exists(site,table)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82a783-88b0-499d-8f9c-53491fcf5a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = ['MCRI', 'IUR', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'KUMC', 'UTSW']\n",
    "tablename = ['onset', 'px', 'dx', 'labnum', 'labcat', 'amed', 'vital', 'demo', 'bt']\n",
    "#tablename = ['bt']\n",
    "\n",
    "#get years from site\n",
    "para_list = []\n",
    "for site in sites:\n",
    "    onset = pd.read_pickle('data/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique())    \n",
    "    para_list_local = [(site, year, table) for year in years for table in tablename]    \n",
    "    para_list.extend(para_list_local)\n",
    "\n",
    "#Check p1 and p2 table exists\n",
    "def if_p1_table_exists(site, table, year):\n",
    "    if exists('data/'+site+'/'+table+'_'+site+'_'+str(year)+'.pkl'):\n",
    "        df = read_pickle('data/'+site+'/'+table+'_'+site+'_'+str(year)+'.pkl')\n",
    "        if df.empty:\n",
    "            print('p1 '+site+' ' +str(year)+' '+table+' is empty')\n",
    "        elif 'DAYS_SINCE_ADMIT' in df.columns:\n",
    "            print('p1 '+site+' ' +str(year)+' '+table+' not pivoted')                         \n",
    "    else:\n",
    "        print('p1 '+site+' ' +str(year)+' '+table+' is missing')\n",
    "\n",
    "for site, year, table in para_list:\n",
    "    if_p1_table_exists(site,table,year)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4824ed6-3722-4b21-8624-8260e0ea4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge check\n",
    "sites = ['MCRI', 'IUR', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA']\n",
    "tablename = ['onset', 'px', 'dx', 'lab', 'amed', 'vital', 'demo']\n",
    "parasites = [(site, table) for site in sites for table in tablename]\n",
    "def p0_merge_check(site, table):    \n",
    "    onset = pd.read_pickle('data/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    newdfX = onset >> select('PATID', 'ENCOUNTERID') >> mutate(dummy = True) >> distinct()\n",
    "    data = pd.read_pickle('data/'+site+'/p0_'+table+'_'+site+'.pkl')\n",
    "    newdata = pd.merge(data, newdfX, left_on=['PATID', 'ENCOUNTERID'], right_on=['PATID', 'ENCOUNTERID'], how='left').fillna({'dummy': False})\n",
    "    if not all(newdata['dummy']):\n",
    "        print('p0 '+site+' '+table+' is inconsistent')\n",
    "        print(newdata['dummy'].value_counts())\n",
    "        \n",
    "for site, table in parasites:\n",
    "    p0_merge_check(site, table)\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875bfb4-1227-4896-b4f7-341bd559e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per year number of record\n",
    "sites = ['MCRI', 'IUR', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA']\n",
    "tablename = ['onset']\n",
    "#get years from site\n",
    "para_list = []\n",
    "for site in sites:\n",
    "    onset = pd.read_pickle('data/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique())    \n",
    "    para_list_local = [(site, year) for year in years for table in tablename]    \n",
    "    para_list.extend(para_list_local)\n",
    "\n",
    "def p1_site_sample_check(site, year):\n",
    "    newdf = pd.read_pickle('data/'+site+'/onset_'+site+'_'+str(year)+'.pkl')\n",
    "    if newdf.shape[0] < 100:\n",
    "        print(site+'-'+str(year))\n",
    "        print(newdf['FLAG'].value_counts())\n",
    "    \n",
    "for site, year in para_list:\n",
    "    p1_site_sample_check(site,year)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb3892-555e-48eb-b92d-b9d9990a8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data time range check\n",
    "#sites = ['MCRI', 'IUR', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA']\n",
    "sites = ['MCW']\n",
    "tablename = ['ONSETS', 'PX', 'DX', 'LAB', 'AMED', 'VITAL', 'DEMO']\n",
    "datafolder = '/home/hchan2/AKI/data/'\n",
    "\n",
    "def p0_year_check(site):\n",
    "    datatt = pd.read_csv(datafolder+site+'/raw/'+'AKI_ONSETS'+'.'+'csv')\n",
    "    yrs = pd.to_datetime(datatt['ADMIT_DATE'])\n",
    "    print([site, 'onset', min(yrs).year, max(yrs).year], flush=True)\n",
    "    datatt = pd.read_csv(datafolder+site+'/raw/'+'AKI_PX'+'.'+'csv')\n",
    "    yrs = pd.to_datetime(datatt['PX_DATE'])\n",
    "    print([site, 'px', min(yrs).year, max(yrs).year], flush=True)\n",
    "    datatt = pd.read_csv(datafolder+site+'/raw/'+'AKI_DX'+'.'+'csv')\n",
    "    yrs = pd.to_datetime(datatt['DX_DATE'])\n",
    "    print([site, 'dx', min(yrs).year, max(yrs).year], flush=True)\n",
    "    datatt = pd.read_csv(datafolder+site+'/raw/'+'AKI_VITAL'+'.'+'csv')\n",
    "    yrs = pd.to_datetime(datatt['MEASURE_DATE_TIME'])\n",
    "    print([site, 'vital', min(yrs).year, max(yrs).year], flush=True)\n",
    "    datatt = pd.read_csv(datafolder+site+'/raw/'+'AKI_AMED'+'.'+'csv')\n",
    "    yrs = pd.to_datetime(datatt['MEDADMIN_START_DATE_TIME'])\n",
    "    print([site, 'amed', min(yrs).year, max(yrs).year], flush=True)\n",
    "    datatt = pd.read_csv(datafolder+site+'/raw/'+'AKI_LAB'+'.'+'csv')\n",
    "    yrs = pd.to_datetime(datatt['LAB_ORDER_DATE'])\n",
    "    print([site, 'lab', min(yrs).year, max(yrs).year], flush=True)\n",
    "    \n",
    "for site in sites:\n",
    "    p0_year_check(site)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f1f44-a56c-4d67-8a44-43d130ad52be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['MCRI', 'IUR', 'MCW', 'UIOWA', 'UNMC', 'UofU', 'UPITT', 'KUMC']\n",
    "#sites = ['KUMC']\n",
    "def ATC_match_check(site, year):\n",
    "    datafolder = '/home/hchan2/AKI/data/'    \n",
    "    home_directory = \"/home/hchan2/AKI/AKI_Python/\"        \n",
    "    amed = pd.read_pickle('data/'+site+'/p0_amed_'+site+'.pkl')    \n",
    "    newdfX = pd.read_pickle('data/'+site+'/onset_'+site+'_'+str(year)+'.pkl')\n",
    "    newdfX = newdfX >> select('PATID', 'ENCOUNTERID') >> mutate(dummy = True) >> distinct()\n",
    "    amed = (pd.merge(amed, newdfX, left_on=['PATID', 'ENCOUNTERID'], right_on=['PATID', 'ENCOUNTERID'], how='left').fillna({'dummy': False}) >> mask(X.dummy) >> select(~X.dummy)).reset_index(drop=True)    \n",
    "    rxcui2atc_dtypes =  {\"Rxcui\": 'object', \"MEDADMIN_CODE\": 'object'}    \n",
    "    rxcui2atc = pd.read_csv(home_directory+\"data/\"+site+'/rxnorm_out_'+site+'.csv',sep=',', dtype=(rxcui2atc_dtypes)) >> rename(MEDADMIN_CODE=X.Rxcui)\n",
    "    rxcui2atc = rxcui2atc >> mutate(dummy = True) >> distinct()    \n",
    "    amed = pd.merge(amed, rxcui2atc, left_on=['MEDADMIN_CODE'], right_on=['MEDADMIN_CODE'], how='left').fillna({'dummy': False})\n",
    "    print(site+'-'+str(year))\n",
    "    print(amed['dummy'].value_counts())\n",
    "\n",
    "ban_list = [('UPITT', 2013), ('UPITT', 2012), ('MCW', 2011)] #Sample size too small\n",
    "para_list = []\n",
    "for site in sites:\n",
    "    onset = pd.read_pickle('data/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique())    \n",
    "    para_list_local = [(site, year) for year in years if not (site, year) in ban_list]   \n",
    "    para_list.extend(para_list_local)    \n",
    "    \n",
    "for site, year in para_list:\n",
    "    ATC_match_check(site, year)\n",
    "print('done')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a52c4-f850-4707-b626-dc6c7cee826f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = ['UMHC', 'UTHSCSA']\n",
    "def NDC_match_check(site, year):\n",
    "    datafolder = '/home/hchan2/AKI/data/'    \n",
    "    home_directory = \"/home/hchan2/AKI/AKI_Python/\"        \n",
    "    amed = pd.read_pickle('data/'+site+'/p0_amed_'+site+'.pkl')    \n",
    "    newdfX = pd.read_pickle('data/'+site+'/onset_'+site+'_'+str(year)+'.pkl')\n",
    "    newdfX = newdfX >> select('PATID', 'ENCOUNTERID') >> mutate(dummy = True) >> distinct()\n",
    "    amed = (pd.merge(amed, newdfX, left_on=['PATID', 'ENCOUNTERID'], right_on=['PATID', 'ENCOUNTERID'], how='left').fillna({'dummy': False}) >> mask(X.dummy) >> select(~X.dummy)).reset_index(drop=True)    \n",
    "    rxcui2atc_dtypes =  {\"ndc\": 'object', \"MEDADMIN_CODE\": 'object'}    \n",
    "    rxcui2atc = pd.read_csv(home_directory+\"data/\"+site+'/ndc_out_'+site+'.csv',sep=',', dtype=(rxcui2atc_dtypes)) >> rename(MEDADMIN_CODE=X.Rxcui)\n",
    "    rxcui2atc = rxcui2atc >> mutate(dummy = True) >> distinct()    \n",
    "    amed = pd.merge(amed, rxcui2atc, left_on=['MEDADMIN_CODE'], right_on=['MEDADMIN_CODE'], how='left').fillna({'dummy': False})\n",
    "    print(site+'-'+str(year))\n",
    "    print(amed['dummy'].value_counts())\n",
    "\n",
    "ban_list = [('UPITT', 2013), ('UPITT', 2012), ('MCW', 2011)] #Sample size too small\n",
    "para_list = []\n",
    "for site in sites:\n",
    "    onset = pd.read_pickle('data/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique())    \n",
    "    para_list_local = [(site, year) for year in years if not (site, year) in ban_list]   \n",
    "    para_list.extend(para_list_local)    \n",
    "    \n",
    "for site, year in para_list:\n",
    "    ATC_match_check(site, year)\n",
    "print('done')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12457a24-9096-4d75-9d8a-ba28c1dc1501",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = ['MCRI', 'IUR', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'KUMC']\n",
    "\n",
    "def icd10toicd09_match_check(site):\n",
    "    datafolder = '/home/hchan2/AKI/data/'    \n",
    "    home_directory = \"/home/hchan2/AKI/AKI_Python/\"        \n",
    "    dx = pd.read_pickle('data/'+site+'/p0_dx_'+site+'.pkl')\n",
    "    dx['DX_TYPE'] = dx['DX_TYPE'].where(dx['DX_TYPE'] != '9', '09')\n",
    "\n",
    "    print(site)\n",
    "    print('BEFORE')\n",
    "    print(dx['DX_TYPE'].value_counts())\n",
    "      \n",
    "    icd10toicd09 = pd.read_csv(home_directory+'2018_I10gem.csv',sep=',')    \n",
    "    icd10toicd09.columns = ['DX', 'DX09']\n",
    "    icd10toicd09 = icd10toicd09 >> mutate(dummy = True) >> distinct()    \n",
    "\n",
    "    dxt = dx >> mask(X.DX_TYPE == '10')\n",
    "    dxt['DX'] = dxt['DX'].map(lambda x: x.replace('.',''))    \n",
    "    dxt = pd.merge(dxt, icd10toicd09, left_on=['DX'], right_on=['DX'], how='left').fillna({'dummy': False})\n",
    "    print('MIDDLE')    \n",
    "    print(dxt['dummy'].value_counts())\n",
    "\n",
    "    dx4 = dx >> mask(X.DX_TYPE == '10')\n",
    "    dx4['DX'] = dx4['DX'].map(lambda x: x.replace('.',''))\n",
    "    dx4 = dx4 >> left_join(icd10toicd09, by='DX')\n",
    "    dx4['DX_TYPE'] = dx4['DX_TYPE'].where(dx4['DX09'].isnull(), '09')\n",
    "    dx4['DX'] = dx4['DX'].where(dx4['DX09'].isnull(), dx4['DX09'])\n",
    "    dx4 = dx4.drop('DX09', axis=1)\n",
    "    dx = pd.concat([dx >> mask(X.DX_TYPE != '10'), dx4], axis=0)\n",
    "    print('AFTER')\n",
    "    print(dx['DX_TYPE'].value_counts())\n",
    "    print(dx.isna().sum())\n",
    "            \n",
    "        \n",
    "for site in sites:\n",
    "    icd10toicd09_match_check(site)\n",
    "print('done')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47427256-f3e8-4fdb-b151-0f222afa7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['MCRI', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'KUMC', 'UTSW']\n",
    "#tablename = ['onset', 'px', 'dx', 'labnum', 'labcat', 'amed', 'vital', 'demo', 'bt']\n",
    "tablename = ['bt']\n",
    "\n",
    "#get years from site\n",
    "para_list = []\n",
    "for site in sites:\n",
    "    onset = pd.read_pickle('data/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique())    \n",
    "    para_list_local = [(site, year) for year in years]    \n",
    "    para_list.extend(para_list_local)\n",
    "\n",
    "#Check p1 and p2 table exists\n",
    "def check_bt_count(site, year):\n",
    "    print(site+':'+str(year))    \n",
    "    newdf = pd.read_pickle('data/'+site+'/onset_'+site+'_'+str(year)+'.pkl')\n",
    "    bt = pd.read_pickle('data/'+site+'/bt_'+site+'_'+str(year)+'.pkl')\n",
    "    newdf_c = newdf['FLAG'].value_counts()\n",
    "    bt_c = bt['FLAG'].value_counts()\n",
    "    if not newdf_c == bt_c:\n",
    "        print('newdf')\n",
    "        print(newdf_c)\n",
    "        print('bt')\n",
    "        print(bt_c)          \n",
    "    # if exists('data/'+site+'/'+table+'_'+site+'_'+str(year)+'.pkl'):\n",
    "    #     df = read_pickle('data/'+site+'/'+table+'_'+site+'_'+str(year)+'.pkl')\n",
    "    #     if df.empty:\n",
    "    #         print('p1 '+site+' ' +str(year)+' '+table+' is empty')\n",
    "    #     elif 'DAYS_SINCE_ADMIT' in df.columns:\n",
    "    #         print('p1 '+site+' ' +str(year)+' '+table+' not pivoted')                         \n",
    "    # else:\n",
    "    #     print('p1 '+site+' ' +str(year)+' '+table+' is missing')\n",
    "\n",
    "for site, year in para_list:\n",
    "    check_bt_count(site,year)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20000bd-bbb1-4a4b-82a4-5b000adca260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
