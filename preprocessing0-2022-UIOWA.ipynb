{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936897e1-0e30-4bc7-a43a-32b8e1870b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T23:37:41.318338Z",
     "start_time": "2023-12-03T23:37:39.324512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import python packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import importlib\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5828b-fe13-4187-b261-8daacd5bb6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_list = ['KUMC', 'UTSW', 'MCW', 'UofU', 'UIOWA', 'UMHC', 'UPITT', 'UTHSCSA', 'UNMC']\n",
    "ext_list = ['csv','dsv', 'dsv', 'csv', 'csv', 'csv', 'csv', 'csv', 'csv']\n",
    "sep_list = [',','|', '|', '|', ',', ',', ',', ',', '|']\n",
    "encoding_list = ['utf-8','utf-8','utf-8','utf-8','utf-8','utf-8', 'windows-1252', 'utf-8', 'utf-16'] \n",
    "ct = 4\n",
    "\n",
    "site = site_list[ct]\n",
    "ext = ext_list[ct]\n",
    "sep = sep_list[ct]\n",
    "encoding = encoding_list[ct]\n",
    "path = []\n",
    "\n",
    "if site != 'KUMC':\n",
    "    rawpath = '/blue/yonghui.wu/hoyinchan/Data/data2022raw/' + site + '/raw/'\n",
    "else: \n",
    "    rawpath = '/blue/yonghui.wu/hoyinchan/Data/data2022raw/' + site + '_ORCALE/raw/'\n",
    "path.append(rawpath)\n",
    "path.append('/blue/yonghui.wu/hoyinchan/Data/data2022/' + site + '/')\n",
    "pdata = '/blue/yonghui.wu/hoyinchan/Data/data2022/'+ site \n",
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794663d0-1a61-4c3b-8333-b6891c1626d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def try_load_csv(dataname, site, ext, sep, path, admit, datecol=None):\n",
    "    \n",
    "    datadtypes =  {\"RESULT_NUM\":float,  \"LAB_LOINC\": str, \"LAB_PX_TYPE\": str, \"RESULT_UNIT\": str, #lab\n",
    "               \"RESULT_QUAL\": str, \"RESULT_NUM\":float, \"SPECIMEN_SOURCE\": str, #lab\n",
    "               \"SEX\": pd.Categorical, \"RACE\": pd.Categorical, \"HISPANIC\": pd.Categorical, #demo, demodeath\n",
    "               \"DX\": str, \"DX_TYPE\": str, #DX\n",
    "               \"PX\": str, \"PX_TYPE\": str, #PX\n",
    "               \"MEDADMIN_TYPE\": str, \"MEDADMIN_CODE\": str, #AMED\n",
    "               \"RXNORM_CUI\": str, #PMED\n",
    "               \"NDC\": str, #DMED\n",
    "               \"SYSTOLIC\": float, \"DIASTOLIC\": float, \"ORIGINAL_BMI\": float, \"WT\": float, #VITAL_OLD\n",
    "               \"OBSCLIN_TYPE\": str, \"OBSCLIN_CODE\": str} #VITAL  \n",
    " \n",
    "    \n",
    "    print(f\"processing : {dataname}\")\n",
    "    filename = 'AKI_'+dataname.upper()\n",
    "    outfilename = f\"/p0_{dataname}_{site}.parquet\"    \n",
    "    \n",
    "    # Site Specific filenames\n",
    "    if 'UMHC' in path[0]:\n",
    "        filename = 'DEID_'+filename    \n",
    "    if 'UofU' in path[0]:\n",
    "        if dataname == 'vital':\n",
    "            filename = 'DEID_AKI_VITAL_OLD'\n",
    "        if  dataname == 'dx_current':\n",
    "            filename = 'DEID_AKI_DX_CURRENT_ADMIT_DATE'       \n",
    "    if 'UIOWA' in path[0]:\n",
    "        if dataname == 'lab':\n",
    "            sep = '|'\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(path[0] +  filename + '.' + ext, sep=sep, encoding=encoding, converters=datadtypes, engine='python', on_bad_lines='skip') \n",
    "    except Exception as e:\n",
    "        print(f\"{site}: {dataname} Failed to load from {path[1]} as well: {e}\")\n",
    "        \n",
    "    try:\n",
    "        # handle UofU column shifted\n",
    "        if 'UofU' in path[0] and dataname=='dx':\n",
    "            df = df.reset_index()\n",
    "            df = df.drop('RAW_DX_POA',axis=1)\n",
    "            df.columns = ['ONSETS_ENCOUNTERID', 'DIAGNOSISID', 'PATID', 'ENCOUNTERID',\n",
    "                   'ENC_TYPE', 'ADMIT_DATE', 'DX_DATE', 'PROVIDERID', 'DX', 'DX_TYPE',\n",
    "                   'DX_SOURCE', 'DX_ORIGIN', 'PDX', 'DX_POA', 'RAW_DX', 'RAW_DX_TYPE',\n",
    "                   'RAW_DX_SOURCE', 'RAW_PDX', 'RAW_DX_POA', 'DAYS_SINCE_ADMIT']\n",
    "            df['DX_DATE'] = df['ADMIT_DATE'] \n",
    "        \n",
    "    \n",
    "        if 'UofU' in path[0] and dataname=='demo':\n",
    "            df = df.reset_index()\n",
    "            df = df.drop(['RAW_HISPANIC', 'RAW_RACE', 'BIOBANK_FLAG'],axis=1)\n",
    "            df.columns = ['ONSETS_ENCOUNTERID', 'AGE', 'PATID',\n",
    "                   'BIRTH_DATE', 'BIRTH_TIME', 'SEX', 'SEXUAL_ORIENTATION',\n",
    "                   'GENDER_IDENTITY', 'HISPANIC', 'BIOBANK_FLAG', 'RACE',\n",
    "                   'PAT_PREF_LANGUAGE_SPOKEN', 'RAW_SEX', 'RAW_SEXUAL_ORIENTATION',\n",
    "                   'RAW_GENDER_IDENTITY', 'RAW_HISPANIC', 'RAW_RACE',\n",
    "                   'RAW_PAT_PREF_LANGUAGE_SPOKEN', 'DEATH_DATE', 'DDAYS_SINCE_ENC',\n",
    "                   'DEATH_DATE_IMPUTE', 'DEATH_SOURCE']   \n",
    "        \n",
    "        # Some site use admit date as dx date\n",
    "        if 'DX_DATE' in df.columns and df['DX_DATE'].isna().all():\n",
    "            df['DX_DATE'] = df['ADMIT_DATE']\n",
    "                \n",
    "        df.rename(columns = {'\\ufeff\"ONSETS_ENCOUNTERID\"': 'ONSETS_ENCOUNTERID'}, inplace = True) # to handle the BOM character in UTHSCSA\n",
    "        df.columns = df.columns.str.upper()\n",
    "        df.columns = df.columns.str.replace('\"+PD.DATE_SHIFT\"','').str.replace('AKI.','') # To handle the starnge date name in KUMC\n",
    "\n",
    "        df['ONSETS_ENCOUNTERID'] = df['ONSETS_ENCOUNTERID'].astype(str)\n",
    "        df['PATID'] = df['PATID'].astype(str)\n",
    "        \n",
    "        # if not onset\n",
    "        if admit is not None:\n",
    "            df[\"ENCOUNTERID\"] = df[\"ONSETS_ENCOUNTERID\"]   \n",
    "            df = df.drop('ADMIT_DATE', axis=1, errors='ignore')\n",
    "            df = admit[[\"PATID\",\"ENCOUNTERID\", 'ADMIT_DATE']].merge(df, on = [\"PATID\",\"ENCOUNTERID\"], how = \"inner\")\n",
    "\n",
    "            # recalculate DAYS_SINCE_ADMIT using day as unit\n",
    "            if datecol is not None:\n",
    "                df[datecol] = pd.to_datetime(pd.to_datetime(df[datecol]).dt.date)\n",
    "                df['DAYS_SINCE_ADMIT'] = (df[datecol]-df['ADMIT_DATE']).dt.days\n",
    "                df = df.drop('ADMIT_DATE',axis=1)\n",
    "        \n",
    "        # Convert dataype\n",
    "        filtered_datadtypes = {key: datadtypes[key] for key in datadtypes if key in df.columns}\n",
    "        df = df.astype(filtered_datadtypes)            \n",
    "            \n",
    "        \n",
    "        if dataname == 'onsets':\n",
    "            return df\n",
    "        else:\n",
    "            df.to_parquet(pdata+outfilename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print (f\"{site}: {dataname} failed at postprocessing: {e}\")\n",
    "#        raise Exception(f\"{site}: {dataname} failed at postprocessing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166cea5c-afcd-4f73-aaaf-70af9b9e5d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "admit = pd.read_pickle(pdata+'/p0_onset_'+site+'.pkl')\n",
    "admit['PATID'] = admit['PATID'].astype(str)\n",
    "admit['ENCOUNTERID'] = admit['ENCOUNTERID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba3e56-22c8-4557-8f94-a6b77213d9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try_load_csv('amed', site, ext, sep, path, admit, datecol='MEDADMIN_START_DATE')\n",
    "# try_load_csv('demo', site, ext, sep, path, admit, datecol='DEATH_DATE')\n",
    "# try_load_csv('demo_death', site, ext, sep, path, admit, datecol='DEATH_DATE')\n",
    "try_load_csv('dmed', site, ext, sep, path, admit, datecol='DISPENSE_DATE')\n",
    "# try_load_csv('dx', site, ext, sep, path, admit, datecol='DX_DATE')\n",
    "# try_load_csv('dx_current', site, ext, sep, path, admit, datecol='DX_DATE')\n",
    "# try_load_csv('lab_scr', site, ext, sep, path, admit, datecol='SPECIMEN_DATE')\n",
    "try_load_csv('pmed', site, ext, sep, path, admit, datecol='RX_START_DATE')\n",
    "# try_load_csv('px', site, ext, sep, path, admit, datecol='PX_DATE')\n",
    "# try_load_csv('vital_old', site, ext, sep, path, admit, datecol='MEASURE_DATE')\n",
    "# try_load_csv('vital', site, ext, sep, path, admit, datecol='OBSCLIN_START_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ef3f9-15c6-4f01-ae61-c644e621a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try_load_csv('lab', site, ext, sep, path, admit, datecol='SPECIMEN_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359afcf3-96de-46ae-a61a-931133135439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "sound_file = 'beep-11.wav'\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d2b89-906b-4ca8-bcd3-e228aebc4e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_PM_TEMPORAL_MOEA",
   "language": "python",
   "name": "aki_pm_temporal_moea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
