{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618a70f-a558-41f6-a0fc-669b07eab6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.interpolate import BSpline, make_interp_spline, interp1d\n",
    "#import rpy2.robjects as robjects\n",
    "#from rpy2.robjects.packages import importr\n",
    "import csv\n",
    "from dfply import *\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import os\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import pickle\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47225a1-5b90-4285-84f0-d10efc989caa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect(stg='', model='',site = '', year='', oversample='', fs='', rmcol='005', return_result=False):\n",
    "    print('Running collect on all site', flush = True)\n",
    "    \n",
    "    #Get all shap result files\n",
    "    files = []\n",
    "    start_dir = os.getcwd()\n",
    "    pattern   = \"shapdata_*\"\n",
    "    for dir,_,_ in os.walk(start_dir):\n",
    "        files.extend(glob(os.path.join(dir,pattern))) \n",
    "\n",
    "    files = [x for x in files if model in x and stg in x and site in x and str(year) in x and oversample in x and fs in x and rmcol in x and not ('drop' in x) and not ('BACKUP' in x)]\n",
    "    \n",
    "    #Read all into dataframe\n",
    "    shap_tables = []\n",
    "    for file in files:\n",
    "        print(file)        \n",
    "        shap_tables.append(pd.read_pickle(file))\n",
    "\n",
    "    #concatanate\n",
    "    result = pd.concat(shap_tables, ignore_index=True)\n",
    "\n",
    "    if return_result:\n",
    "        return result\n",
    "    \n",
    "    #save to file\n",
    "    result.to_pickle('result.pkl')\n",
    "    result.to_csv('result.csv', index=False)\n",
    "\n",
    "    print('Finished collect on all site', flush = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb7243f-793b-453a-87cc-409c421cee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_strp(filename, cat=True):\n",
    "    result = pd.read_pickle(filename)\n",
    "    if cat:\n",
    "        result = result.loc[:,['fval', 'mean_val', 'se_val', 'Feature', 'Importances', 'rank', 'site', 'year', 'stg', 'fs', 'oversample', 'model', 'rmcol', 'auc', 'isCategorical']]\n",
    "    else:\n",
    "#        result = result.loc[:,['fval', 'mean_val', 'se_val', 'Feature', 'Importances', 'rank', 'site', 'year', 'stg', 'fs', 'oversample', 'model', 'rmcol', 'auc', 'isCategorical']]        \n",
    "        pass\n",
    "    result.to_pickle('result_strp.pkl')\n",
    "    result = result.drop(['rank', 'stg', 'rmcol', 'model'],axis=1)\n",
    "    result.to_pickle('result_strp3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48c742-ecab-45a2-9c90-a266a0c0fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_split(model, stg='stg01', site = '', year='', oversample='raw', fs='rmscrbun', rmcol='005', return_result=False):\n",
    "    t = collect(stg=stg, model=model,site =site, year=year, oversample=oversample, fs=fs, rmcol='005', return_result=True)\n",
    "    if return_result:\n",
    "        return t\n",
    "    else:\n",
    "        filestring = ('resultsplit_'+model+\"_\"+stg+\"_\"+site+\"_\"+year+\"_\"+fs+\"_\"+oversample+\"_\"+rmcol+'.pkl').replace(\"_.pkl\", \".pkl\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\")   \n",
    "        print(filestring)\n",
    "        t.to_pickle(filestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c349ae-f289-4ec1-9e65-3921ff82e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEID(model, stg='stg01', site = '', year='', oversample='raw', fs='rmscrbun', rmcol='005', return_result=False):\n",
    "#    shap_data = pd.read_pickle('result.pkl')\n",
    "    result_split(model, stg, site, year, oversample, fs, rmcol, return_result=False)\n",
    "    filestring = ('resultsplit_'+model+\"_\"+stg+\"_\"+site+\"_\"+year+\"_\"+fs+\"_\"+oversample+\"_\"+rmcol+'.pkl').replace(\"_.pkl\", \".pkl\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\")   \n",
    "    shap_data = pd.read_pickle(filestring)\n",
    "    mask1 = shap_data['Feature'] != 'AGE'\n",
    "    mask2 = shap_data['fval'] < 90\n",
    "    shap_data = shap_data.loc[mask1 | mask2]\n",
    "    #save to file\n",
    "    shap_data.to_pickle('DEID_'+filestring)\n",
    "#    shap_data.to_pickle('DEID_result.pkl')\n",
    "#    shap_data.to_csv('DEID_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fdc5e-1615-4452-ad90-5ba2f3f1bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_bt(stg='', fs='', oversample='', model_type='', numberbt=10, suffix='', return_result=False, site = '', year = '', rmcol=''):\n",
    "\n",
    "    files = []\n",
    "    start_dir = os.getcwd()\n",
    "    pattern   = \"boosttrap_*\"\n",
    "    for dir,_,_ in os.walk(start_dir):\n",
    "        files.extend(glob(os.path.join(dir,pattern))) \n",
    "\n",
    "    files = [x for x in files if model_type in x and stg in x and site in x and str(year) in x and oversample in x and fs in x and rmcol in x and not ('drop' in x) and not ('BACKUP' in x)]\n",
    "    \n",
    "    shap_tables = []\n",
    "    for file in files:\n",
    "        print(file)        \n",
    "        with open(file, 'rb') as f:\n",
    "            x = pickle.load(f)\n",
    "            shap_tables.append(pd.read_pickle(file))\n",
    "        \n",
    "    #concatanate\n",
    "    result = pd.DataFrame(shap_tables, columns =['site', 'year', 'stg', 'fs', 'oversample', 'model', 'numberbt', 'modelobj', 'roc', 'cm'])\n",
    "\n",
    "    if return_result:\n",
    "        return result\n",
    "    \n",
    "    result.to_pickle('result_boosttrap.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400881b-4ab6-4c99-8ee4-203c0c5bb907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
