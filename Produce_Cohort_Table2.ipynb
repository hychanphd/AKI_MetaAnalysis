{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4cfce-cea5-47e2-8b7b-00fd57a48da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from ipynb.fs.full.slackbot import ping_slack\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.interpolate import BSpline, make_interp_spline, interp1d\n",
    "#import rpy2.robjects as robjects\n",
    "#from rpy2.robjects.packages import importr\n",
    "import csv\n",
    "from dfply import *\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os.path import exists\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import utils_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e533239e-a610-44ad-925e-6e2d09917b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d29d5-c71e-47cc-a25b-df5c38e1f61c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_list = ['KUMC', 'UTSW', 'MCW', 'UofU', 'UIOWA', 'UMHC', 'UPITT', 'UTHSCSA', 'UNMC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a7ae0-2df1-4d60-9154-37fde82dabe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site='KUMC'\n",
    "year=2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ace353-e345-4d3e-b9e5-ba5a4f234c89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cohort_table_2(site):\n",
    "\n",
    "    configs_variables = utils_function.read_config(site)\n",
    "    datafolder = configs_variables['datafolder']\n",
    "    home_directory = configs_variables['home_directory']  \n",
    "    \n",
    "    onset = pd.read_parquet(datafolder+site+'/p0_onset_'+site+'.parquet')        \n",
    "\n",
    "    def count_AKI(onset, new_name, cohort_table=None):\n",
    "        cohort_table2 = onset[['ENCOUNTERID', 'AKI_STAGE']].groupby('AKI_STAGE').count()\n",
    "        cohort_table2.rename(columns={'ENCOUNTERID': new_name}, inplace=True)\n",
    "        # Add a row for the total of stages 1.0, 2.0, and 3.0\n",
    "        total = cohort_table2.loc[1.0:3.0].sum()\n",
    "        cohort_table2.loc['Total_AKI'] = total  \n",
    "        cohort_table2.loc['Total'] = onset.shape[0]\n",
    "        if cohort_table is not None:\n",
    "            cohort_table2 = pd.concat([cohort_table, cohort_table2], axis=1)\n",
    "        return cohort_table2\n",
    "\n",
    "    cohort_table = count_AKI(onset, 'Raw_count')\n",
    "\n",
    "    onset= onset[onset['SINCE_ADMIT']!=0]\n",
    "    cohort_table2 = count_AKI(onset, 'drop_first_day_encounter', cohort_table)\n",
    "\n",
    "    covid = pd.read_parquet(datafolder+site+f\"/p0_covid_status_{site}.parquet\")\n",
    "    covid = covid.drop_duplicates()\n",
    "    covid_false = covid[covid['BCCOVID']]\n",
    "    onset = onset.merge(covid_false, on = ['PATID','ENCOUNTERID'],how='inner')\n",
    "    cohort_table3 = count_AKI(onset, 'drop_covid', cohort_table2)\n",
    "\n",
    "    data = pd.read_pickle(datafolder+site+'/bt3pos'+''+'_'+site+'_'+'stg01'+'_'+str(3000)+'.pkl')\n",
    "    cohort_table3.loc['Total_AKI', 'FLAG_sum'] = data['FLAG'].sum()\n",
    "    # Add the total of data[data['FLAG'] == 0]['FLAG'].sum() to row 0.0\n",
    "    cohort_table3.loc[0.0, 'FLAG_sum'] = (data['FLAG'] == 0).sum()\n",
    "    cohort_table3.loc['Total', 'FLAG_sum'] = data.shape[0]\n",
    "    \n",
    "    stg = configs_variables['stg']\n",
    "    fs = configs_variables['fs']\n",
    "    oversample = configs_variables['oversample']\n",
    "    model_type = configs_variables['model_type']\n",
    "    drop_correlation_catboost = configs_variables['drop_correlation_catboost']\n",
    "    if drop_correlation_catboost:\n",
    "        suffix='nc'\n",
    "    else:\n",
    "        suffix= ''\n",
    "    y_train = pd.read_pickle(datafolder+site+'/y_train_'+site+'_'+str(3000)+'_'+stg+'_'+fs+'_'+oversample+suffix+'.pkl')\n",
    "    y_test =  pd.read_pickle(datafolder+site+ '/y_test_'+site+'_'+str(3000)+'_'+stg+'_'+fs+'_'+oversample+suffix+'.pkl')\n",
    "    \n",
    "    cohort_table3.loc['Total_AKI', 'y_train'] = y_train.sum()\n",
    "    # Add the total of data[data['FLAG'] == 0]['FLAG'].sum() to row 0.0\n",
    "    cohort_table3.loc[0.0, 'y_train'] = (y_train == 0).sum()\n",
    "    cohort_table3.loc['Total', 'y_train'] = y_train.shape[0]\n",
    "        \n",
    "    cohort_table3.loc['Total_AKI', 'y_test'] = y_test.sum()\n",
    "    # Add the total of data[data['FLAG'] == 0]['FLAG'].sum() to row 0.0\n",
    "    cohort_table3.loc[0.0, 'y_test'] = (y_test == 0).sum()\n",
    "    cohort_table3.loc['Total', 'y_test'] = y_test.shape[0]\n",
    "        \n",
    "    \n",
    "    return cohort_table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e04d9-2c3e-4adb-b03d-7846493dabd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pkls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bac17-9bed-4170-89ef-c8d1001575c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95859a2e-ac65-4a99-8b5a-5cfc23fb6f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "pkl_files = [\"/blue/yonghui.wu/hoyinchan/Data/data2022/UofU/dx00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UofU/cohort_table00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/vital_UMHC_2037.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/vital_UMHC_2031.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/demo_UMHC_2033.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/vital_UMHC_2035.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/onset_UMHC_2030.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/demo_UMHC_2030.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/vital_UMHC_2036.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/dx_UMHC_2034.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/demo_UMHC_2036.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/onset_UMHC_2031.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/dx_UMHC_2035.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/vital_UMHC_2032.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/onset_UMHC_2037.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/demo_UMHC_2035.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/vital_UMHC_1989.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/demo_UMHC_2037.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/onset_UMHC_2034.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/vital_UMHC_2034.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/onset_UMHC_2036.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/onset_UMHC_2033.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/vital_UMHC_2033.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/demo_UMHC_2031.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/onset_UMHC_1989.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/demo_UMHC_2032.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/onset_UMHC_2035.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/demo_UMHC_2034.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/cohort_table00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/onset_UMHC_2032.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UMHC/demo_UMHC_1989.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/KUMC/cohort_table00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UIOWA/cohort_table00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UTSW/cohort_table00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/meltcorrallcount_0.8.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/MCW/demo_MCW_2011.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/MCW/labcat_MCW_2011.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/MCW/onset_MCW_2011.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/MCW/px_MCW_2011.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/MCW/dx_MCW_2011.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/MCW/vital_MCW_2011.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/MCW/amed_MCW_2011.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/MCW/cohort_table00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UNMC/cohort_table00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UPITT/labcat_UPITT_2012.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UPITT/amed_UPITT_2009.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UPITT/labnum_UPITT_2012.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UPITT/onset_UPITT_2012.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UPITT/amed_UPITT_2012.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UPITT/vital_UPITT_2009.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UPITT/vital_UPITT_2012.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UPITT/cohort_table00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UPITT/demo_UPITT_2012.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UTHSCSA/amed_UTHSCSA_2009.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UTHSCSA/df_rrt00.pkl\",\"/blue/yonghui.wu/hoyinchan/Data/data2022/UTHSCSA/cohort_table00.pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0994e4d-d149-4122-97f9-f3185025545e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "match = re.search(r'/data(\\d+)/([^/]+)/', pkl_files[2])\n",
    "match.group(1)\n",
    "match.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513c0eb-a649-4a12-be24-03f28ae5a36d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datafolder = '/blue/yonghui.wu/hoyinchan/Data/data2022/'\n",
    "\n",
    "for file in pkl_files:\n",
    "    # Extract site and year using regex\n",
    "    match = re.search(r'[a-z]+_([A-Z]+)_(\\d+)\\.pkl', file)   \n",
    "    if match:\n",
    "        year = match.group(1)\n",
    "        site = match.group(2)\n",
    "        print(file, year, site)\n",
    "        \n",
    "        try:\n",
    "            # Read the original pickle file\n",
    "            df = pd.read_pickle(file)\n",
    "            \n",
    "            # Define the output file path\n",
    "            output_folder = os.path.join(datafolder, year)\n",
    "            output_file = os.path.join(output_folder, f'onset_{year}_{site}.pkl')\n",
    "            \n",
    "            \n",
    "            # Create the output folder if it doesn't exist\n",
    "#            os.makedirs(output_folder, exist_ok=True)\n",
    "            df2 = pd.read_pickle(output_file)\n",
    "            # Save the DataFrame to the new file\n",
    "#            df.to_pickle(output_file)\n",
    "            \n",
    "            # Output the shape\n",
    "            print(f'{file}:{df.shape} -> {output_file}:{df2.shape}')\n",
    "        except Exception as e:\n",
    "            print(f'{file}: Failed to process ({e})')\n",
    "    else:\n",
    "        print(f'{file}: Failed to extract site and year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515a323-42d9-49b6-90b1-9f29fcae19f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "onset = pd.read_parquet(datafolder+site+'/p0_onset_'+site+'.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1d2a8-8489-43dd-a841-e9e5d7da8010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47c12596-6159-48e7-a7d0-c2af649f1468",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Flow Chart for baseline estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e3d3a3-377e-4460-b20b-7e66c3814a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flow_chart_dict = {'Total Encounters': 2034996,\n",
    " 'Total Patients': 1121851,\n",
    " 'Enc. with 1w SCr': 547952,\n",
    " 'Enc. without 1w SCr': 1487044,\n",
    " 'Enc. with 1y SCr': 895473,\n",
    " 'Enc. without 1y SCr': 591571,\n",
    " 'Non-CKD Enc. without 1y SCr': 578293,\n",
    " 'CKD Enc. without 1y SCr': 13278,\n",
    " 'Total Onset Enc.:': 414622,\n",
    " 'Total Onset Patients:': 315950,\n",
    " 'AKI1 Enc.': 270999,\n",
    " 'AKI2 Enc.': 88052,\n",
    " 'AKI3 Enc.': 55571}\n",
    "\n",
    "total_encounters = flow_chart_dict['Total Encounters']\n",
    "percentage_dict = {\n",
    "    key: np.round((value / total_encounters * 100),1) if isinstance(value, (int, float)) else value\n",
    "    for key, value in flow_chart_dict.items()\n",
    "}\n",
    "percentage_dict['Total Encounters']=100\n",
    "\n",
    "import schemdraw\n",
    "from schemdraw import flow\n",
    "\n",
    "arl = 2\n",
    "with schemdraw.Drawing() as d:\n",
    "    d.config(fontsize=14, unit=0.5)\n",
    "    # Start terminal\n",
    "    d += flow.Terminal().label('Estimate SCr baseline').fill('#2296dd')\n",
    "    # Arrow to decision\n",
    "    d += flow.Arrow().length(arl).label(f\"Encounter number\\nn={flow_chart_dict['Total Encounters']:,} ({percentage_dict['Total Encounters']}%)\")\n",
    "\n",
    "    # Decision box\n",
    "    decision = flow.Decision(E='Yes', S='No', w=5, h=3).label('SCr\\nwithin 7 days prior\\nto Admission?').fill('#EEE811')\n",
    "    d += decision  # Add the decision to the drawing    \n",
    "    # Arrow and square on east\n",
    "    d += flow.Arrow().right().at(decision.E).length(arl*2.5).label(f\"n={flow_chart_dict['Enc. with 1w SCr']:,} ({percentage_dict['Enc. with 1w SCr']}%)\", loc='bottom')\n",
    "    d += flow.Process(w=7.5, h=2).label('min(most recent SCr records\\nwith in 7 days prior to admission,\\nadmission 24h SCr value)').fill('#48b780')    \n",
    "    # Arrow and square on south\n",
    "    d += flow.Arrow().down().at(decision.S).length(arl).label(f\"n={flow_chart_dict['Enc. without 1w SCr']:,} ({percentage_dict['Enc. without 1w SCr']}%)\")\n",
    "\n",
    "    # Decision box\n",
    "    decision = flow.Decision(E='Yes', S='No', w=5, h=3).label('SCr\\n7-365 days prior to\\nAdmission?').fill('#EEE811')\n",
    "    d += decision  # Add the decision to the drawing    \n",
    "    # Arrow and square on east\n",
    "    d += flow.Arrow().right().at(decision.E).length(arl*2.5).label(f\"n={flow_chart_dict['Enc. with 1y SCr']:,} ({percentage_dict['Enc. with 1y SCr']}%)\", loc='bottom')\n",
    "    d += flow.Process(w=7.5, h=2).label('min(mean(most recent SCr records\\nwith in 7 days prior to admission),\\nadmission 24h SCr value)').fill('#48b780')    \n",
    "    # Arrow and square on south\n",
    "    d += flow.Arrow().down().at(decision.S).length(arl).label(f\"n={flow_chart_dict['Enc. without 1y SCr']:,} ({percentage_dict['Enc. without 1y SCr']}%)\")\n",
    "\n",
    "    # Decision box\n",
    "    decision = flow.Decision(E='No', S='Yes', w=5, h=3).label('CKD History?').fill('#EEE811')\n",
    "    d += decision  # Add the decision to the drawing    \n",
    "    # Arrow and square on east\n",
    "    d += flow.Arrow().right().at(decision.E).length(arl*2.5).fill('#EEE811').label(f\"n={flow_chart_dict['Non-CKD Enc. without 1y SCr']:,} ({percentage_dict['Non-CKD Enc. without 1y SCr']}%)\", loc='bottom')\n",
    "    d += flow.Process(w=7.5, h=2).label('minSCr estimated by MDRD\\nwith 75 mL/min/1.73m\\u00b2 eGFR,\\nadmission 24h SCr value)').fill('#48b780')    \n",
    "    # Arrow and square on south\n",
    "    d += flow.Arrow().down().at(decision.S).length(arl).label(f\"n={flow_chart_dict['CKD Enc. without 1y SCr']:,} ({percentage_dict['CKD Enc. without 1y SCr']}%)\")\n",
    "    \n",
    "    d += flow.Process(w=7, h=2.5).label('Drop encounters with CKD\\nhistory if no SCr\\nmeasurements can be found\\nfrom the last year.').fill('#48b780')\n",
    "    \n",
    "    # Show the drawing\n",
    "    d.draw()\n",
    "    d.save('scrbaseline.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da848d98-8b1d-4d54-8624-28347a317546",
   "metadata": {},
   "source": [
    "## Feature counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0a122-0d4e-48f6-ad2a-15b627da0aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utils_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sites = ['UTHSCSA', 'UTSW', 'MCW', 'UofU', 'UIOWA', 'UMHC', 'UNMC', 'KUMC', 'UPITT']\n",
    "configs_variables_list = [utils_function.read_config(site) for site in sites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52526d36-5673-417e-89a6-eb7044461b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get before and after drop nan\n",
    "all_columns_pre = dict()\n",
    "all_columns_drop_nan = dict()\n",
    "\n",
    "for configs_variables in configs_variables_list:\n",
    "    \n",
    "    site, datafolder, home_directory = utils_function.get_commons(configs_variables)    \n",
    "    \n",
    "    print(site)\n",
    "\n",
    "    stg = configs_variables['stg']\n",
    "    threshold = float(configs_variables['threshold_for_too_much_nan'])\n",
    "\n",
    "    onset = pd.read_parquet(configs_variables['datafolder']+configs_variables['site']+'/p0_onset_'+configs_variables['site']+'.parquet')\n",
    "    years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique())    \n",
    "    bt_list = list()\n",
    "\n",
    "    columns_agg = list()\n",
    "    \n",
    "    for year in years:\n",
    "        # try:\n",
    "        data = pd.read_pickle(datafolder+site+'/bt3_'+site+'_'+str(year)+'.pkl')\n",
    "        columns_agg.extend(list(data.columns))\n",
    "    \n",
    "    bt_all = pd.read_pickle(datafolder+site+'/bt3pos_'+site+'_'+stg+'_3000.pkl')\n",
    "    \n",
    "    all_columns_pre[site] = np.unique(columns_agg)\n",
    "    all_columns_drop_nan[site] = list(bt_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09160ef-5f11-41ec-9f18-58eabe8c9e55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_of_lengths = {key: len(value) for key, value in all_columns_drop_nan.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2872be-816d-4e27-86e6-b24b581a69e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_of_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5e68e-f45a-4beb-80a8-66322ce811a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_key = {3:'MCW', 4:'UIOWA', 5:'UMHC', 6:'UNMC', 9:'UofU', 8:'UTHSCSA', 2:'KUMC', 1:'UTSW', 7:'UPITT'}\n",
    "reversed_site_key = {v: k for k, v in site_key.items()}\n",
    "updated_dict = {reversed_site_key[value]: length for value, length in dict_of_lengths.items() if value in reversed_site_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f969cfa6-e72f-4802-9ef0-288691d4775d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(updated_dict.items()), columns=['Site Key', 'Length']).sort_values('Site Key').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f339a42-53d3-4dbf-865d-f814fdc43a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c66f44-1258-4930-af2c-49f6add0b879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_timeseries",
   "language": "python",
   "name": "aki_timeseries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
