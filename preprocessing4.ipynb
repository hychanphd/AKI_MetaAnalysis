{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9387011d-0244-4d22-a83d-cbafdd62d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.interpolate import BSpline, make_interp_spline, interp1d\n",
    "#import rpy2.robjects as robjects\n",
    "#from rpy2.robjects.packages import importr\n",
    "import csv\n",
    "from dfply import *\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874a6e0e-29b7-4654-a45b-bfb02e3c7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_too_much_nan(site, year, newdfs, threshold, keep_med=True):\n",
    "    print('Remove sparse feature on site '+site+\":\"+str(year), flush = True)                        \n",
    "    allcols = []\n",
    "    for newdf in newdfs:\n",
    "        allcols = allcols + list(newdf.columns)\n",
    "    allcols = np.unique(np.array(allcols))\n",
    "    allcols = allcols[allcols != 'FLAG']\n",
    "    allcols = allcols[allcols != 'PATID']\n",
    "    allcols = allcols[allcols != 'ENCOUNTERID']\n",
    "\n",
    "    flag0nan = {key: 0 for key in allcols}\n",
    "    flag1nan = {key: 0 for key in allcols}\n",
    "    flag0total = 0\n",
    "    flag1total = 0\n",
    "\n",
    "    for newdf in newdfs:\n",
    "        btX = newdf.replace(False, np.nan)\n",
    "        flag0total += np.logical_not(btX['FLAG']).sum()\n",
    "        flag1total += btX['FLAG'].sum()    \n",
    "        for col in allcols:\n",
    "            if col in newdf.columns:\n",
    "                flag0nan[col] += np.logical_and(np.logical_not(btX['FLAG']), np.isnan(btX[col])).sum()\n",
    "                flag1nan[col] += np.logical_and(btX['FLAG'], np.isnan(btX[col])).sum()\n",
    "            else:\n",
    "                flag0nan[col] += np.logical_not(btX['FLAG']).sum()\n",
    "                flag1nan[col] += btX['FLAG'].sum()\n",
    "                \n",
    "    remlist = []        \n",
    "    for col in allcols:\n",
    "#        print(col, flag0nan[col]/flag0total, flag1nan[col]/flag1total)        \n",
    "        if flag0nan[col]/flag0total >= 1-threshold and flag1nan[col]/flag1total >= 1-threshold:\n",
    "            remlist = remlist + [col]\n",
    "\n",
    "    if keep_med:\n",
    "        remlist = [x for x in remlist if 'MED' not in x]\n",
    "            \n",
    "    for i in range(len(newdfs)):\n",
    "        newdfs[i] = newdfs[i].drop(remlist,axis=1, errors='ignore')\n",
    "\n",
    "    return newdfs, remlist, flag0nan, flag1nan, flag0total, flag1total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ff4ddb-638f-4da1-9026-d3ac5185a2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_too_much_nan_positive(site, year, newdfs, threshold, keep_med=True):\n",
    "    print('Remove sparse feature on site '+site+\":\"+str(year), flush = True)                        \n",
    "    allcols = []\n",
    "    for newdf in newdfs:\n",
    "        allcols = allcols + list(newdf.columns)\n",
    "    allcols = np.unique(np.array(allcols))\n",
    "    allcols = allcols[allcols != 'FLAG']\n",
    "    allcols = allcols[allcols != 'PATID']\n",
    "    allcols = allcols[allcols != 'ENCOUNTERID']\n",
    "\n",
    "    flag0nan = {key: 0 for key in allcols}\n",
    "    flag1nan = {key: 0 for key in allcols}\n",
    "    flag0total = 0\n",
    "    flag1total = 0\n",
    "        \n",
    "    for newdf in newdfs:\n",
    "        btX = newdf.replace(False, np.nan)\n",
    "        flag0total += np.logical_not(btX['FLAG']).sum()\n",
    "        flag1total += btX['FLAG'].sum()    \n",
    "        for col in allcols:\n",
    "            if col in newdf.columns:\n",
    "#                flag0nan[col] += np.logical_and(np.logical_not(btX['FLAG']), np.isnan(btX[col])).sum()\n",
    "                flag1nan[col] += np.logical_and(btX['FLAG'], np.isnan(btX[col])).sum()\n",
    "            else:\n",
    "#                flag0nan[col] += np.logical_not(btX['FLAG']).sum()\n",
    "                flag1nan[col] += btX['FLAG'].sum()\n",
    "\n",
    "    remlist = []        \n",
    "    for col in allcols:\n",
    "#        print(col, flag0nan[col]/flag0total, flag1nan[col]/flag1total)        \n",
    "#        if flag0nan[col]/flag0total >= 1-threshold and flag1nan[col]/flag1total >= 1-threshold:\n",
    "        if flag1nan[col]/flag1total >= 1-threshold:\n",
    "            remlist = remlist + [col]\n",
    "            \n",
    "    if keep_med:\n",
    "        remlist = [x for x in remlist if 'MED' not in x]\n",
    "        \n",
    "    for i in range(len(newdfs)):\n",
    "        newdfs[i] = newdfs[i].drop(remlist,axis=1, errors='ignore')\n",
    "        \n",
    "    return newdfs, remlist, flag0nan, flag1nan, flag0total, flag1total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d88df9-b3f1-4b8f-a698-ce1f15825d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bt_ckd(site, year, newdf):                                    \n",
    "    #lab_num\n",
    "    print('Merging ckd_info on site '+site+\":\"+str(year), flush = True)                \n",
    "    try:\n",
    "        efgr2 = pd.read_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/p0_'+'ckdgroup'+'_'+site+'.pkl')\n",
    "        return pd.merge(newdf, efgr2, left_on=['PATID', 'ENCOUNTERID'], right_on=['PATID', 'ENCOUNTERID'], how='left')\n",
    "    except FileNotFoundError:\n",
    "        logging.basicConfig(filename='BT.log', filemode='a')    \n",
    "        print('No efgr table!!!!! '+site+\":\"+str(year), flush = True)\n",
    "        logging.error('No efgr table!!!!! '+site+\":\"+str(year))\n",
    "        logging.shutdown()\n",
    "        return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0963d82c-43de-4537-b073-e21a1db78ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bt_postprocess(site, year, newdf):\n",
    "    print('Finishing on site '+site+\":\"+str(year), flush = True)                    \n",
    "    newdf = newdf.drop(['PATID', 'ENCOUNTERID', 'AKI1_SINCE_ADMIT', 'SINCE_ADMIT', 'DAYS_SINCE_ADMIT','DAYS_SINCE_ADMIT_x'],axis=1, errors='ignore')\n",
    "    newdf.columns=newdf.columns.str.replace('<','st')\n",
    "    newdf.columns=newdf.columns.str.replace('>','bt')\n",
    "    newdf.columns=newdf.columns.str.replace('[','lb')\n",
    "    newdf.columns=newdf.columns.str.replace(']','rb')   \n",
    "    return newdf.dropna(axis=1, how='all')\n",
    "\n",
    "#    newdf_debug['drop'] = newdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b84d1a9-a858-4615-bec8-5a230e5fb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_convert(dataX, stg):\n",
    "    data = dataX.copy()\n",
    "    \n",
    "    if stg == 'stg23':\n",
    "        data = data[data['FLAG']!=1]\n",
    "        data['FLAG'] = (data['FLAG']>1)*1\n",
    "        return data\n",
    "    \n",
    "    if stg == 'stg010':\n",
    "        data = data[data['FLAG']!=2]\n",
    "        data = data[data['FLAG']!=3]\n",
    "        return data\n",
    "    \n",
    "    if stg == 'stg123':\n",
    "        data = data[data['FLAG']!=0]\n",
    "        \n",
    "    if stg == 'stg01':\n",
    "        data['FLAG'] = (data['FLAG']>0)*1\n",
    "    else:\n",
    "        data['FLAG'] = (data['FLAG']>1)*1    \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38aaa362-10f0-4b51-a958-bcc827678ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_dtypes(datanew, site, stg): \n",
    "#    datanew = pd.read_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/bt3pos_'+site+'_'+stg+'_3000.pkl')\n",
    "    \n",
    "    onset = pd.read_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique()) \n",
    "    bt_list = list()\n",
    "\n",
    "    for year in years:\n",
    "        try:\n",
    "            data = pd.read_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/bt3_'+site+'_'+str(year)+'.pkl')\n",
    "            bt_list.append(data.dtypes)\n",
    "        except:\n",
    "            print(str(year)+' not exists')\n",
    "\n",
    "    datatype_list = pd.concat(bt_list).reset_index().drop_duplicates()\n",
    "    datatype_list['index'] = datatype_list['index'].str.replace('<','st')\n",
    "    datatype_list['index'] = datatype_list['index'].str.replace('>','bt')\n",
    "    datatype_list['index'] = datatype_list['index'].str.replace('[','lb')\n",
    "    datatype_list['index'] = datatype_list['index'].str.replace(']','rb') \n",
    "    datatype_list.index = datatype_list['index']\n",
    "    datatype_list.columns = ['index1', 0]\n",
    "\n",
    "    datanewcol = pd.DataFrame(datanew.columns)\n",
    "    datanewcol.columns = ['index1']\n",
    "\n",
    "    datatype_list = datanewcol.merge(datatype_list, on='index1', how='left')\n",
    "    datatype_list.index = datatype_list['index1']\n",
    "    datatype_list = datatype_list[0].to_dict()\n",
    "    datanew = datanew.astype(datatype_list)\n",
    "#    datanew.to_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    return datanew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e3f3a61-03d0-416b-bfd7-c9cfb207cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinebt(site, yearX, stg, threshold=0.01):\n",
    "    \n",
    "    onset = pd.read_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique())    \n",
    "    bt_list = list()\n",
    "\n",
    "    for year in years:\n",
    "        try:\n",
    "            data = pd.read_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/bt3_'+site+'_'+str(year)+'.pkl')\n",
    "            data = flag_convert(data, stg)\n",
    "            bt_list.append(data.copy())\n",
    "        except:\n",
    "            print(str(year)+' not exists')\n",
    "\n",
    "            \n",
    "    bt_list, remlist, flag0nan, flag1nan, flag0total, flag1total = drop_too_much_nan(site, yearX, bt_list, threshold)\n",
    "#    return bt_list, remlist, flag0nan, flag1nan, flag0total, flag1total\n",
    "    bt_all = pd.concat(bt_list, ignore_index=True)\n",
    "    # replace nan in boolean columns with False\n",
    "    bt_bool = bt_all.select_dtypes('O').columns\n",
    "    bt_all[bt_bool] = bt_all[bt_bool].fillna(False)\n",
    "\n",
    "    bt_all = bt_ckd(site, yearX, bt_all)\n",
    "    bt_all = bt_postprocess(site, yearX, bt_all)\n",
    "    \n",
    "    \n",
    "    bt_all.to_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/bt3_'+site+'_'+stg+'_3000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a257834-e4ed-4464-b9c2-14097b47e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinebtpos(site, yearX, stg, threshold=0.01, n_jobs=30):\n",
    "\n",
    "    onset = pd.read_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/p0_onset_'+site+'.pkl')\n",
    "    years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique())    \n",
    "    bt_list = list()\n",
    "\n",
    "    for year in years:\n",
    "        try:\n",
    "            data = pd.read_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/bt3_'+site+'_'+str(year)+'.pkl')\n",
    "            data = flag_convert(data, stg)\n",
    "            bt_list.append(data.copy())\n",
    "        except:\n",
    "            print(str(year)+' not exists')\n",
    "\n",
    "    #    bt_list, remlist, flag0nan, flag1nan, flag0total, flag1total = drop_too_much_nan(site, yearX, bt_list, threshold)\n",
    "    bt_list, remlist, flag0nan, flag1nan, flag0total, flag1total = drop_too_much_nan_positive(site, yearX, bt_list, threshold)\n",
    "    bt_all = pd.concat(bt_list, ignore_index=True)\n",
    "\n",
    "    # replace nan in boolean columns with False\n",
    "    bt_bool = bt_all.select_dtypes('O').columns\n",
    "#    bt_all[bt_bool] = bt_all[bt_bool].fillna(False)\n",
    "\n",
    "    def fillnap(bt_all, bt_bool):\n",
    "        bt_all[bt_bool] = bt_all[bt_bool].fillna(False)\n",
    "        return bt_all\n",
    "\n",
    "    col = bt_all.columns\n",
    "    n=int(bt_all.shape[0]/n_jobs)+1\n",
    "    chunks = [bt_all[i:i+n].copy() for i in range(0,bt_all.shape[0],n)]\n",
    "    bt_all = Parallel(n_jobs=n_jobs)(delayed(fillnap)(chunk, bt_bool) for chunk in chunks)\n",
    "    bt_all = np.concatenate(bt_all)\n",
    "    bt_all = pd.DataFrame(bt_all, columns = col)\n",
    "\n",
    "    bt_all = bt_ckd(site, yearX, bt_all)\n",
    "    bt_all = bt_postprocess(site, yearX, bt_all)\n",
    "    bt_all = correct_dtypes(bt_all, site, stg)\n",
    "    #    bt_all.to_pickle('/home/hoyinchan/blue/Data/data2021/data2021/'+site+'/bt3pos_'+site+'_'+stg+'_3000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f95051-db47-4c03-b198-b46aba7fa874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    combinebtpos('UPITT', 3000, 'stg01', threshold=0.01, n_jobs=60)\n",
    "    combinebtpos('UPITT', 3000, 'stg23', threshold=0.01, n_jobs=60)\n",
    "    combinebtpos('UPITT', 3000, 'stg123', threshold=0.01, n_jobs=60)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c51d2f-e853-461a-bb3e-5747fff4ef87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_CDM_PY",
   "language": "python",
   "name": "aki_cdm_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
