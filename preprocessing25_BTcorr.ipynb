{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f485a-31dd-482c-b8ea-e3ad018edc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.interpolate import BSpline, make_interp_spline, interp1d\n",
    "#import rpy2.robjects as robjects\n",
    "#from rpy2.robjects.packages import importr\n",
    "import csv\n",
    "from dfply import *\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import os\n",
    "import logging\n",
    "from glob import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f4fe8-de9b-440b-9074-5ec478bb8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corr(site, year):\n",
    "    bt = pd.read_pickle('data/'+site+'/bt_'+site+'_'+str(year)+'.pkl')\n",
    "    corr = bt.corr()\n",
    "    corr.to_pickle('data/'+site+'/btcorr_'+site+'_'+str(year)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6645121-704b-43e8-b4fa-9cb7fef24754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corr_occurence2():\n",
    "    files = []\n",
    "    start_dir = os.getcwd()\n",
    "    pattern   = \"btcorr_*\"\n",
    "    for dir,_,_ in os.walk(start_dir):\n",
    "        files.extend(glob(os.path.join(dir,pattern))) \n",
    "\n",
    "    meltcorrlist = list() \n",
    "\n",
    "    for file in files:\n",
    "        site = file.split('/')[-1].split('.')[0].split('_')[1]\n",
    "        year = file.split('/')[-1].split('.')[0].split('_')[2]\n",
    "        corr = pd.read_pickle(file)\n",
    "        corr = abs(corr)\n",
    "        meltcorr = pd.melt(corr.reset_index(), id_vars=['index'])\n",
    "        meltcorr = meltcorr[meltcorr['index'] != meltcorr['variable']]\n",
    "        meltcorr['site'] = site\n",
    "        meltcorr['year'] = year    \n",
    "        meltcorrlist.append(meltcorr)\n",
    "\n",
    "        \n",
    "    meltcorrall = pd.concat(meltcorrlist)\n",
    "    meltcorrall.columns = ['v1', 'v2', 'corr', 'site', 'year']\n",
    "    meltcorrall.to_pickle('data/meltcorrall.pkl')\n",
    "                              \n",
    "#if __name__ == \"__main__\":\n",
    "#    calculate_corr_occurence2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451ab1a-c773-4bff-8c8e-f13d10d5e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corr_occurence(threshold = 0.5):\n",
    "    files = []\n",
    "    start_dir = os.getcwd()\n",
    "    pattern   = \"btcorr_*\"\n",
    "    for dir,_,_ in os.walk(start_dir):\n",
    "        files.extend(glob(os.path.join(dir,pattern))) \n",
    "\n",
    "    meltcorrlist = list() \n",
    "\n",
    "    for file in files:\n",
    "        site = file.split('/')[-1].split('.')[0].split('_')[1]\n",
    "        year = file.split('/')[-1].split('.')[0].split('_')[2]\n",
    "        corr = pd.read_pickle(file)\n",
    "        meltcorr = pd.melt(corr.reset_index(), id_vars=['index'])\n",
    "        meltcorr = meltcorr[meltcorr['value'] >= threshold]\n",
    "        meltcorr = meltcorr[meltcorr['index'] != meltcorr['variable']]\n",
    "        meltcorr['site'] = site\n",
    "        meltcorr['year'] = year    \n",
    "        meltcorrlist.append(meltcorr)\n",
    "\n",
    "    meltcorrall = pd.concat(meltcorrlist)\n",
    "    meltcorrall.columns = ['v1', 'v2', 'corr', 'site', 'year']\n",
    "    meltcorrallcount = pd.melt(meltcorrall.drop('corr', axis=1), id_vars=['site', 'year']).drop('variable', axis=1).drop_duplicates().groupby('value').count().drop('site',axis=1).reset_index()\n",
    "    meltcorrallcount.columns = ['value', 'count']\n",
    "    meltcorrallcount.to_pickle('data/meltcorrallcount_'+str(threshold)+'.pkl')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    calculate_corr_occurence(threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ad30c-f23b-4a61-864c-4d842a3124fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_corr_bt(site, year, threshold=0.5):   \n",
    "\n",
    "    meltcorrallcount = pd.read_pickle('data/meltcorrallcount_'+str(threshold)+'.pkl')\n",
    "    bt = pd.read_pickle('data/'+site+'/bt_'+site+'_'+str(year)+'.pkl')\n",
    "    corr = bt.corr()\n",
    "    corr.to_pickle('data/'+site+'/btcorr_'+site+'_'+str(year)+'.pkl')\n",
    "    meltcorr = pd.melt(corr.reset_index(), id_vars=['index'])\n",
    "    meltcorr = meltcorr[meltcorr['value'] >= threshold]\n",
    "    meltcorr = meltcorr[meltcorr['index'] != meltcorr['variable']]\n",
    "       \n",
    "    correlated_group = list()\n",
    "    correlated_group.append([meltcorr.iloc[0,0], meltcorr.iloc[0,1]])\n",
    "    for i in range(meltcorr.shape[0]):\n",
    "        newgroup = True\n",
    "        for j in range(len(correlated_group)):\n",
    "            if (meltcorr.iloc[i,0] in correlated_group[j] or meltcorr.iloc[i,1] in correlated_group[j]):\n",
    "                correlated_group[j].append(meltcorr.iloc[i,0])\n",
    "                correlated_group[j].append(meltcorr.iloc[i,1])\n",
    "                newgroup = False\n",
    "                break\n",
    "        if newgroup:\n",
    "            correlated_group.append([meltcorr.iloc[i,0], meltcorr.iloc[i,1]])\n",
    "\n",
    "    keep_list = list()\n",
    "    drop_list = list()\n",
    "\n",
    "    for i in range(len(correlated_group)):\n",
    "        correlated_groupX = list(set(correlated_group[i]))\n",
    "        correlated_groupX.sort(reverse=True)\n",
    "        maxcount = -1\n",
    "        for feature in correlated_groupX:\n",
    "            count = meltcorrallcount[meltcorrallcount['value'] == feature].iloc[0,1]\n",
    "            if maxcount < count:\n",
    "                maxfeature = feature\n",
    "                maxcount = count\n",
    "        keep_list.append(maxfeature)\n",
    "        correlated_groupX.remove(maxfeature)\n",
    "        drop_list.extend(correlated_groupX)\n",
    "        \n",
    "    with open('data/'+site+'/corrdropadd_'+site+'_'+str(year)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(drop_list, f)            \n",
    "        pickle.dump(keep_list, f)            \n",
    "    bt = bt.drop(drop_list, axis=1)\n",
    "    bt.to_pickle('data/'+site+'/bt2_'+site+'_'+str(year)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d28f57-d94d-4e3f-b090-035e02338bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
