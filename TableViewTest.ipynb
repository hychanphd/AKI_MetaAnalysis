{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.stats import fisher_exact\n",
    "import shelve\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.interpolate import BSpline, make_interp_spline, interp1d\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import csv\n",
    "from dfply import *\n",
    "import itertools\n",
    "import os\n",
    "import logging\n",
    "from sys import getsizeof\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import Pool, cv\n",
    "import xgboost\n",
    "import catboost\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035017e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Site\n",
    "#sites = ['IUR', 'MCRI', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'UTSW']\n",
    "sites = ['IUR', 'MCRI', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'UTSW']\n",
    "site='UPITT'\n",
    "year=3000\n",
    "stg = 'stg01'\n",
    "oversample = 'raw'\n",
    "fs = 'nofs'\n",
    "recol = '005'\n",
    "model_type = 'catd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c3430-481c-4493-a198-af2e66d567a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stg = 'stg23'\n",
    "fs = 'nofs'\n",
    "oversample='raw'\n",
    "model = 'catd'    \n",
    "rmcol = '005'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774610fd-31c4-49b5-9b29-865395c74e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = pd.read_pickle('data/'+site+'/bt3_'+site+'_'+stg+'_'+str(year)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbaa6c8-da55-4fc4-beea-2aac3d5c06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1308a-e4ee-4d5a-8734-96c384fa75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a80158f-8518-4dd6-9fff-8fa774e62f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'MED:ATC:N02BE'\n",
    "df_list = list()\n",
    "for site in sites:\n",
    "    try:\n",
    "        bt = pd.read_pickle('data/'+site+'/bt3_'+site+'_'+stg+'_'+str(year)+'.pkl')\n",
    "        #bt[[target_feature,'FLAG']]\n",
    "        base = (bt['FLAG']==1).sum()/bt.shape[0]\n",
    "        support = bt[target_feature].sum()/bt.shape[0]\n",
    "        support1 = np.logical_and(bt[target_feature],bt['FLAG']==1).sum()/(bt['FLAG']==1).sum()        \n",
    "        conf = np.logical_and(bt[target_feature],bt['FLAG']==1).sum()/bt[target_feature].sum()\n",
    "        df_list.append(pd.DataFrame({'site':site, 'support':support, 'support1':support1,'base':base, 'conf':conf},index=[0]))\n",
    "    except:\n",
    "        pass\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242719b1-0a57-4ea4-b8bb-b251c649de2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site = 'UNMC'\n",
    "home_directory = \"/home/hchan2/AKI/AKI_Python/\"    \n",
    "onset = pd.read_pickle('data/'+site+'/p0_onset_'+site+'.pkl')\n",
    "amed = pd.read_pickle('data/'+site+'/p0_amed_'+site+'.pkl')\n",
    "amed_rx = amed.loc[amed['MEDADMIN_TYPE'] == \"RX\"]\n",
    "rxcui2atc_dtypes =  {\"Rxcui\": 'object', \"ATC4th\": 'object'}    \n",
    "rxcui2atc = pd.read_csv(home_directory+\"data/\"+site+'/rxnorm_out_'+site+'.csv',sep=',', dtype=(rxcui2atc_dtypes)) >> rename(MEDADMIN_CODE=X.Rxcui)\n",
    "amed_rx = amed_rx >> left_join(rxcui2atc, by='MEDADMIN_CODE')\n",
    "#amed_rx['MEDADMIN_TYPE'] = amed_rx['MEDADMIN_TYPE'].where(amed_rx['ATC4th'].isnull(), 'ATC')\n",
    "#amed_rx['MEDADMIN_CODE'] = amed_rx['MEDADMIN_CODE'].where(amed_rx['ATC4th'].isnull(), amed_rx['ATC4th'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873a28b-a43c-490f-8b2f-87274a37e907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amed_rx[amed_rx['ATC4th']=='B01AB'][['PATID', 'MEDADMIN_CODE','ATC4th']].drop_duplicates().drop('PATID',axis=1).groupby('MEDADMIN_CODE').count()\n",
    "#amed_rx[amed_rx['ATC4th']=='B01AB'][['MEDADMIN_CODE','ATC4th']].groupby('MEDADMIN_CODE').count()\n",
    "#amed_rx[amed_rx['ATC4th']=='B01AB'][['PATID']].drop_duplicates().count()\n",
    "#amed_rx[['PATID']].drop_duplicates().count()\n",
    "#onset[['PATID']].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ecd70-840b-4930-9283-e27293bbaa4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation_calculation(site, year, stg, target='LAB::17861-6(mg/dL)', threshold = 8.6, max_row=10, drop='LAB'):\n",
    "    bt = pd.read_pickle('data/'+site+'/bt3_'+site+'_'+stg+'_'+str(year)+'.pkl')\n",
    "\n",
    "    r1 = bt[target] > 8.6\n",
    "    r3 = bt[target] < 8.6\n",
    "\n",
    "    corrdict1 = dict()\n",
    "    corrdict3 = dict()\n",
    "    for col in bt.columns:\n",
    "        if 'MED' in col:\n",
    "            corrdict1[col] = bt[r1]['LAB::17861-6(mg/dL)'].corr(bt[r1][col])\n",
    "            corrdict3[col] = bt[r3]['LAB::17861-6(mg/dL)'].corr(bt[r3][col])    \n",
    "\n",
    "    #Correlation with high Calcium\n",
    "    df1 = pd.DataFrame(corrdict1, index=[0]).T.sort_values(0,ascending=True).reset_index()\n",
    "    #df1['index'] = df1['index'].str.split(':',expand=True).loc[:,2].str.split('(',expand=True).loc[:,0]\n",
    "    #df1['name'] = df1['index'].apply(lablonic2name)\n",
    "    df_high_anti = df1[~df1['index'].str.contains(drop)].dropna().head(max_row)\n",
    "    df_high_anti['site'] = site\n",
    "    df_high_anti['stg'] = stg\n",
    "    \n",
    "    #Correlation with high Calcium\n",
    "    df1 = pd.DataFrame(corrdict1, index=[0]).T.sort_values(0,ascending=False).reset_index()\n",
    "    #df1['index'] = df1['index'].str.split(':',expand=True).loc[:,2].str.split('(',expand=True).loc[:,0]\n",
    "    #df1['name'] = df1['index'].apply(lablonic2name)\n",
    "    df_high_corr = df1[~df1['index'].str.contains(drop)].dropna().head(max_row)\n",
    "    df_high_corr['site'] = site\n",
    "    df_high_corr['stg'] = stg\n",
    "\n",
    "    #Correlation with low Calcium\n",
    "    df1 = pd.DataFrame(corrdict3, index=[0]).T.sort_values(0,ascending=True).reset_index()\n",
    "    #df1['index'] = df1['index'].str.split(':',expand=True).loc[:,2].str.split('(',expand=True).loc[:,0]\n",
    "    #df1['name'] = df1['index'].apply(lablonic2name)\n",
    "    df_low_anti = df1[~df1['index'].str.contains(drop)].dropna().head(max_row)\n",
    "    df_low_anti['site'] = site\n",
    "    df_low_anti['stg'] = stg\n",
    "\n",
    "    #Correlation with low Calcium\n",
    "    df1 = pd.DataFrame(corrdict3, index=[0]).T.sort_values(0,ascending=False).reset_index()\n",
    "    #df1['index'] = df1['index'].str.split(':',expand=True).loc[:,2].str.split('(',expand=True).loc[:,0]\n",
    "    #df1['name'] = df1['index'].apply(lablonic2name)\n",
    "    df_low_corr = df1[~df1['index'].str.contains(drop)].dropna().head(max_row)\n",
    "    df_low_corr['site'] = site\n",
    "    df_low_corr['stg'] = stg\n",
    "    \n",
    "    return [df_high_corr, df_low_corr, df_high_anti, df_low_anti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30657801-1dc8-44ae-9724-d9004beecdc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = ['IUR', 'MCRI', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'UTSW']\n",
    "#stgs = ['stg01', 'stg23']\n",
    "stgs = ['stg01']\n",
    "\n",
    "df_high_corr = list()\n",
    "df_low_corr = list()\n",
    "for site in sites:\n",
    "    for stg in stgs:\n",
    "        try:\n",
    "            print(site, stg)\n",
    "            dfhc, dflc, d1, d2 = correlation_calculation(site, 3000, stg, target='LAB::17861-6(mg/dL)', threshold = 8.6, max_row=10, drop='LAB')\n",
    "            df_high_corr.append(dfhc.copy())\n",
    "            df_low_corr.append(dflc.copy())\n",
    "        except:\n",
    "            pass\n",
    "df_high_corr = pd.concat(df_high_corr)\n",
    "df_low_corr = pd.concat(df_low_corr)\n",
    "df_high_corr.columns = ['index', 'corr', 'site', 'stg']\n",
    "df_low_corr.columns = ['index', 'corr', 'site', 'stg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfa425-13ef-4a78-8656-9e5a147506ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_high_corr['rank'] = df_high_corr.groupby(['site','stg'])['corr'].rank(\"first\", ascending=False)\n",
    "df_high_corr['index(corr)'] = df_high_corr['index']+'('+df_high_corr['corr'].round(3).astype(str)+')'\n",
    "df_high_corr[['site', 'index(corr)', 'rank']].pivot(index='site', columns='rank', values='index(corr)').applymap(lambda x: x.split(':')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823b812-e173-496d-9d03-979f2d15999b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_low_corr['rank'] = df_low_corr.groupby(['site','stg'])['corr'].rank(\"first\", ascending=False)\n",
    "df_low_corr['index(corr)'] = df_low_corr['index']+'('+df_low_corr['corr'].round(3).astype(str)+')'\n",
    "df_low_corr[['site', 'index(corr)', 'rank']].pivot(index='site', columns='rank', values='index(corr)').applymap(lambda x: x.split(':')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd42af-cdcd-46a4-b108-c21163d45cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_low_corr.to_csv('df_low_corr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f573f7-7503-449e-aa35-7d54fbfcd093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read data session\n",
    "datafolder = '/home/hchan2/AKI/data/'\n",
    "datatt = pd.read_csv(datafolder+site+'/raw/'+'AKI_VITAL'+'.'+'csv')\n",
    "onset = pd.read_pickle('data/'+site+'/p0_onset_'+site+'.pkl')\n",
    "newdf = pd.read_pickle('data/'+site+'/onset_'+site+'_'+str(year)+'.pkl')\n",
    "vital = pd.read_pickle('data/'+site+'/p0_vital_'+site+'.pkl')\n",
    "vital_tt = pd.read_pickle('data/'+site+'/vital_'+site+'_'+str(year)+'.pkl')\n",
    "demo = pd.read_pickle('data/'+site+'/p0_demo_'+site+'.pkl')\n",
    "demo_t = pd.read_pickle('data/'+site+'/demo_'+site+'_'+str(year)+'.pkl')\n",
    "dx = pd.read_pickle('data/'+site+'/p0_dx_'+site+'.pkl')\n",
    "dx_t = pd.read_pickle('data/'+site+'/dx_'+site+'_'+str(year)+'.pkl')\n",
    "px = pd.read_pickle('data/'+site+'/p0_px_'+site+'.pkl')\n",
    "px_t = pd.read_pickle('data/'+site+'/px_'+site+'_'+str(year)+'.pkl')\n",
    "lab = pd.read_pickle('data/'+site+'/p0_lab_'+site+'.pkl')\n",
    "labnum_tt = pd.read_pickle('data/'+site+'/labnum_'+site+'_'+str(year)+'.pkl')\n",
    "labcat_tt = pd.read_pickle('data/'+site+'/labcat_'+site+'_'+str(year)+'.pkl')\n",
    "amed = pd.read_pickle('data/'+site+'/p0_amed_'+site+'.pkl')\n",
    "amed_tt = pd.read_pickle('data/'+site+'/amed_'+site+'_'+str(year)+'.pkl')\n",
    "bt = pd.read_pickle('data/'+site+'/bt3_'+site+'_'+str(year)+'.pkl')\n",
    "\n",
    "X_train = pd.read_pickle('data/'+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "X_test =  pd.read_pickle('data/'+site+ '/X_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "y_train = pd.read_pickle('data/'+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "y_test =  pd.read_pickle('data/'+site+ '/y_test_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "shap_data = pd.read_pickle('data/'+site+'/shapdata_'+model_type+'_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'_005.pkl')\n",
    "\n",
    "model = pickle.load(open('data/'+site+'/model_'+model_type+'_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl', 'rb'))\n",
    "result = pd.read_pickle('result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5348f2d-d3a0-4b3f-a894-0964e2ed092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load statistics\n",
    "stg = 'stg01'\n",
    "fs = 'rmscrbun'\n",
    "oversample='raw'\n",
    "model = 'catd'    \n",
    "rmcol = '005'\n",
    "result = pd.read_pickle('./DEID_resultsplit_'+model+'_'+stg+'_'+fs+'_'+oversample+'_005.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b936b5-0103-42fc-b7e8-609c64fd7808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result2 = result.loc[result['site'] == 'KUMC']\n",
    "#result2 = result2.loc[result['year'] == 2016]\n",
    "#result2[['site', 'year', 'Feature', 'rank', 'rank_abs_shap_max', 'rank_minmax_SHAP', 'rank_var_SHAP']].drop_duplicates().sort_values('rank_var_SHAP')\n",
    "\n",
    "resultX = result.loc[:,['site', 'year', 'Feature', 'mean_val']].groupby(['site', 'year', 'Feature']).agg([np.mean]).reset_index()\n",
    "resultX.columns = ['site', 'year', 'Feature', 'meanmean_val'] \n",
    "resultX['rank_meanmean_SHAP'] = resultX.groupby(['site', 'year'])['meanmean_val'].rank(method='min', ascending=False)\n",
    "\n",
    "resultY = result.loc[:,['site', 'year', 'Feature', 'mean_imp']].groupby(['site', 'year', 'Feature']).agg([np.mean]).reset_index()\n",
    "resultY.columns = ['site', 'year', 'Feature', 'absmean_val'] \n",
    "resultY['rank_absmean_SHAP'] = resultY.groupby(['site', 'year'])['absmean_val'].rank(method='min', ascending=False)\n",
    "\n",
    "result = pd.merge(result, resultX, left_on=['site', 'year', 'Feature'], right_on=['site', 'year', 'Feature'], how='left')    \n",
    "result = pd.merge(result, resultY, left_on=['site', 'year', 'Feature'], right_on=['site', 'year', 'Feature'], how='left')    \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247976fb-f71a-4268-b5c7-558b042af023",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pickle('./DEID_resultsplit_'+model+'_'+stg+'_'+fs+'_'+oversample+'_005_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3ddb9-3e33-4714-a92b-f7fb56b103d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c66b4-5b92-4ec9-ac2c-e4feaf593e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result.loc[result['site'] == 'KUMC']\n",
    "result2 = result2.loc[result['year'] == 2016]\n",
    "result2[['site', 'year', 'Feature', 'rank', 'rank_abs_shap_max', 'rank_minmax_SHAP', 'rank_var_SHAP', 'rank_meanmean_SHAP', 'rank_absmean_SHAP']].drop_duplicates().sort_values('rank').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722ea88-f206-43b4-adf9-16912744ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "stg = 'stg01'\n",
    "fs = 'rmscrbun'\n",
    "oversample='raw'\n",
    "model_type = 'catd'    \n",
    "rmcol = '005'\n",
    "\n",
    "site='KUMC'\n",
    "year=3000\n",
    "\n",
    "model = pickle.load(open('data/'+site+'/model_'+model_type+'_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl', 'rb'))\n",
    "\n",
    "#load tables\n",
    "X_train = pd.read_pickle('data/'+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "X_test =  pd.read_pickle('data/'+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "y_train = pd.read_pickle('data/'+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "y_test =  pd.read_pickle('data/'+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "\n",
    "pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e56ee-e137-4fa6-99f6-ca9265b04677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "roc = roc_auc_score(y_test, pred[:,1])\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, pred[:,1])\n",
    "pyplot.plot(ns_fpr, ns_tpr)\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "sklearn.metrics.auc(ns_fpr, ns_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed68a2-e79f-45b4-b3fa-355c2b89704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, cv\n",
    "import xgboost\n",
    "import catboost\n",
    "\n",
    "stg = 'stg01'\n",
    "fs = 'rmscrbun'\n",
    "oversample='raw'\n",
    "model_type = 'catd'    \n",
    "rmcol = '005'\n",
    "\n",
    "site='MCRI'\n",
    "year=3000\n",
    "\n",
    "model = pickle.load(open('data/'+site+'/model_'+model_type+'_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl', 'rb'))\n",
    "\n",
    "#load tables\n",
    "X_train = pd.read_pickle('data/'+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "X_test =  pd.read_pickle('data/'+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "y_train = pd.read_pickle('data/'+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "y_test =  pd.read_pickle('data/'+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "\n",
    "# Get AUC\n",
    "#    pred = model.get_booster().predict(dtest, pred_contribs=False)\n",
    "#    pred = model.predict(X_test)    \n",
    "#    roc = roc_auc_score(y_test, pred)    \n",
    "\n",
    "pred = model.predict_proba(X_test)\n",
    "roc = roc_auc_score(y_test, pred[:,1])    \n",
    "\n",
    "shapX = pd.concat([X_train, X_test])\n",
    "shapy = pd.concat([y_train, y_test])\n",
    "\n",
    "# Calculate SHAP value\n",
    "if type(model) == xgboost.sklearn.XGBClassifier:\n",
    "    dshap  = xgb.DMatrix(shapX, label=shapy)\n",
    "    shap = model.get_booster().predict(dshap, pred_contribs=True)\n",
    "    # Get feature importance\n",
    "    model_data = pd.concat([pd.DataFrame(model.get_booster().get_score(importance_type='cover'), index=['Cover']), \\\n",
    "    pd.DataFrame(model.get_booster().get_score(importance_type='gain'), index=['Gain']), \\\n",
    "    pd.DataFrame(model.get_booster().get_score(importance_type='weight'), index=['Frequency'])]).transpose() >> mutate(Feature = X.index)\n",
    "    model_data['rank'] = model_data['Gain'].rank(method='min', ascending=False)\n",
    "    used_feature = list(model.get_booster().get_score().keys())        \n",
    "elif type(model) == catboost.core.CatBoostClassifier:\n",
    "    cat_features = model.get_cat_feature_indices()\n",
    "    pshap = Pool(data=shapX, label=shapy, cat_features=cat_features)        \n",
    "    shap = model.get_feature_importance(data=pshap, type='ShapValues')\n",
    "    model_data = model.get_feature_importance(prettified=True)\n",
    "    model_data['Feature'] = model_data['Feature Id']\n",
    "    model_data = model_data >> select('Feature', 'Importances')\n",
    "    model_data['rank'] = model_data['Importances'].rank(method='min', ascending=False)     \n",
    "    used_feature = list((model_data >> mask(X.Importances!=0)).Feature)\n",
    "else:\n",
    "#Using shap package example\n",
    "    import shap\n",
    "    explainer = shap.Explainer(model, algorithm='permutation')\n",
    "    shap_valuesX = explainer.shap_values(shapX)\n",
    "    #shap.summary_plot(shap_valuesX, X_test, plot_type=\"bar\")    \n",
    "    shap = shap_valuesX    \n",
    "\n",
    "\n",
    "# Collect SHAP value\n",
    "def CI95(data):\n",
    "    if len(data) == 1:\n",
    "        return (np.nan, np.nan)\n",
    "    return st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)) #95% confidence interval\n",
    "\n",
    "shap_data = list()\n",
    "shap_data_raw = list()\n",
    "#for i in range(shapX.columns.shape[0]):\n",
    "i = 0\n",
    "df = pd.DataFrame(list(zip(shapX.iloc[:,i], shap[:, i], abs(shap[:, i]))),columns =['Name', 'val', 'absval'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec2d4c-9116-4138-abd5-c8c8a7cefc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[shapy==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c4073-63f5-4ee2-92c9-4a646d235a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_all = df.groupby(\"Name\").agg([np.mean, np.var, np.std, np.median, CI95, 'size']).reset_index()\n",
    "plot_data_0= df[shapy==0].groupby(\"Name\").agg([np.mean, np.var, np.std, np.median, CI95, 'size']).reset_index()\n",
    "plot_data_1= df[shapy==1].groupby(\"Name\").agg([np.mean, np.var, np.std, np.median, CI95, 'size']).reset_index()\n",
    "plot_data_all.columns = [''.join(x) for x in plot_data_all.columns]\n",
    "plot_data_0.columns = [x+'_0' for x in plot_data_all.columns]\n",
    "plot_data_1.columns = [x+'_1' for x in plot_data_all.columns]\n",
    "plot_data_all = plot_data_all.drop('absvalsize', axis=1)\n",
    "plot_data_0   = plot_data_0.drop('absvalsize_0', axis=1)\n",
    "plot_data_1   = plot_data_1.drop('absvalsize_1', axis=1)\n",
    "plot_data_0 = plot_data_0.rename({'Name_0':'Name'},axis=1)\n",
    "plot_data_1 = plot_data_1.rename({'Name_1':'Name'},axis=1)\n",
    "plot_data = pd.merge(plot_data_all, plot_data_0, left_on='Name', right_on='Name', how='left')\n",
    "plot_data = pd.merge(plot_data, plot_data_1, left_on='Name', right_on='Name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2b398-66a1-477a-bebd-abc8874bb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'UofU'\n",
    "year = 3000\n",
    "stg = 'stg01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf99bb-2a2e-48ef-96a8-957423aaad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/'+site+'/bt3_'+site+'_'+stg+'_3000.pkl')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b77095-1db5-409d-b95b-2066a2062c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = data[data['FLAG']==0].select_dtypes('bool').sum()/data[data['FLAG']==0].shape[0]\n",
    "p1 = data[data['FLAG']==1].select_dtypes('bool').sum()/data[data['FLAG']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042798bc-c8e2-49de-8ffd-f28b45a450c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.DataFrame([p0,p1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a43288-33e8-4dc6-adcb-a513ac740c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b7f0b-8602-4609-bd66-94badba2d446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
