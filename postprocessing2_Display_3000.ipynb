{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe15a3-a091-4459-b70a-e3182a4613d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.interpolate import BSpline, make_interp_spline, interp1d\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import csv\n",
    "from dfply import *\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import os\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import importlib\n",
    "import ipynb.fs.full.postprocessing3_collect\n",
    "import scipy.stats as st\n",
    "\n",
    "from scipy import stats, optimize\n",
    "\n",
    "from statsmodels.regression.linear_model import WLS\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "\n",
    "from statsmodels.stats.meta_analysis import (\n",
    "    effectsize_smd,\n",
    "    effectsize_2proportions,\n",
    "    combine_effects,\n",
    "    _fit_tau_iterative,\n",
    "    _fit_tau_mm,\n",
    "    _fit_tau_iter_mm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea80f3-399f-4ef9-91aa-05e444899411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(df, ax=None, height=0.2,\n",
    "                    xlim=None, ylim=None,\n",
    "                    xlabel='score', ylabel='Feature', fmap='',\n",
    "                    importance_type='auc', max_num_features=None,\n",
    "                    grid=True, show_values=True, \n",
    "                    error=False, importance_type_down = '', importance_type_up = '', **kwargs):\n",
    "\n",
    "    title = importance_type    \n",
    "    \n",
    "    if error:\n",
    "        df = df.sort_values(by=importance_type, ascending=True)\n",
    "        labels = df[ylabel].to_numpy()\n",
    "        values = df[importance_type].to_numpy()\n",
    "        xerr = df[[importance_type_down, importance_type_up]].to_numpy().T\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(1, 1)\n",
    "\n",
    "        ylocs = np.arange(len(values))\n",
    "        ax.barh(ylocs, values, align='center', height=height, xerr=xerr, capsize=10, **kwargs)        \n",
    "    else:\n",
    "        importance = (df >> select(ylabel, importance_type)).set_index('Feature').to_dict()[importance_type]\n",
    "        tuples = [(k, importance[k]) for k in importance]\n",
    "        if max_num_features is not None:\n",
    "            # pylint: disable=invalid-unary-operand-type\n",
    "            tuples = sorted(tuples, key=lambda x: x[1])[-max_num_features:]\n",
    "        else:\n",
    "            tuples = sorted(tuples, key=lambda x: x[1])\n",
    "        labels, values = zip(*tuples)\n",
    "\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots(1, 1)\n",
    "\n",
    "        ylocs = np.arange(len(values))\n",
    "        ax.barh(ylocs, values, align='center', height=height, **kwargs)\n",
    "\n",
    "    if show_values is True:\n",
    "        for x, y in zip(values, ylocs):\n",
    "            ax.text(x + x/25, y, round(x,2), va='center')\n",
    "\n",
    "    ax.set_yticks(ylocs)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    if xlim is not None:\n",
    "        if not isinstance(xlim, tuple) or len(xlim) != 2:\n",
    "            raise ValueError('xlim must be a tuple of 2 elements')\n",
    "    else:\n",
    "        xlim = (0, max(values) * 1.2)\n",
    "    ax.set_xlim(xlim)\n",
    "\n",
    "    if ylim is not None:\n",
    "        if not isinstance(ylim, tuple) or len(ylim) != 2:\n",
    "            raise ValueError('ylim must be a tuple of 2 elements')\n",
    "    else:\n",
    "        ylim = (-1, len(values))\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    if xlabel is not None:\n",
    "        ax.set_xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    ax.grid(grid)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a7aed-28ad-4f62-992a-cd125107199f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_n_SHAP(result, site, year, importance_type = 'Importances', max_num_features = 10, numgraphcol=2):\n",
    "    \n",
    "    shap_data = result >> mask(X.site==site) >> mask(X.year==year)    \n",
    "    #Print top_n SHAP plot\n",
    "#    importance_type = 'Importances'\n",
    "    A = (shap_data >> select('Feature', importance_type)).set_index('Feature').to_dict()[importance_type]\n",
    "    topf_n = sorted(A, key=A.get, reverse=True)[:max_num_features]\n",
    "    \n",
    "    plotindex=0\n",
    "    plt.clf()    \n",
    "    fltrow = math.ceil(max_num_features/numgraphcol)\n",
    "#    fig = plt.figure(figsize=(9,4.5*fltrow))\n",
    "    fig = plt.figure(figsize=(22.5,9))\n",
    "    \n",
    "    for f in topf_n:\n",
    "        plot_data = shap_data >> mask(X.Feature == f) >> select(X.fval, X.mean_val, X.se_val)\n",
    "#        plt.figure()    \n",
    "        plotindex = plotindex+1\n",
    "        plt.subplot(fltrow, numgraphcol, plotindex)\n",
    "        plt.scatter(x=plot_data['fval'],y=plot_data['mean_val'])\n",
    "        plt.errorbar(plot_data['fval'],plot_data['mean_val'], yerr=plot_data['se_val'], fmt=\"o\")\n",
    "        myimp = (shap_data >> mask(X.Feature == f))['Importances'].iloc[0]\n",
    "        plt.title(f+'(' + str(round(myimp,2)) + ')')\n",
    "        # if plot_data.shape[0] > 2:\n",
    "        #     spl = np.polynomial.legendre.Legendre.fit(plot_data['fval'], plot_data['mean_val'],5, full=True)\n",
    "        #     [spline_x, spline_y] = spl[0].linspace()\n",
    "#            plt.plot(spline_x, spline_y)      \n",
    "        plt.grid()\n",
    "    plt.show()\n",
    "    return fig, topf_n\n",
    "    #    plt.savefig('data/'+site+'/model_'+site+'_'+str(year)+'_'+f+'.png')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b609c6-e5c6-49b8-9b37-30d34dfbf7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_feature_SHAP_allyear_allsite(shap_data, feature, sites=None, numgraphcol=5, ylim_range=None):\n",
    "    #Print top_n SHAP plot\n",
    "    shap_data = shap_data >> mask(X.Feature == feature)\n",
    "    if sites is None:\n",
    "        sites = shap_data['site'].unique()\n",
    "    years = shap_data['year'].unique()\n",
    "    years.sort()\n",
    "    \n",
    "    plotindex=0\n",
    "    plt.clf()    \n",
    "    fltrow = math.ceil(len(sites)/numgraphcol)\n",
    "#    fig = plt.figure(figsize=(18/numgraphcol,9/numgraphcol*fltrow))\n",
    "    fig = plt.figure(figsize=(22.5,9))\n",
    "\n",
    "    for site in sites:\n",
    "        plotindex = plotindex+1\n",
    "        plt.subplot(fltrow, numgraphcol, plotindex)    \n",
    "        shap_dataX = shap_data >> mask(X.site == site)\n",
    "        for yr in years:\n",
    "            plot_data = shap_dataX >> mask(X.year == yr) >> select(X.fval, X.mean_val, X.se_val)\n",
    "    #        plt.figure()    \n",
    "            plt.scatter(x=plot_data['fval'],y=plot_data['mean_val'])\n",
    "            plt.errorbar(plot_data['fval'],plot_data['mean_val'], yerr=plot_data['se_val'], fmt=\"o\")\n",
    "#            if plot_data.shape[0] > 2:\n",
    "#                spl = np.polynomial.legendre.Legendre.fit(plot_data['fval'], plot_data['mean_val'],5, full=True)\n",
    "#                [spline_x, spline_y] = spl[0].linspace()\n",
    "#    #            plt.plot(spline_x, spline_y)                 \n",
    "        myimp = shap_dataX['Importances'].iloc[0]\n",
    "        plt.title(site+\"_\"+feature+'(' + str(round(myimp,2)) + ')')\n",
    "        plt.grid()\n",
    "        if not (ylim_range is None):\n",
    "            plt.ylim(ylim_range)\n",
    "    plt.show()\n",
    "    return fig\n",
    "#    plt.savefig('allsite'+f+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852b2a2-9856-4327-a520-ecd942adf0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_feature_SHAP(shap_data, feature, site, numgraphcol=2):\n",
    "    #Print top_n SHAP plot\n",
    "    shap_dataX = shap_data >> mask(X.site == site) >> mask(X.Feature == feature)\n",
    "    years = shap_dataX['year'].unique()\n",
    "    years.sort()\n",
    "    \n",
    "    plotindex=0\n",
    "    plt.clf()    \n",
    "    fltrow = math.ceil(len(years)/numgraphcol)\n",
    "#    fig = plt.figure(figsize=(9,4.5*fltrow))\n",
    "    fig = plt.figure(figsize=(22.5,9))\n",
    "        \n",
    "    for yr in years:\n",
    "        plot_data = shap_dataX >> mask(X.year == yr) >> select(X.fval, X.mean_val, X.se_val)\n",
    "#        plt.figure()    \n",
    "        plotindex = plotindex+1\n",
    "        plt.subplot(fltrow, numgraphcol, plotindex)\n",
    "        plt.scatter(x=plot_data['fval'],y=plot_data['mean_val'])\n",
    "        plt.errorbar(plot_data['fval'],plot_data['mean_val'], yerr=plot_data['se_val'], fmt=\"o\")\n",
    "        myimp = shap_dataX['Importances'].iloc[0]\n",
    "        plt.title(site+\"_\"+feature+'(' + str(round(myimp,2)) + ')')\n",
    "#         if plot_data.shape[0] > 2:\n",
    "#             spl = np.polynomial.legendre.Legendre.fit(plot_data['fval'], plot_data['mean_val'],5, full=True)\n",
    "#             [spline_x, spline_y] = spl[0].linspace()\n",
    "#            plt.plot(spline_x, spline_y)      \n",
    "        plt.grid()\n",
    "    plt.show()\n",
    "    return fig    \n",
    "    #    plt.savefig('data/'+site+'/model_'+site+'_'+str(year)+'_'+f+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ff295-9b97-4352-a9ca-96f70c9059dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_feature_SHAP(shap_data, feature, site, yr, vline=[], vlinelabel=[]):     \n",
    "    fig = plt.figure()    \n",
    "    cmap = ['r', 'b', 'g', 'y', 'c']\n",
    "    shap_dataX = shap_data >> mask(X.site == site) >> mask(X.Feature == feature)\n",
    "    plot_data = shap_dataX >> mask(X.year == yr) >> select(X.fval, X.mean_val, X.se_val)\n",
    "    plt.scatter(x=plot_data['fval'],y=plot_data['mean_val'])\n",
    "    plt.errorbar(plot_data['fval'],plot_data['mean_val'], yerr=plot_data['se_val'], fmt=\"o\")\n",
    "#    plt.vlines(vline, ymin=plot_data['mean_val'].min(), ymax=plot_data['mean_val'].max(), label=vlinelabel, colors=cmap[:len(vlinelabel)])\n",
    "    for i in range(len(vline)):\n",
    "        plt.vlines(vline[i], ymin=plot_data['mean_val'].min(), ymax=plot_data['mean_val'].max(), label=vlinelabel[i], colors='r')        \n",
    "#    plt.legend()\n",
    "    plt.title(site+\"_\"+feature+\"_\"+str(yr))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return fig\n",
    "    #    plt.savefig('data/'+site+'/model_'+site+'_'+str(year)+'_'+f+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719cf934-32ff-4d36-9896-05a61df9513e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_comparison(model1, model2, stg='stg01', site = '', year='2016', oversample='raw', fs='rmscrbun', rmcol='005'):\n",
    "    import ipynb.fs.full.postprocessing3_collect\n",
    "    import importlib\n",
    "    importlib.reload(ipynb.fs.full.postprocessing3_collect)\n",
    "    data1 = ipynb.fs.full.postprocessing3_collect.result_split(model1, stg=stg, site =site, year=year, oversample=oversample, fs=fs, rmcol=rmcol, return_result=True)\n",
    "    data2 = ipynb.fs.full.postprocessing3_collect.result_split(model2, stg=stg, site =site, year=year, oversample=oversample, fs=fs, rmcol=rmcol, return_result=True)    \n",
    "    \n",
    "    data1 = list(data1.loc[:, ['site', 'auc']].sort_values('site').to_records(index=False))\n",
    "    data2 = list(data2.loc[:, ['site', 'auc']].sort_values('site').to_records(index=False))\n",
    "    labels1, values1 = zip(*data1)\n",
    "    labels2, values2 = zip(*data2)\n",
    "    \n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    ylocs1 = np.arange(len(values1))\n",
    "    ylocs2 = np.arange(len(values2))    \n",
    "    ax.barh(ylocs1, values1, align='center', height=height, label=model1, **kwargs)\n",
    "    ax.barh(ylocs2, values2, align='center', height=height, label=model2, **kwargs)\n",
    "\n",
    "    if show_values is True:\n",
    "        for x, y in zip(values1, ylocs1):\n",
    "            ax.text(x + x/100, y, round(x,2), va='center')\n",
    "        for x, y in zip(values2, ylocs2):\n",
    "            ax.text(x + x/100, y, round(x,2), va='center')\n",
    "\n",
    "    ax.set_yticks(ylocs1)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    if xlim is not None:\n",
    "        if not isinstance(xlim, tuple) or len(xlim) != 2:\n",
    "            raise ValueError('xlim must be a tuple of 2 elements')\n",
    "    else:\n",
    "        xlim = (0, max(values) * 1.1)\n",
    "    ax.set_xlim(xlim)\n",
    "\n",
    "    if ylim is not None:\n",
    "        if not isinstance(ylim, tuple) or len(ylim) != 2:\n",
    "            raise ValueError('ylim must be a tuple of 2 elements')\n",
    "    else:\n",
    "        ylim = (-1, len(values))\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    if xlabel is not None:\n",
    "        ax.set_xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    ax.grid(grid)\n",
    "    return ax    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84270ba4-bea6-4dd4-9080-75dcaeed2089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_features(shap_data, importance_type = 'Importances', max_num_features = 10):\n",
    "#    siteyr = shap_data['siteyr'].unique()\n",
    "    siteyrlen = shap_data.loc[:,['site', 'year']].drop_duplicates().shape[0]\n",
    "    #    years.sort()\n",
    "    rank_table = shap_data.sort_values(['site', 'year', importance_type], ascending=False).loc[:,['site', 'year', 'Feature']].drop_duplicates().groupby(['site', 'year']).head(max_num_features).reset_index(drop=True)\n",
    "    rank_table.loc[:, 'rank'] = list(range(1,max_num_features+1))*siteyrlen\n",
    "    rank_table = rank_table.pivot(index=['site', 'year'], columns='rank', values='Feature')\n",
    "    return rank_table   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4babfb-7071-42e0-b820-fac1ebda2913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(ipynb.fs.full.postprocessing3_collect)\n",
    "\n",
    "#Load statistics\n",
    "stg = 'stg23'\n",
    "fs = 'nofs'\n",
    "#stgs = [\"stg01\", \"stg123\"]\n",
    "#fss =  ['nofs', 'rmscrbun']\n",
    "oversample='raw'\n",
    "model = 'catd'    \n",
    "rmcol = '005'\n",
    "year = '3000'\n",
    "\n",
    "#ipynb.fs.full.postprocessing3_collect.result_split(model, stg=stg, site = '', year='', oversample=oversample, fs=fs, rmcol=rmcol, return_result=False)\n",
    "#ipynb.fs.full.postprocessing3_collect.DEID(model, stg=stg, site = '', year=year, oversample=oversample, fs=fs, rmcol=rmcol, return_result=False)\n",
    "result = pd.read_pickle('DEID_resultsplit_'+model+'_'+stg+'_'+year+'_'+fs+'_'+oversample+'_005.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80d1f2-0722-4f1f-ad6d-cc237d4525b2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result['ckd_group'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e0cc9-268e-4df9-bd99-5555e30bccdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def featuredecode(s):\n",
    "    return s.split(':')[-1].split('(')[0]\n",
    "def featuredecodetable(result):\n",
    "    x = pd.DataFrame(result['Feature'].unique())\n",
    "    x.columns = ['Feature']\n",
    "    x['featuredecode'] = x['Feature'].map(featuredecode)\n",
    "    return x\n",
    "decodetable = featuredecodetable(result)\n",
    "result = pd.merge(result, decodetable, right_on='Feature', left_on='Feature', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf48248-de07-4f18-b1e6-8347f9708f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipynb.fs.full.postprocessing3_collect.result_bt(stg, fs, oversample, model, numberbt=10, suffix='', return_result=False)\n",
    "result_boosttrap = pd.read_pickle('result_boosttrap.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c564cf9-bb5f-4017-917f-d4e55f6a6a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CI95(data):\n",
    "    if len(data) == 1:\n",
    "        return (np.nan, np.nan)\n",
    "    return st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)) #95% confidence interval\n",
    "\n",
    "plot_data = result_boosttrap[['site', 'roc']].groupby(\"site\").agg([np.mean, np.var, np.std, np.median, CI95]).reset_index()\n",
    "plot_data.columns = [''.join(x) for x in plot_data.columns]\n",
    "plot_data[['rocCI95down', 'rocCI95up']] = pd.DataFrame(plot_data['rocCI95'].tolist(), index=plot_data.index)\n",
    "plot_data['rocCI95down'] = plot_data['rocmean'] - plot_data['rocCI95down']\n",
    "plot_data['rocCI95up'] = plot_data['rocCI95up'] - plot_data['rocmean']\n",
    "plot_data = plot_data.drop(['rocCI95'],axis=1)\n",
    "plot_data = (plot_data>>mutate(Feature=X.site)>>mutate(auc=X.rocmean)>>mutate(aucdown=X.rocCI95down)>>mutate(aucup=X.rocCI95up)>>select('Feature','auc','aucdown','aucup')).drop_duplicates().groupby('Feature').mean().reset_index()\n",
    "ax = plot_importance(plot_data, importance_type='auc', max_num_features = 10, error=True, importance_type_down = 'aucdown', importance_type_up = 'aucup')\n",
    "result_boosttrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160dc214-a98f-4096-b477-ba666932a53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Show top freatures for each site year \n",
    "top_features(result, max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347171bd-4fe2-4881-ab52-77e826f6ef97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ttN = top_features(result, max_num_features=10)\n",
    "x = pd.get_dummies(ttN)\n",
    "y = x.groupby(x.columns.str.split('_').str[1], axis=1).sum()    \n",
    "y.dot(y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d837fc7-86bf-453b-a113-0635b3de61dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get top of top features\n",
    "maxnum_features=10\n",
    "maxmax_feature=10\n",
    "\n",
    "topnfeature = top_features(result, max_num_features=maxnum_features, importance_type='Importances')\n",
    "numsiteyr = topnfeature.shape[0]\n",
    "toptopfeatureN = topnfeature.melt()['value'].value_counts()\n",
    "toptopfeatureN = toptopfeatureN[range(maxmax_feature)]\n",
    "toptopfeature = pd.DataFrame(toptopfeatureN.keys())\n",
    "toptopfeature.columns = ['featuredecode']\n",
    "ttN = pd.DataFrame(toptopfeatureN).reset_index()\n",
    "\n",
    "var_list = pd.read_pickle('spdf1.pkl')\n",
    "opdf = pd.merge(ttN, var_list, left_on=['index'], right_on=['index'], how='left')\n",
    "opdf[0] = np.sqrt(opdf[0])\n",
    "opdf\n",
    "#plt.scatter(x=opdf['value'],y=opdf[0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfce408-dabd-4b5a-a0d5-912c2af306f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "toptopfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e0e6dc-b5c0-46a7-97de-06760caaa90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sites = ['MCRI', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'KUMC', 'UTSW']\n",
    "sites = ['MCRI', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'UTSW']\n",
    "\n",
    "stg = 'stg01'\n",
    "fs = 'rmscrbun'\n",
    "oversample='raw'\n",
    "model = 'catd'    \n",
    "rmcol = '005'\n",
    "model_file = pickle.load(open('data/'+'KUMC'+'/model_'+model+'_'+'KUMC'+'_'+str(3000)+'_'+stg+'_'+fs+'_'+oversample+'.pkl', 'rb'))\n",
    "\n",
    "X_df = pd.read_pickle('data/'+'KUMC'+'/X_train_'+'KUMC'+'_'+str(3000)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "X_df = X_df[0:0]\n",
    "\n",
    "for site in sites:\n",
    "    X_test =  pd.read_pickle('data/'+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "    common_col = [x for x in X_df.columns if x in X_test.columns]\n",
    "    X_test1 = X_df.copy()\n",
    "    X_test1[common_col] = X_test[common_col]\n",
    "    X_testbool = X_test1.select_dtypes('O').columns\n",
    "    X_test1[X_testbool] = False\n",
    "    y_test =  pd.read_pickle('data/'+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "    pred = model_file.predict_proba(X_test1)\n",
    "    roc = roc_auc_score(y_test, pred[:,1])    \n",
    "    print(site, roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357aad45-8cf9-4503-a749-a6f21440565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sites = ['MCRI', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'KUMC', 'UTSW']\n",
    "sites = ['MCRI', 'UIOWA', 'UNMC', 'UofU', 'UTHSCSA', 'KUMC', 'UTSW']\n",
    "\n",
    "stg = 'stg01'\n",
    "fs = 'rmscrbun'\n",
    "oversample='raw'\n",
    "model = 'catd'    \n",
    "rmcol = '005'\n",
    "model_file = pickle.load(open('data/'+'UMHC'+'/model_'+model+'_'+'UMHC'+'_'+str(3000)+'_'+stg+'_'+fs+'_'+oversample+'.pkl', 'rb'))\n",
    "\n",
    "X_df = pd.read_pickle('data/'+'UMHC'+'/X_train_'+'UMHC'+'_'+str(3000)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "X_df = X_df[0:0]\n",
    "\n",
    "for site in sites:\n",
    "    X_test =  pd.read_pickle('data/'+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "    common_col = [x for x in X_df.columns if x in X_test.columns]\n",
    "    X_test1 = X_df.copy()\n",
    "    X_test1[common_col] = X_test[common_col]\n",
    "    X_testbool = X_test1.select_dtypes('O').columns\n",
    "    X_test1[X_testbool] = False\n",
    "    y_test =  pd.read_pickle('data/'+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl')\n",
    "    pred = model_file.predict_proba(X_test1)\n",
    "    roc = roc_auc_score(y_test, pred[:,1])    \n",
    "    print(site, roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80824fd-0c12-496b-b921-af6b532b21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average auc per site\n",
    "plotdata = result\n",
    "plotdata = plotdata.astype({'year': 'str'})\n",
    "plotdata = (plotdata>>mutate(Feature=X.site)>>select('Feature','auc')).drop_duplicates().groupby('Feature').mean().reset_index()\n",
    "ax = plot_importance(plotdata, importance_type='auc', max_num_features = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810e779-f81f-4004-a96b-3f9087629b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'KUMC'\n",
    "year = 3000\n",
    "shap_data = result >> mask(X.site==site) >> mask(X.year==year)\n",
    "#plot feature importance\n",
    "importance_type = 'Importances'\n",
    "#importance_type = 'minmax_SHAP'\n",
    "#importance_type = 'varSHAP'\n",
    "ax = plot_importance(shap_data, importance_type=importance_type, max_num_features = 10)\n",
    "#ax.figure.savefig('data/'+site+'/model_'+site+'_'+str(year)+\"_feature_\"+importance_type+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7159b22-7c9f-428c-b01e-ec202f0c98f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myfig, topf_n = top_n_SHAP(result, 'UMHC', 3000, importance_type=importance_type, max_num_features = 10, numgraphcol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746a6aa-94f7-4668-8714-98f5bdce663a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myfig = one_feature_SHAP_allyear_allsite(result, 'AGE', numgraphcol=5, ylim_range=[-0.8, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1671630-d898-4e4f-8e2c-956ae7720f43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myfig = one_feature_SHAP_allyear_allsite(result, 'LAB::33037-3(mmol/L)', numgraphcol=5, ylim_range=[-1.5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd1b58-3cf5-4d61-a22c-fffa42525098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myfig = one_feature_SHAP_allyear_allsite(result, 'PX:CH:84300', numgraphcol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bb008-0094-4203-a2da-7314a3e8000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result[result['Feature'] == 'AGE']\n",
    "result2[['site', 'Importances']].drop_duplicates().groupby('site').mean().sort_values('Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa5a02-749d-4547-8962-c4cb9668f558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de4fed-ddb0-4cd2-a46d-1b07427d48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_feature_SHAP_allyear_allsite(result, '2823-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c4b67-f757-436e-bb26-9d0ce1e71c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_feature_SHAP(result, 'SYSTOLIC', 'MCRI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c930555-196a-4914-9a4e-3da2edbdb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost, Pool\n",
    "stg = 'stg01'\n",
    "fs = 'rmscrbun'\n",
    "oversample='raw'\n",
    "model_type = 'catd'    \n",
    "rmcol = '005'\n",
    "site = 'MCRI'\n",
    "year = '2011'\n",
    "suffix=''\n",
    "year=3000\n",
    "model = pickle.load(open('data/'+site+'/model_'+model_type+'_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl', 'rb'))\n",
    "X_train = pd.read_pickle('data/'+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+'.pkl')\n",
    "y_train = pd.read_pickle('data/'+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+suffix+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae28f88-a18a-4267-af04-af593c15b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cat = (X_train.dtypes == bool)\n",
    "cat_features_index = np.where(is_cat)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c06a7b-37d5-40f7-80af-2ac029389553",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(X_train, y_train, cat_features=cat_features_index, feature_names=list(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb7e1e-846c-46eb-8cb0-c58903538380",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('testtree.txt', format=\"json\", export_parameters=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b11b5-22f5-433f-9481-62caff1166ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfea = 'SYSTOLIC'\n",
    "\n",
    "ageidx = np.where(np.array(model.feature_names_) == tfea)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d54d7-3216-4f85-9884-cc38635d1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('testtree.txt')\n",
    "tree = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f3239-ca4c-4a6a-90c4-7b14661b975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tree['features_info']['float_features'])):\n",
    "    if tree['features_info']['float_features'][i]['flat_feature_index'] == ageidx:\n",
    "        print(i)\n",
    "        ageidx2 = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755feeca-a34f-47b3-afd5-ec53ace0760a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.plot_tree(tree_idx=38,pool=pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba251d0-2709-4b81-bd7b-df83d6249b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tree['oblivious_trees'][5]\n",
    "sp0 = X_train['SYSTOLIC']<93.33\n",
    "sp1 = np.logical_and(X_train['SYSTOLIC']>=93.33, X_train['SYSTOLIC']<=109.25)\n",
    "sp2 = X_train['SYSTOLIC']>109.25\n",
    "spt = np.logical_not(np.isnan(X_train['SYSTOLIC']))\n",
    "p0 = y_train[sp0].sum()/sp0.sum()\n",
    "p1 = y_train[sp1].sum()/sp1.sum()\n",
    "p2 = y_train[sp2].sum()/sp2.sum()\n",
    "pt = y_train[spt].sum()/spt.sum()\n",
    "print(p0, p1, p2, pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7450f-8383-46b0-8b48-fe4ed1a7789f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tree['oblivious_trees'][5]\n",
    "sp0 = X_train['SYSTOLIC']<93.33\n",
    "sp1 = np.logical_and(X_train['SYSTOLIC']>=93.33, X_train['SYSTOLIC']<=108.25)\n",
    "sp2 = X_train['SYSTOLIC']>108.25\n",
    "spt = np.logical_not(np.isnan(X_train['SYSTOLIC']))\n",
    "p0 = y_train[sp0].sum()/sp0.sum()\n",
    "p1 = y_train[sp1].sum()/sp1.sum()\n",
    "p2 = y_train[sp2].sum()/sp2.sum()\n",
    "pt = y_train[spt].sum()/spt.sum()\n",
    "print(p0, p1, p2, pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573fca32-c9ce-4e6a-bf44-6d76e60cffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree['oblivious_trees'][5]\n",
    "sp0 = X_train['SYSTOLIC']<93.33\n",
    "sp1 = np.logical_and(X_train['SYSTOLIC']>=108.25, X_train['SYSTOLIC']<=110.25)\n",
    "sp2 = X_train['SYSTOLIC']>108.25\n",
    "spt = np.logical_not(np.isnan(X_train['SYSTOLIC']))\n",
    "p0 = y_train[sp0].sum()/sp0.sum()\n",
    "p1 = y_train[sp1].sum()/sp1.sum()\n",
    "p2 = y_train[sp2].sum()/sp2.sum()\n",
    "pt = y_train[spt].sum()/spt.sum()\n",
    "print(p0, p1, p2, pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e34563-9b83-42c6-aaee-3ebde88468a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#myfig = zero_feature_SHAP(result, tfea, 'MCRI', int(year), vline=vline[:7], vlinelabel=vlinelabel[:7])\n",
    "myfig = zero_feature_SHAP(result, tfea, 'MCRI', 3000, vline=vline[:7], vlinelabel=vlinelabel[:7])\n",
    "print(list(zip(vline,vlinelabel))[:7])\n",
    "myfig.savefig(\"SHAP_MCRI_2011_overelay2013.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aaa5a6-c7c4-4e02-9198-7f276778bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_feature_SHAP(result, tfea, 'UIOWA', int(year), vline=vline[:7], vlinelabel=vlinelabel[:7])\n",
    "print(list(zip(vline,vlinelabel))[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b39b9-15d2-400d-972d-4cc29c1f8b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vline = []\n",
    "vlinelabel = []\n",
    "rank=0\n",
    "for i in range(len(tree['oblivious_trees'])):\n",
    "    for j in range(len(tree['oblivious_trees'][i]['splits'])):\n",
    "        if 'float_feature_index' in tree['oblivious_trees'][i]['splits'][j].keys():\n",
    "#            print(tree['oblivious_trees'][i]['splits'][j]['float_feature_index'])\n",
    "            if tree['oblivious_trees'][i]['splits'][j]['float_feature_index'] == ageidx2:\n",
    "                print(i, j, tree['oblivious_trees'][i]['splits'][j])\n",
    "                vline.append(tree['oblivious_trees'][i]['splits'][j]['border'])\n",
    "                vlinelabel.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4c419-5899-445c-bd88-1f9079e1bfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab863a-f9c5-4675-a2e0-517b7c3d3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c713c3-4d1d-44e0-8344-2dac9de891fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuredecode(s):\n",
    "    return s.split(':')[-1].split('(')[0]\n",
    "def featuredecodetable(result):\n",
    "    x = pd.DataFrame(result['Feature'].unique())\n",
    "    x.columns = ['Feature']\n",
    "    x['featuredecode'] = x['Feature'].map(featuredecode)\n",
    "    return x\n",
    "decodetable = featuredecodetable(result)\n",
    "result = pd.merge(result, decodetable, right_on='Feature', left_on='Feature', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236c34b-fa74-4260-96df-ad20c72957f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[np.logical_and(result['isCategorical'], result['fval']==1)][['site','Feature','mean_val','valCI95down', 'valCI95up']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af50f7c-e52a-4ba3-96ff-de2855bb35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forest_plot(result):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('error')\n",
    "    with warnings.catch_warnings():\n",
    "        res3_list = dict()\n",
    "#        dframe1 = result[result['isCategorical']][['site', 'Feature', 'fval', 'valmean_0', 'valstd_0', 'valsize_0', 'valmean_1', 'valstd_1', 'valsize_1']]       \n",
    "        dframe1 = result[result['isCategorical']][['site', 'Feature', 'fval', 'valmean_0', 'valstd_0', 'valsize_0', 'valmean_1', 'valstd_1', 'valsize_1']]       \n",
    "        filter_con = dframe1['valstd_0'] != 0\n",
    "        filter_con = np.logical_and(dframe1['valstd_1'] != 0, filter_con)\n",
    "        filter_con = np.logical_and(dframe1['valsize_0'] != 0, filter_con)\n",
    "        filter_con = np.logical_and(dframe1['valsize_1'] != 0, filter_con)\n",
    "        filter_con = np.logical_and(dframe1['fval'] != 0, filter_con)    \n",
    "        dframe1 = dframe1[filter_con].dropna()\n",
    "        for name, group in dframe1.groupby(['Feature']):\n",
    "            if group.shape[0] != 1:\n",
    "                try:\n",
    "                    mean2, sd2, nobs2, mean1, sd1, nobs1 = np.asarray(group[['valmean_0', 'valstd_0', 'valsize_0', 'valmean_1', 'valstd_1', 'valsize_1']]).T\n",
    "                    rownames  = group['site'].tolist()        \n",
    "                    eff, var_eff = effectsize_smd(mean2, sd2, nobs2, mean1, sd1, nobs1)\n",
    "                    res3 = combine_effects(eff, var_eff, method_re=\"chi2\", use_t=True, row_names=rownames)\n",
    "                    res3.conf_int_samples(nobs=np.array(nobs1 + nobs2))\n",
    "                    #print(res3.summary_frame())\n",
    "                    res3_list[name] = res3\n",
    "                except:\n",
    "                    print(name)\n",
    "#    redf = pd.DataFrame([list(res3_list.keys()), [res3_list[key] for key in res3_list.keys()]]).T \n",
    "#    redf.columns = ['Feature', 'statmodel']\n",
    "#    return redf\n",
    "    return res3_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b47c8-cf2a-4e93-a19a-535866c24606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res3_list = generate_forest_plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894b142-8575-44ba-bc96-8a51fb3a8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forestplot_all_feature(res3_list, top_eff=10, reverse=False):    \n",
    "#    res_fil = {key:res3_list[key] for key in res3_list.keys() if res3_list[key].summary_frame().loc['random effect']['ci_low']>0 or res3_list[key].summary_frame().loc['random effect']['ci_upp']<0}\n",
    "    res_fil = {key:res3_list[key] for key in res3_list.keys()}\n",
    "#    ci_low = [res_fil[key].summary_frame().loc['random effect']['ci_low'] for key in res_fil.keys()]\n",
    "#    ci_upp = [res_fil[key].summary_frame().loc['random effect']['ci_upp'] for key in res_fil.keys()]\n",
    "    res3_list_eff = {key:res_fil[key].summary_frame().loc['random effect']['eff'] for key in res_fil.keys()}\n",
    "    max_key = sorted(res3_list_eff, key=res3_list_eff.get, reverse=reverse)[:top_eff]\n",
    "    \n",
    "    for key in max_key:\n",
    "        print(key)\n",
    "        res3_list[key].plot_forest()\n",
    "        plt.savefig('allsite'+key.replace(\":\",\"_\")+'.svg',bbox_inches='tight')        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67916504-c896-4b26-b25c-f66cc406708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot_all_feature(res3_list, top_eff=10, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c073dd07-ff6a-40d2-b9f9-923582e19632",
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot_all_feature(res3_list, top_eff=10, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5d94a-903c-4dd6-aa7f-9d4a58986ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
