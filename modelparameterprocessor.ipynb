{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843bb517-6493-4a4d-aa93-4e5f28ee56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ipynb.fs.full.preprocessing0\n",
    "import ipynb.fs.full.preprocessing1\n",
    "import ipynb.fs.full.preprocessing2_BT\n",
    "import ipynb.fs.full.preprocessing3_smote\n",
    "import ipynb.fs.full.runxgboost\n",
    "import ipynb.fs.full.postprocessing1_SHAP\n",
    "import ipynb.fs.full.postprocessing3_collect\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.interpolate import BSpline, make_interp_spline, interp1d\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import csv\n",
    "from dfply import *\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import os\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import operator\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62195762-6484-4482-85d8-b6301c5bc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_type = ['catd', 'catcv', 'catr', 'xgbshg', 'xgbb']\n",
    "sites = ['MCRI', 'IUR', 'MCW', 'UIOWA', 'UMHC', 'UNMC', 'UofU', 'UPITT', 'UTHSCSA', 'KUMC', 'UTSW']\n",
    "stgs = [\"stg01\", \"stg123\"]\n",
    "fss =  ['nofs', 'rmscrbun']\n",
    "oversamples = ['raw', 'cp', 'sm']\n",
    "rmcols = ['raw', '0.05']\n",
    "ban_list = [('UPITT', 2013), ('UPITT', 2012), ('MCW', 2011)] #Sample size too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a0f43-28f5-4c5d-bdb5-988a39ba567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate all combo and make it into dict\n",
    "def generate_parameter_file(models_type, sites, stg, fss, oversamples, rmcols, ban_list):\n",
    "    para_dicts = []\n",
    "    paradir = \"data/modelparameter\"\n",
    "    datafolder = '/home/hchan2/AKI/data/'\n",
    "    home_directory = \"/home/hchan2/AKI/AKI_Python/\"\n",
    "    print(sites)\n",
    "    for s in sites:\n",
    "        onset = pd.read_pickle('data/'+s+'/p0_onset_'+s+'.pkl')        \n",
    "        years = list(pd.to_datetime(onset['ADMIT_DATE']).dt.year.unique())    \n",
    "        para_dictsS = [{'model_type':m, 'site':s, 'year':y, 'stg':st, 'fs':fs, 'oversample':o, 'rmcol':r} for m in models_type for st in stg for fs in fss for o in oversamples for r in rmcols for y in years if (s, y) not in ban_list]\n",
    "        para_dicts = para_dicts+para_dictsS\n",
    "    return para_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f4876-4e47-468a-8cd2-e964d7320d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parameter_file_additional(para_list):\n",
    "    for p in para_list:\n",
    "        model_type, site, year, stg, fs, oversample, rmcol = operator.itemgetter('model_type', 'site', 'year', 'stg', 'fs', 'oversample', 'rmcol')(p)\n",
    "        p['p0_onset'] = 'data/'+site+'/p0_onset_'+site+'.pkl'\n",
    "        p['p0_vital'] = 'data/'+site+'/p0_vital_'+site+'.pkl'\n",
    "        p['p0_demo']  = 'data/'+site+'/p0_demo_' +site+'.pkl'\n",
    "        p['p0_dx']    = 'data/'+site+'/p0_dx_'   +site+'.pkl'\n",
    "        p['p0_px']    = 'data/'+site+'/p0_px_'   +site+'.pkl'\n",
    "        p['p0_lab']   = 'data/'+site+'/p0_lab_'  +site+'.pkl'\n",
    "        p['p0_amed']  = 'data/'+site+'/p0_amed_' +site+'.pkl'\n",
    "        \n",
    "        p['onset']  = 'data/'+site+'/onset_' +site+'_'+str(year)+'.pkl'\n",
    "        p['vital']  = 'data/'+site+'/vital_' +site+'_'+str(year)+'.pkl'\n",
    "        p['demo']   = 'data/'+site+'/demo_'  +site+'_'+str(year)+'.pkl'\n",
    "        p['dx']     = 'data/'+site+'/dx_'    +site+'_'+str(year)+'.pkl'\n",
    "        p['px']     = 'data/'+site+'/px_'    +site+'_'+str(year)+'.pkl'\n",
    "        p['labnum'] = 'data/'+site+'/labnum_'+site+'_'+str(year)+'.pkl'\n",
    "        p['labcat'] = 'data/'+site+'/labcat_'+site+'_'+str(year)+'.pkl'\n",
    "        p['amed']   = 'data/'+site+'/amed_'  +site+'_'+str(year)+'.pkl'\n",
    "\n",
    "        p['bt'] = 'data/'+site+'/bt_'+site+'_'+str(year)+'.pkl'\n",
    "        \n",
    "        p['X_train'] = 'data/'+site+'/X_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl'\n",
    "        p['X_test'] =  'data/'+site+'/X_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl'\n",
    "        p['y_train'] = 'data/'+site+'/y_train_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl'\n",
    "        p['y_test'] =  'data/'+site+'/y_test_' +site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl'\n",
    "\n",
    "        p['model']       = 'data/'+site+'/model_'     +model_type+'_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl'\n",
    "        p['shapdata']    = 'data/'+site+'/shapdata_'  +model_type+'_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'.pkl'        \n",
    "        p['parafile']    = 'modelparameter/parafile_' +model_type+'_'+site+'_'+str(year)+'_'+stg+'_'+fs+'_'+oversample+'_'+rmcol+'.pkl'\n",
    "        \n",
    "    return para_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b1059-4ed0-476a-8a8e-1ff2de45a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_para_list(paralist):\n",
    "    pd.DataFrame(paralist).to_pickle('paralist.pkl')\n",
    "    for p in paralist:\n",
    "        pickle.dump(p, open(p['parafile'], 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3867b0-6bfe-4496-85ee-f39c24856ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    para_list = generate_parameter_file(models_type, sites, stg, fss, oversamples, rmcols, ban_list)\n",
    "    para_list = generate_parameter_file_additional(para_list)\n",
    "    save_para_list(para_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375dfd3-b450-4518-bfc8-89b6d48cdd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_site_year(sites=None):\n",
    "    pl = pd.read_pickle('paralist.pkl')\n",
    "    sites = ['UTSW', 'KUMC']\n",
    "    pl = pl.loc[:,['site' ,'year']].drop_duplicates()\n",
    "    if sites is not None:\n",
    "        return pl[pl['site'].isin(sites)].to_dict(orient='records')\n",
    "    else:\n",
    "        return pl.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d4c1d-8809-45c5-9ff1-4e5f4f3b0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_site():\n",
    "    pl = pd.read_pickle('paralist.pkl')\n",
    "    sites = ['UTSW', 'KUMC']\n",
    "    pl = pl.loc[:,'site'].drop_duplicates()\n",
    "    return list(pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a9400-194a-4f64-be55-0d62373c68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_site_runner(runners, sites=None):\n",
    "    if sites is None:\n",
    "        sites = generate_site()  \n",
    "    return [{'runner_wrapper':r, 'site':s} for r in runners for s in sites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670395a-9e46-42dd-978a-732137c22374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_site_year_runner(runners, sites=None):\n",
    "    sites_yr = generate_site_year(sites)    \n",
    "    return [{'runner_wrapper':r, 'site':sy['site'], 'year':sy['year']} for r in runners for sy in sites_yr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438cc77-2656-4bb4-a0b1-f660f553f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xgbcat_runner(runners, model_type=None, site=None, stg=None, fs=None, oversample=None, rmcol=None):\n",
    "    sites_yr = generate_site_year(sites)    \n",
    "    if model_type is None:\n",
    "        model_type = ['catd']\n",
    "    if stg is None:\n",
    "        stg = ['stg01']\n",
    "    if fs is None:\n",
    "        fs = ['nofs', 'rmscrbun']\n",
    "    if oversample is None:\n",
    "        oversample = ['raw', 'cp']\n",
    "    return [{'runner_wrapper':runners, 'site':sy['site'], 'year':sy['year'], 'stg':st, 'fs':f, 'oversample':o} for sy in sites_yr for m in model_type for st in stg for o in oversample for f in fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fae078-9784-49f4-a28f-2e90e07f115a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_CAUSAL",
   "language": "python",
   "name": "aki_causal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
